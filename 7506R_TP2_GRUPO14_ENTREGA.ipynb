{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "______________________________________\n",
    "# <center>**Trabajo Practico Nº2 para la Materia *Organización de Datos***</center>\n",
    "\n",
    "*Integrantes*:\n",
    "- 103963\tCarolina Di Matteo\tcdimatteo@fi.uba.ar\n",
    "- 101231\tPablo Salvador Dimartino\tpdimartino@fi.uba.ar\n",
    "- 100113\tJuan Sebastian Burgos\tjsburgos@fi.uba.ar\n",
    "- 104415\tValentina Laura Correa\tvcorrea@fi.uba.ar\n",
    "\n",
    "*Grupo*: 14\n",
    "\n",
    "*Repositorio*: [github](https://github.com/valencorrea/7506R-2C2022-GRUPO14)\n",
    "\n",
    "*Curso*: Rodriguez\n",
    "\n",
    "*Cuatrimestre*: 2c2022\n",
    "\n",
    "Datos provistos por [properati](https://www.properati.com.ar).\n",
    "______________________________________\n"
   ],
   "metadata": {
    "collapsed": false,
    "id": "ALhQpMoS2Do2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introducción"
   ],
   "metadata": {
    "id": "jrObdaVTw13E"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "El presente trabajo práctico es una continuación del ‘TP1: Propiedades en Venta’. \n",
    "\n",
    "En la entrega anterior se propuso aplicar técnicas de análisis exploratorio, preprocesamiento de datos, agrupamiento, clasificación y regresión. Siguiendo esta línea, y con el objetivo de continuar resolviendo problemas reales de ciencia de datos, en esta segunda parte se implementarán nuevos modelos predictivos a partir de los anteriormente mencionados. \n",
    "\n",
    "En esta oportunidad se buscará demostrar los conocimientos adquiridos sobre procesamiento del lenguaje natural, redes neuronales y ensamble de modelos. Para esto se utilizarán tanto datasets provistos por la materia, tomados de la página de la empresa Properati, como los generados por el grupo en el trabajo anterior."
   ],
   "metadata": {
    "id": "8Tot765gvLP2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0. Setup"
   ],
   "metadata": {
    "id": "civIgEQKvQ6A"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Importación de bibliotecas"
   ],
   "metadata": {
    "id": "vrqonJJjvVay"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: visualkeras in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from visualkeras) (9.2.0)\n",
      "Requirement already satisfied: numpy>=1.18.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from visualkeras) (1.21.5)\n",
      "Requirement already satisfied: aggdraw>=1.3.11 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from visualkeras) (1.3.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import joblib as joblib\n",
    "\n",
    "pip install visualkeras"
   ],
   "metadata": {
    "id": "h6RrCiyq2Do7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3e7b3e93-b112-4351-a933-5d45f291d371"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikeras[tensorflow] in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from scikeras[tensorflow]) (1.1.3)\n",
      "Requirement already satisfied: packaging>=0.21 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from scikeras[tensorflow]) (21.3)\n",
      "Requirement already satisfied: tensorflow>=2.11.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from scikeras[tensorflow]) (2.11.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from packaging>=0.21->scikeras[tensorflow]) (3.0.9)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (1.21.5)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (2.11.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (2.1.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (0.29.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (2.11.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (4.3.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (0.4.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (3.7.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (1.16.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (65.5.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (14.0.6)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (0.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (1.14.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (2.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (3.19.6)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (1.42.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (2.11.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (2.11.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (3.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (0.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (2.28.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (2.0.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (2.6.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (0.6.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (1.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (2.0.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (3.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikeras[tensorflow]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikeras[tensorflow-cpu] in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: packaging>=0.21 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from scikeras[tensorflow-cpu]) (21.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from scikeras[tensorflow-cpu]) (1.1.3)\n",
      "Requirement already satisfied: tensorflow-cpu>=2.11.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from scikeras[tensorflow-cpu]) (2.11.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from packaging>=0.21->scikeras[tensorflow-cpu]) (3.0.9)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras[tensorflow-cpu]) (1.21.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras[tensorflow-cpu]) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras[tensorflow-cpu]) (1.7.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras[tensorflow-cpu]) (1.1.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (2.11.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (0.29.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (2.1.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (1.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (65.5.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (2.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (1.14.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (0.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (1.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (3.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (4.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (2.11.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (1.42.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (3.19.6)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (2.11.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (14.0.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (3.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (0.37.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (0.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (0.6.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (2.6.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (2.0.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (4.7.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (1.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (2022.12.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (3.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikeras[tensorflow-cpu]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "pip install unidecode"
   ],
   "metadata": {
    "id": "vdZzPMc93I-C",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "045bdfc2-9805-43c2-c41d-1cd20aa7efce"
   },
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "pip install types-all"
   ],
   "metadata": {
    "id": "7SrZ6Pvh8b_K",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "2aff2586-af7e-4665-9009-c3ba548ce286"
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: types-all in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: types-contextvars in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (2.4.7)\n",
      "Requirement already satisfied: types-Deprecated in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.2.9)\n",
      "Requirement already satisfied: types-backports in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.1.3)\n",
      "Requirement already satisfied: types-tabulate in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.9.0.0)\n",
      "Requirement already satisfied: types-chardet in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (5.0.4.1)\n",
      "Requirement already satisfied: types-PyJWT in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.7.1)\n",
      "Requirement already satisfied: types-colorama in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.4.15.4)\n",
      "Requirement already satisfied: types-backports-abc in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.5.2)\n",
      "Requirement already satisfied: types-pycurl in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (7.45.2.0)\n",
      "Requirement already satisfied: types-kazoo in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.1.3)\n",
      "Requirement already satisfied: types-pysftp in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.2.17)\n",
      "Requirement already satisfied: types-ujson in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (5.6.0.0)\n",
      "Requirement already satisfied: types-polib in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.1.12.1)\n",
      "Requirement already satisfied: types-DateTimeRange in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.2.8)\n",
      "Requirement already satisfied: types-paramiko in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (2.12.0.1)\n",
      "Requirement already satisfied: types-itsdangerous in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.1.6)\n",
      "Requirement already satisfied: types-Werkzeug in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.0.9)\n",
      "Requirement already satisfied: types-dateparser in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.1.4.4)\n",
      "Requirement already satisfied: types-aiofiles in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (22.1.0.4)\n",
      "Requirement already satisfied: types-python-dateutil in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (2.8.19.5)\n",
      "Requirement already satisfied: types-redis in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (4.3.21.6)\n",
      "Requirement already satisfied: types-pathlib2 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (2.3.0)\n",
      "Requirement already satisfied: types-simplejson in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (3.18.0.0)\n",
      "Requirement already satisfied: types-dataclasses in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.6.6)\n",
      "Requirement already satisfied: types-pyaudio in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.2.16.4)\n",
      "Requirement already satisfied: types-requests in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (2.28.11.6)\n",
      "Requirement already satisfied: types-ipaddress in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.0.8)\n",
      "Requirement already satisfied: types-xxhash in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (3.0.5.1)\n",
      "Requirement already satisfied: types-maxminddb in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.5.0)\n",
      "Requirement already satisfied: types-cachetools in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (5.2.1)\n",
      "Requirement already satisfied: types-singledispatch in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (3.7.5.1)\n",
      "Requirement already satisfied: types-toml in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.10.8.1)\n",
      "Requirement already satisfied: types-mypy-extensions in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.4.24)\n",
      "Requirement already satisfied: types-docutils in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.19.1.1)\n",
      "Requirement already satisfied: types-pyvmomi in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (8.0.0.0)\n",
      "Requirement already satisfied: types-emoji in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (2.1.0.1)\n",
      "Requirement already satisfied: types-termcolor in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.1.6)\n",
      "Requirement already satisfied: types-PyMySQL in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.0.19.1)\n",
      "Requirement already satisfied: types-pkg-resources in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.1.3)\n",
      "Requirement already satisfied: types-PyYAML in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (6.0.12.2)\n",
      "Requirement already satisfied: types-scribe in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (2.0.0)\n",
      "Requirement already satisfied: types-characteristic in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (14.3.7)\n",
      "Requirement already satisfied: types-Routes in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (2.5.0)\n",
      "Requirement already satisfied: types-fb303 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.0.0)\n",
      "Requirement already satisfied: types-waitress in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (2.1.4.3)\n",
      "Requirement already satisfied: types-docopt in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.6.11)\n",
      "Requirement already satisfied: types-protobuf in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (4.21.0.2)\n",
      "Requirement already satisfied: types-Markdown in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (3.4.2.1)\n",
      "Requirement already satisfied: types-frozendict in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (2.0.9)\n",
      "Requirement already satisfied: types-orjson in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (3.6.2)\n",
      "Requirement already satisfied: types-croniter in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.3.2.1)\n",
      "Requirement already satisfied: types-openssl-python in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.1.3)\n",
      "Requirement already satisfied: types-retry in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.9.9)\n",
      "Requirement already satisfied: types-MarkupSafe in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.1.10)\n",
      "Requirement already satisfied: types-decorator in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (5.1.8.1)\n",
      "Requirement already satisfied: types-nmap in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.1.6)\n",
      "Requirement already satisfied: types-certifi in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (2021.10.8.3)\n",
      "Requirement already satisfied: types-Jinja2 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (2.11.9)\n",
      "Requirement already satisfied: types-six in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.16.21.4)\n",
      "Requirement already satisfied: types-pyfarmhash in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.3.1)\n",
      "Requirement already satisfied: types-geoip2 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (3.0.0)\n",
      "Requirement already satisfied: types-typed-ast in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.5.8.3)\n",
      "Requirement already satisfied: types-enum34 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.1.8)\n",
      "Requirement already satisfied: types-annoy in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.17.8.1)\n",
      "Requirement already satisfied: types-first in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (2.0.5)\n",
      "Requirement already satisfied: types-tornado in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (5.1.1)\n",
      "Requirement already satisfied: types-atomicwrites in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.4.5.1)\n",
      "Requirement already satisfied: types-JACK-Client in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.5.10.3)\n",
      "Requirement already satisfied: types-Flask in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.1.6)\n",
      "Requirement already satisfied: types-pyRFC3339 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.1.1.1)\n",
      "Requirement already satisfied: types-python-slugify in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (7.0.0.1)\n",
      "Requirement already satisfied: types-click in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (7.1.8)\n",
      "Requirement already satisfied: types-filelock in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (3.2.7)\n",
      "Requirement already satisfied: types-mock in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (4.0.15.2)\n",
      "Requirement already satisfied: types-futures in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (3.3.8)\n",
      "Requirement already satisfied: types-tzlocal in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (4.2.2.2)\n",
      "Requirement already satisfied: types-pytz in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (2022.7.0.0)\n",
      "Requirement already satisfied: types-pymssql in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (2.1.0)\n",
      "Requirement already satisfied: types-bleach in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (5.0.3.1)\n",
      "Requirement already satisfied: types-cryptography in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (3.3.23.2)\n",
      "Requirement already satisfied: types-freezegun in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.1.10)\n",
      "Requirement already satisfied: types-boto in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (2.49.18.3)\n",
      "Requirement already satisfied: types-python-gflags in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (3.1.7.1)\n",
      "Requirement already satisfied: types-Pillow in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (9.3.0.4)\n",
      "Requirement already satisfied: types-click-spinner in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.1.13.1)\n",
      "Requirement already satisfied: types-urllib3<1.27 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-requests->types-all) (1.26.25.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.29.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (14.0.6)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.21.5)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.42.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.6.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.12)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pip install keras"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#Importación de librerías\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from collections import Counter\n",
    "import unidecode\n",
    "import re\n",
    "from joblib import load, dump\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from keras.metrics import MeanSquaredError\n",
    "from sklearn.metrics import recall_score, accuracy_score, f1_score, precision_score, r2_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n",
    "from collections import defaultdict\n",
    "import math\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "#Configuración de Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "#Ejecución con Drive\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    IN_COLAB = True\n",
    "else:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB :\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    properati = pd.read_csv('/content/drive/MyDrive/📔 Organización de Datos (75.06)/TPS/TP2/1d_df_reducido.csv')\n",
    "    properati_descrip = pd.read_csv('/content/drive/MyDrive/📔 Organización de Datos (75.06)/TPS/TP1/properati_argentina_2021_decrip.csv')\n",
    "    stop_words = '/content/drive/MyDrive/📔 Organización de Datos (75.06)/TPS/TP2/stopwords.txt'\n",
    "else:\n",
    "    # properati = pd.read_csv('./1d_df_reducido.csv')\n",
    "    df_train = pd.read_csv('./DATASETS/df_train_tp1.csv')\n",
    "    df_test = pd.read_csv('./DATASETS/df_test_tp1.csv')\n",
    "    properati_descrip = pd.read_csv('properati_argentina_2021_decrip.csv')\n",
    "    stop_words = 'stopwords'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Funciones auxiliares"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def metricas_clasificacion(y_test, y_pred):\n",
    "    print(f'Accuracy: {round(accuracy_score(y_test, y_pred),2)}')\n",
    "    print(f'Precision: {round(precision_score(y_test, y_pred, average=\"macro\"),2)}')\n",
    "    print(f'Recall: {round(recall_score(y_test, y_pred, average=\"macro\"),2)}')\n",
    "    print(f'F1 Score: {round(f1_score(y_test, y_pred, average=\"macro\"),2)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def prediccion_y_metricas_regresion(regressor, x_test, y_test):\n",
    "\n",
    "  y_pred = regressor.predict(x_test)\n",
    "\n",
    "  print(f\"Se obtuvo un Score de {round(regressor.score(x_test, y_test)*100,3)}%\")\n",
    "\n",
    "  mse = metrics.mean_squared_error(\n",
    "        y_true  = y_test,\n",
    "        y_pred  = y_pred,\n",
    "        squared = True\n",
    "       )\n",
    "\n",
    "  print(f\"El error según la métrica 'Mean Square Error' de test es: {mse}\")\n",
    "\n",
    "  rmse = metrics.mean_squared_error(\n",
    "        y_true  = y_test,\n",
    "        y_pred  = y_pred,\n",
    "        squared = False\n",
    "       )\n",
    "\n",
    "  print(f\"El error según la métrica 'Root Mean Square Error' de test es: {rmse}\")\n",
    "\n",
    "  return"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def format_aspects(line, word):\n",
    "    format = r\"\\W*([\\w]+)\"\n",
    "    n = 2\n",
    "    x = re.search(r'{}\\W*{}{}'.format(format*n, word, format*n), line)\n",
    "    if x is not None:\n",
    "        return x.group()\n",
    "    else:\n",
    "        return \"\""
   ],
   "metadata": {
    "id": "CCKsO-A5w7TQ"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def convert_b_m_a(x):\n",
    "    mx = max(x[0], x[1], x[2])\n",
    "    if mx == x[0]:\n",
    "        return 'bajo'\n",
    "    elif mx == x[1]:\n",
    "        return 'medio'\n",
    "    elif mx == x[2]:\n",
    "        return 'alto'"
   ],
   "metadata": {
    "id": "3suAr0ciwY91"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def estandarizar(df, columns):\n",
    "  sscaler = StandardScaler()\n",
    "\n",
    "  for col in columns:\n",
    "    df[col] = sscaler.fit_transform(pd.DataFrame(df[col]))"
   ],
   "metadata": {
    "id": "0LF1eyB9l4nt"
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def limpiar_values_de_aspects(df, aspects, values):\n",
    "    i = 0\n",
    "    for aspect in aspects:\n",
    "        for word in values[i]:\n",
    "            df[aspect] = df[aspect].apply(lambda line: word if word in line else line)\n",
    "        df[aspect] = df[aspect].apply(lambda line: line if len(line.split())<2 else '')\n",
    "        i = i+1"
   ],
   "metadata": {
    "id": "AAEy2PV92DpO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def evaluate_model(model, x, y, splits, n):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=splits, n_repeats=n, random_state=1)\n",
    "    scores = cross_val_score(model, x, y, scoring='neg_mean_squared_error', cv=cv, verbose=1, n_jobs=3, error_score='raise')\n",
    "    return scores"
   ],
   "metadata": {
    "id": "tDt5-bPcEn_m"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_results(model_scores, name):\n",
    "    \n",
    "    model_names = list(model_scores.keys())\n",
    "    results = [model_scores[model] for model in model_names]\n",
    "    fig = go.Figure()\n",
    "    for model, result in zip(model_names, results):\n",
    "        fig.add_trace(go.Box(\n",
    "            y=result,\n",
    "            name=model,\n",
    "            boxpoints='all',\n",
    "            jitter=0.5,\n",
    "            whiskerwidth=0.2,\n",
    "            marker_size=2,\n",
    "            line_width=1)\n",
    "        )\n",
    "    \n",
    "    fig.update_layout(\n",
    "    title='Performance of Different Models Using 5-Fold Cross-Validation',\n",
    "    paper_bgcolor='rgb(243, 243, 243)',\n",
    "    plot_bgcolor='rgb(243, 243, 243)',\n",
    "    xaxis_title='Model',\n",
    "    yaxis_title='Error Cuadrático Medio',\n",
    "    showlegend=False)\n",
    "    fig.show()"
   ],
   "metadata": {
    "id": "NImxsouY4HaJ"
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preparación de datasets"
   ],
   "metadata": {
    "id": "yG33nESmvkqN"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "df_train_x = df_train.drop([\"property_price\", \"tipo_precio_3\"], axis=\"columns\")\n",
    "df_train_y_regresion = df_train[\"property_price\"]\n",
    "df_train_y_clasificacion = df_train[\"tipo_precio_3\"]\n",
    "\n",
    "df_test_x = df_test.drop([\"property_price\", \"tipo_precio_3\"], axis=\"columns\")\n",
    "df_test_y_regresion = df_test[\"property_price\"]\n",
    "df_test_y_clasificacion = df_test[\"tipo_precio_3\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Procesamiento del Lenguaje Natural"
   ],
   "metadata": {
    "collapsed": false,
    "id": "DajLENWv2DpA"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.a Ampliación del dataset\n",
    "___"
   ],
   "metadata": {
    "id": "mmjJ3qskuJyJ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hacemos un merge del dataset original y el de descripciones, y quedémonos únicamente con las columnas `id` y `property_description`:"
   ],
   "metadata": {
    "id": "904YC-oLyddb"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "df_descrip = pd.merge(df_train_x, properati_descrip, on=\"id\")\n",
    "df_descrip = df_descrip[[\"id\", \"property_description\"]]\n",
    "\n",
    "df_test_descrip = pd.merge(df_test_x, properati_descrip, on=\"id\")\n",
    "df_test_descrip = df_test_descrip[[\"id\", \"property_description\"]]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "vRbU2jpk2Do_",
    "outputId": "44fcabfb-0e8b-496a-881f-0de5fbc8f3e6"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "                             id  \\\n0      ahcEMvB66wjPz0SYWZQDBw==   \n1      M0g0l0s6S13X+cZlGkUo8g==   \n2      V/KMMLRRx/Nn+g3m5lrW7A==   \n3      odR0QjYc3xtaYfqNJvbOSQ==   \n4      RqOcPIKYYZDG+CFMq2c1RA==   \n...                         ...   \n18600  g2fBcuyxiq3V0GdPATLFDw==   \n18601  2jfcV70r5M8iASKFbpFEqA==   \n18602  H4X7bNq04pK7U6fCcbxYNg==   \n18603  QWBP5Zp0TBUlFrzP9GO9bA==   \n18604  pKo6hHHPBZJydrHIn5S5Tg==   \n\n                                    property_description  \n0      Corredor Responsable: Juan Carlos Treco - CUCI...  \n1      Corredor Responsable: Micaela Perez / Lucas Fe...  \n2      Corredor Responsable: Gustavo Guastello - C.U....  \n3      PH A ESTRENAR SANCHEZ DE LORIA AL 1500 Y CONST...  \n4      EXCELENTE SEMIPISO 3 AMB C/BALCON LUMINOSO EN ...  \n...                                                  ...  \n18600  Venta DEPARTAMENTO 2 Ambientes Villa Ortuzar. ...  \n18601  Departamento a estrenar monoambiente, luminoso...  \n18602  Corredor Responsable: Daniel Acosta - CUCICBA ...  \n18603  El departamento se ubica en la PB y contiene:<...  \n18604  Departamento tipo PH en el hermoso edificio hi...  \n\n[18605 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>property_description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ahcEMvB66wjPz0SYWZQDBw==</td>\n      <td>Corredor Responsable: Juan Carlos Treco - CUCI...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M0g0l0s6S13X+cZlGkUo8g==</td>\n      <td>Corredor Responsable: Micaela Perez / Lucas Fe...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>V/KMMLRRx/Nn+g3m5lrW7A==</td>\n      <td>Corredor Responsable: Gustavo Guastello - C.U....</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>odR0QjYc3xtaYfqNJvbOSQ==</td>\n      <td>PH A ESTRENAR SANCHEZ DE LORIA AL 1500 Y CONST...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RqOcPIKYYZDG+CFMq2c1RA==</td>\n      <td>EXCELENTE SEMIPISO 3 AMB C/BALCON LUMINOSO EN ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>18600</th>\n      <td>g2fBcuyxiq3V0GdPATLFDw==</td>\n      <td>Venta DEPARTAMENTO 2 Ambientes Villa Ortuzar. ...</td>\n    </tr>\n    <tr>\n      <th>18601</th>\n      <td>2jfcV70r5M8iASKFbpFEqA==</td>\n      <td>Departamento a estrenar monoambiente, luminoso...</td>\n    </tr>\n    <tr>\n      <th>18602</th>\n      <td>H4X7bNq04pK7U6fCcbxYNg==</td>\n      <td>Corredor Responsable: Daniel Acosta - CUCICBA ...</td>\n    </tr>\n    <tr>\n      <th>18603</th>\n      <td>QWBP5Zp0TBUlFrzP9GO9bA==</td>\n      <td>El departamento se ubica en la PB y contiene:&lt;...</td>\n    </tr>\n    <tr>\n      <th>18604</th>\n      <td>pKo6hHHPBZJydrHIn5S5Tg==</td>\n      <td>Departamento tipo PH en el hermoso edificio hi...</td>\n    </tr>\n  </tbody>\n</table>\n<p>18605 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_descrip"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Busquemos aspectos de una propiedad utilizando la columna `property_description`."
   ],
   "metadata": {
    "id": "uCEL8YyUxYaa"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Veamos cuántos registros nulos existen:"
   ],
   "metadata": {
    "id": "tAEE-G_QzCXj"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay 0 datos nulos.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Hay {df_descrip['property_description'].isna().sum()} datos nulos.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ydHTArN62DpA",
    "outputId": "532aec7a-b0bc-4f97-d56d-80ee53135a25"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Veamos cuáles son las 100 palabras más comunes en el campo de descripción de propiedades:"
   ],
   "metadata": {
    "id": "t4hiRECrz3Wa"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "[('de', 857976),\n ('y', 507778),\n ('con', 401867),\n ('la', 290195),\n ('en', 278176),\n ('a', 243751),\n ('el', 169952),\n ('del', 153279),\n ('que', 140055),\n ('por', 133635),\n ('al', 125215),\n ('-', 113875),\n ('un', 103716),\n ('las', 90713),\n ('los', 88435),\n ('para', 88190),\n ('se', 63109),\n ('DE', 56457),\n ('son', 56420),\n ('2', 52790),\n ('es', 50384),\n ('una', 48927),\n ('3', 41258),\n ('cocina', 38889),\n ('ambientes', 38848),\n ('valor', 38420),\n ('esta', 38292),\n ('muy', 36893),\n ('x', 36800),\n ('Av.', 36630),\n ('comedor', 35535),\n ('baño', 35476),\n ('Y', 34141),\n ('CON', 33915),\n ('no', 33912),\n ('piso', 33348),\n ('o', 33050),\n ('/', 32253),\n ('tu', 32101),\n ('A', 32063),\n ('hasta', 30269),\n ('balcón', 29805),\n ('inmueble', 28725),\n ('casa', 28655),\n ('No', 28635),\n ('propiedad.', 28070),\n ('30%', 27684),\n ('departamento', 27670),\n ('EN', 27267),\n ('cuadras', 27069),\n ('Corredor', 26991),\n ('préstamo', 26920),\n ('cuota', 26780),\n ('medidas', 26422),\n ('Responsable:', 25970),\n ('living', 25952),\n ('4', 25848),\n ('Lendar', 25571),\n ('querés!', 25421),\n ('podés.', 25362),\n ('Accedé', 25354),\n ('Simulá', 25349),\n ('#', 25248),\n ('ID', 25231),\n ('MLS', 25227),\n ('CUCICBA', 24648),\n ('El', 24541),\n ('edificio', 24305),\n ('dos', 24304),\n ('cuenta', 24241),\n ('personas', 23936),\n ('completo', 23797),\n ('propiedad', 23309),\n ('salida', 23058),\n ('parte', 22277),\n (',', 22138),\n ('pisos', 21621),\n ('encuentra', 21617),\n ('frente', 21612),\n ('Las', 21073),\n ('1', 20964),\n ('amplio', 20885),\n ('Comprá', 20793),\n ('\\\\n\\\\n', 20732),\n ('vista', 19912),\n ('presente', 19511),\n ('dormitorio', 19499),\n ('Ley', 19317),\n ('gran', 19096),\n ('La', 18859),\n ('placard', 18483),\n ('espacio', 18475),\n ('metros', 18400),\n ('m2', 17976),\n ('Los', 17521),\n ('<br>', 17369),\n ('accesible', 17076),\n ('su', 16596),\n ('dormitorios', 16161),\n ('sobre', 16145)]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(\" \".join(df_descrip[\"property_description\"]).split()).most_common(100)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WpAlq6jJ2DpC",
    "outputId": "ba6d7ea0-e0b6-4446-d3e2-550d723373d2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Podemos observar que podríamos optimizar el texto mediante algunas técnicas de reducción y/o transformación. Entre otras:"
   ],
   "metadata": {
    "id": "iwnQ6tgt0MRV"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Eliminemos la etiqueta `<br>` de html:"
   ],
   "metadata": {
    "id": "qK78Ucya0Ugr"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df_descrip[\"property_description\"] = df_descrip[\"property_description\"].apply(lambda line: line.replace(\"<br>\", \" \"))\n",
    "df_test_descrip[\"property_description\"] = df_test_descrip[\"property_description\"].apply(lambda line: line.replace(\"<br>\", \" \"))"
   ],
   "metadata": {
    "id": "_o_B51Zk0hGz"
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transformemos todas las palabras a minúsculas, de modo que el contador no realice distinciones:"
   ],
   "metadata": {
    "id": "pyNp4Y520yHS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df_descrip[\"property_description\"] = df_descrip[\"property_description\"].apply(lambda line: line.lower())\n",
    "df_test_descrip[\"property_description\"] = df_test_descrip[\"property_description\"].apply(lambda line: line.lower())\n"
   ],
   "metadata": {
    "id": "VWBmcgfI04Ge"
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Quitemos los tíldes de las letras:"
   ],
   "metadata": {
    "id": "WpSPMtks1bZz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df_descrip[\"property_description\"] = df_descrip[\"property_description\"].apply(lambda line: unidecode.unidecode(line))\n",
    "df_test_descrip[\"property_description\"] = df_test_descrip[\"property_description\"].apply(lambda line: unidecode.unidecode(line))"
   ],
   "metadata": {
    "id": "KWHrTmAG1dGn"
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Eliminemos los símbolos:"
   ],
   "metadata": {
    "id": "tpUndCZy1j2X"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df_descrip[\"property_description\"] = df_descrip[\"property_description\"].apply(lambda line: re.sub(r'[^\\w]', ' ', line))\n",
    "df_test_descrip[\"property_description\"] = df_test_descrip[\"property_description\"].apply(lambda line: re.sub(r'[^\\w]', ' ', line))"
   ],
   "metadata": {
    "id": "sWcF2SIJ1lfG"
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Eliminemos los espacios múltiples entre palabras:"
   ],
   "metadata": {
    "id": "bdqDlvqN1rL1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "df_descrip[\"property_description\"] = df_descrip[\"property_description\"].apply(lambda line: re.sub(\"\\s\\s+\" , \" \", line))\n",
    "df_test_descrip[\"property_description\"] = df_test_descrip[\"property_description\"].apply(lambda line: re.sub(\"\\s\\s+\" , \" \", line))"
   ],
   "metadata": {
    "id": "uQvajcwC2DpE"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utilizando el contenido del archivo `stop_words.txt`, eliminemos palabras sin significado del datset y colocamos los cambios en uno nuevo:"
   ],
   "metadata": {
    "id": "BzcWZSJY4GPs"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "with open(stop_words) as f:\n",
    "    lines = f.read().splitlines()\n",
    "\n",
    "f = lambda x: ' '.join([item for item in x.split() if item not in lines])\n",
    "\n",
    "df_descrip[\"property_description\"] = df_descrip[\"property_description\"].apply(f)\n",
    "df_test_descrip[\"property_description\"] = df_test_descrip[\"property_description\"].apply(f)"
   ],
   "metadata": {
    "id": "FrOeCCBY2DpF"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Luego de estas transformaciones, veamos cuáles son las palabras más utilizadas:"
   ],
   "metadata": {
    "id": "JYXs-85EVQwx"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "[('cocina', 89458),\n ('2', 88203),\n ('bano', 74428),\n ('3', 74274),\n ('ambientes', 71516),\n ('balcon', 71288),\n ('comedor', 68490),\n ('piso', 67830),\n ('living', 63837),\n ('propiedad', 62558),\n ('departamento', 54476),\n ('edificio', 53422),\n ('av', 50583),\n ('1', 50142),\n ('dormitorio', 48859),\n ('completo', 48391),\n ('pisos', 46212),\n ('4', 46043),\n ('frente', 44713),\n ('expensas', 44286),\n ('n', 44023),\n ('excelente', 41314),\n ('corredor', 41145),\n ('medidas', 41046),\n ('x', 40904),\n ('inmueble', 40569),\n ('responsable', 37723),\n ('amplio', 36355),\n ('m2', 34044),\n ('30', 34027),\n ('placard', 33948),\n ('casa', 32676),\n ('dormitorios', 32257),\n ('lavadero', 31877),\n ('c', 31791),\n ('cuadras', 31165),\n ('luminoso', 30549),\n ('cucicba', 30414),\n ('accede', 29382),\n ('terraza', 29328),\n ('ley', 27849),\n ('aire', 27700),\n ('lendar', 27449),\n ('queres', 27416),\n ('prestamo', 27366),\n ('vista', 26980),\n ('venta', 26867),\n ('cuota', 26856),\n ('podes', 26580),\n ('salida', 26111),\n ('ubicacion', 25546),\n ('simula', 25536),\n ('id', 25235),\n ('cochera', 25233),\n ('mls', 25230),\n ('personas', 24976),\n ('espacio', 24793),\n ('5', 24267),\n ('planta', 23607),\n ('zona', 23396),\n ('compra', 23246),\n ('metros', 23075),\n ('independiente', 23073),\n ('inmobiliario', 22866),\n ('patio', 22294),\n ('servicio', 22214),\n ('principal', 21845),\n ('barrio', 21305),\n ('ubicado', 21087),\n ('linea', 20909),\n ('parrilla', 20747),\n ('mesada', 20701),\n ('suite', 20635),\n ('toilette', 20555),\n ('acceso', 20485),\n ('presente', 19926),\n ('servicios', 19773),\n ('accesible', 19275),\n ('subte', 18715),\n ('unidades', 18413),\n ('agua', 18371),\n ('mas', 18246),\n ('acondicionado', 18043),\n ('hall', 17969),\n ('b', 17717),\n ('operacion', 17568),\n ('aviso', 17401),\n ('unidad', 16996),\n ('24', 16901),\n ('comercial', 16525),\n ('madera', 16499),\n ('doble', 16416),\n ('propietario', 16374),\n ('calefaccion', 16297),\n ('calidad', 16139),\n ('entrada', 15982),\n ('discapacidades', 15931),\n ('informacion', 15902),\n ('estacion', 15816),\n ('operaciones', 15668)]"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(\" \".join(df_descrip[\"property_description\"]).split()).most_common(100)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FNYcv0DM2DpG",
    "outputId": "eed3ff96-3911-4d2a-a042-969e76b82e01"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Seleccionemos los aspectos que nos parecen relevantes, para luego buscar sus posibles valores.\n",
    "\n",
    "Para esto, elegimos: `cocina`, `pisos`, `calefaccion`, `expensas`, `lavadero`, `balcon`, `cochera` y `aire` y limpiamos cualquier tipo de formato restante en el dataset:"
   ],
   "metadata": {
    "collapsed": false,
    "id": "Ai_Odw_x2DpG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "aspectos = ['cocina', 'pisos', 'calefaccion', 'expensas', 'lavadero', 'balcon', 'cochera', 'aire']"
   ],
   "metadata": {
    "id": "BkHpD1gtB7e_"
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "for word in aspectos:\n",
    "    df_descrip[word] = df_descrip[\"property_description\"].apply(lambda line: format_aspects(line, word))\n",
    "    df_test_descrip[word] = df_test_descrip[\"property_description\"].apply(lambda line: format_aspects(line, word))"
   ],
   "metadata": {
    "id": "AnaswxtR2DpH"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Veamos cuáles son las 15 palabras más comunes para cada uno de los aspectos elegidos:"
   ],
   "metadata": {
    "id": "EDsk7Bjgx116"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "cant_val_aspectos = 15"
   ],
   "metadata": {
    "id": "eYdLqsvGyNcj"
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Aspecto `cocina`\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "wWJKdB85y1l0"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "[('cocina', 62810),\n ('comedor', 19198),\n ('integrada', 11530),\n ('living', 9979),\n ('bano', 8949),\n ('lavadero', 6978),\n ('balcon', 6225),\n ('independiente', 6077),\n ('completo', 5385),\n ('diario', 4992),\n ('muebles', 4829),\n ('separada', 4746),\n ('amplia', 4518),\n ('toilette', 3963),\n ('completa', 3692)]"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(\" \".join(df_descrip[\"cocina\"]).split()).most_common(cant_val_aspectos)"
   ],
   "metadata": {
    "id": "l-7v9FP82DpH",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6bea24da-1ae1-4df4-eb9a-5fddb082398b"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para `cocina`, los valores podrían ser: \n",
    "- integrada\n",
    "- lavadero\n",
    "- completa"
   ],
   "metadata": {
    "collapsed": false,
    "id": "6ACLlV0F2DpI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Aspecto `pisos`"
   ],
   "metadata": {
    "id": "1XQ4TVyUzSqc"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "[('pisos', 31829),\n ('parquet', 6394),\n ('madera', 4426),\n ('porcelanato', 4025),\n ('living', 3671),\n ('edificio', 3624),\n ('comedor', 3155),\n ('unidades', 1821),\n ('cocina', 1754),\n ('departamentos', 1662),\n ('bano', 1576),\n ('2', 1411),\n ('4', 1314),\n ('3', 1241),\n ('ambientes', 1201)]"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(\" \".join(df_descrip[\"pisos\"]).split()).most_common(cant_val_aspectos)"
   ],
   "metadata": {
    "id": "UQQMsrnL2DpI",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a261ec0d-9cd6-4277-98b0-7b18d0b28211"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para `pisos`, los valores podrían ser: \n",
    "- porcelanato\n",
    "- parquet\n",
    "- madera"
   ],
   "metadata": {
    "collapsed": false,
    "id": "l39ZahiN2DpJ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Aspecto `calefaccion`"
   ],
   "metadata": {
    "id": "a4pG3YbW1wnt"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "[('calefaccion', 15449),\n ('radiante', 4448),\n ('losa', 3916),\n ('central', 3444),\n ('caliente', 2653),\n ('agua', 2257),\n ('radiadores', 2052),\n ('individual', 1921),\n ('aire', 1777),\n ('piso', 1527),\n ('caldera', 1246),\n ('tiro', 1197),\n ('acondicionado', 1097),\n ('servicios', 1056),\n ('ambientes', 798)]"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(\" \".join(df_descrip[\"calefaccion\"]).split()).most_common(cant_val_aspectos)"
   ],
   "metadata": {
    "id": "RPZApHfA2DpJ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "67f4d899-74cf-4d93-ea99-c89946b6f262"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para `calefaccion`, los valores podrían ser: \n",
    "- radiadores\n",
    "- radiante\n",
    "- central\n",
    "- individual"
   ],
   "metadata": {
    "collapsed": false,
    "id": "Mt-7dfsl2DpK"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Aspecto `expensas`"
   ],
   "metadata": {
    "id": "XfzRZc861ysa"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "[('expensas', 35164),\n ('servicios', 6846),\n ('impuestos', 5906),\n ('valores', 5559),\n ('bajas', 4879),\n ('funcionales', 4365),\n ('000', 3296),\n ('abl', 2445),\n ('medidas', 1959),\n ('aysa', 1606),\n ('sujetos', 1542),\n ('propiedad', 1276),\n ('superficies', 1260),\n ('indicados', 1242),\n ('consignadas', 1189),\n ('2021', 1147),\n ('tasas', 1143),\n ('mensuales', 1138),\n ('consignado', 1084),\n ('gastos', 1053),\n ('presente', 1046),\n ('ambientes', 1044),\n ('sujeto', 947),\n ('500', 942),\n ('edificio', 915),\n ('aprox', 867),\n ('4', 836),\n ('incluyen', 829),\n ('2', 819),\n ('3', 806)]"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(\" \".join(df_descrip[\"expensas\"]).split()).most_common(cant_val_aspectos*2)"
   ],
   "metadata": {
    "id": "iRKPdGhA2DpK",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e89ec902-f5d3-45e5-df24-45d796fd889b"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para `expensas`, los valores podrían ser: \n",
    "- servicios\n",
    "- impuestos \n",
    "- bajas"
   ],
   "metadata": {
    "collapsed": false,
    "id": "C7EiojY82DpK"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Aspecto `lavadero`"
   ],
   "metadata": {
    "id": "ZVVvuLxu11U0"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "[('lavadero', 28549),\n ('independiente', 7972),\n ('cocina', 7923),\n ('comedor', 4376),\n ('bano', 4342),\n ('diario', 3175),\n ('servicio', 2922),\n ('dependencia', 2920),\n ('incorporado', 2506),\n ('completo', 2102),\n ('patio', 1882),\n ('separado', 1807),\n ('balcon', 1738),\n ('espacio', 1736),\n ('toilette', 1385)]"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(\" \".join(df_descrip[\"lavadero\"]).split()).most_common(cant_val_aspectos)"
   ],
   "metadata": {
    "id": "sAzBKC5c2DpK",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c811e281-914c-4804-fe87-064ada17a12d"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para `lavadero`, los valores podrían ser: \n",
    "- independiente\n",
    "- cocina\n",
    "- comedor"
   ],
   "metadata": {
    "collapsed": false,
    "id": "i8zxU-Co2DpL"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Aspecto `balcon`"
   ],
   "metadata": {
    "id": "0opxhwgx122i"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "[('balcon', 42917),\n ('salida', 9996),\n ('frente', 9711),\n ('comedor', 8052),\n ('ambientes', 6387),\n ('corrido', 6126),\n ('cocina', 4569),\n ('living', 4207),\n ('vista', 4051),\n ('amplio', 3716),\n ('terraza', 3682),\n ('aterrazado', 3172),\n ('2', 3151),\n ('luminoso', 2855),\n ('3', 2684)]"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(\" \".join(df_descrip[\"balcon\"]).split()).most_common(cant_val_aspectos)"
   ],
   "metadata": {
    "id": "geCmhGct2DpL",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7f9103b9-03aa-4035-dd78-c3a1c435e833"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para `balcon`, los valores podrían ser: \n",
    "- frente\n",
    "- amplio \n",
    "- terraza \n",
    "- salida \n",
    "- corrido\n",
    "- luminoso"
   ],
   "metadata": {
    "collapsed": false,
    "id": "GUiM00PQ2DpL"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Aspecto `cochera`"
   ],
   "metadata": {
    "id": "W05qxE7f138s"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "[('cochera', 17208),\n ('cocheras', 7359),\n ('fija', 4756),\n ('cubierta', 4118),\n ('ambientes', 3484),\n ('baulera', 2863),\n ('2', 2467),\n ('edificio', 2119),\n ('balcon', 1521),\n ('3', 1399),\n ('opcional', 1307),\n ('1', 1132),\n ('fijas', 1080),\n ('terraza', 1007),\n ('dependencia', 979),\n ('posibilidad', 958),\n ('piso', 826),\n ('frente', 780),\n ('bano', 760),\n ('disponibles', 759),\n ('departamento', 759),\n ('4', 753),\n ('servicio', 729),\n ('planta', 701),\n ('parrilla', 699),\n ('espacio', 615),\n ('subsuelo', 598),\n ('amenities', 586),\n ('completo', 553),\n ('patio', 525)]"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(\" \".join(df_descrip[\"cochera\"]).split()).most_common(cant_val_aspectos*2)"
   ],
   "metadata": {
    "id": "vF7x7sFV2DpL",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "aa1e9494-2db9-48dd-8101-5987d80ccb55"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para `cochera`, los valores podrían ser: \n",
    "- fija\n",
    "- cubierta"
   ],
   "metadata": {
    "collapsed": false,
    "id": "_sGYjhjF2DpM"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Aspecto `aire`"
   ],
   "metadata": {
    "id": "ehAh9leY2Lfu"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "[('aire', 20578),\n ('acondicionado', 14337),\n ('frio', 5985),\n ('aires', 5809),\n ('split', 2204),\n ('ciudad', 2020),\n ('acondicionados', 1961),\n ('luz', 1851),\n ('equipos', 1585),\n ('calefaccion', 1493),\n ('instalacion', 1413),\n ('ambientes', 1411),\n ('living', 1138),\n ('central', 1062),\n ('balcon', 1002)]"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(\" \".join(df_descrip[\"aire\"]).split()).most_common(cant_val_aspectos)"
   ],
   "metadata": {
    "id": "eQlqeMRa2DpM",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "fa0a82b5-9f5b-4ab4-80b7-f0090e746727"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para `aire`, posibles valores son: \n",
    "- split \n",
    "- central \n",
    "- acondicionado"
   ],
   "metadata": {
    "collapsed": false,
    "id": "9hWHT90P2DpM"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Consolidación de valores"
   ],
   "metadata": {
    "id": "fF4R61si2RJI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A continuación creamos la variable `values`, que contiene los posibles valores para cada uno de los aspectos elegidos:"
   ],
   "metadata": {
    "collapsed": false,
    "id": "ZTu9pPYV2DpN"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "values_cocina = ['integrada' , 'lavadero' , 'completa']\n",
    "values_pisos = ['porcelanato' , 'parquet' , 'madera']\n",
    "values_calefaccion = ['radiadores' , 'radiante' , 'central' , 'individual']\n",
    "values_expensas = ['serviocios' , 'impuestos' , 'bajas']\n",
    "values_lavadero = ['independiente' , 'cocina' , 'comedor']\n",
    "values_balcon = ['frente' , 'amplio' , 'terraza' , 'salida' , 'corrido' , 'luminoso']\n",
    "values_cochera = ['fija' , 'cubierta']\n",
    "values_aire = ['split' , 'central' , 'acondicionado']"
   ],
   "metadata": {
    "id": "8woiCcO32DpN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "values = [values_cocina, values_pisos, values_calefaccion, values_expensas, values_lavadero, values_balcon, values_cochera, values_aire]"
   ],
   "metadata": {
    "id": "CFU_0j0EGUE5"
   },
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "En primer lugar, creamos un dataset auxiliar que tenga los IDs y las columnas de los aspectos:"
   ],
   "metadata": {
    "collapsed": false,
    "id": "B9JpAzOi2DpN"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "aux_df = df_descrip.copy()\n",
    "aux_df_test = df_test_descrip.copy()\n",
    "\n",
    "aux_df.drop('property_description', inplace=True, axis=1)\n",
    "aux_df_test.drop('property_description', inplace=True, axis=1)"
   ],
   "metadata": {
    "id": "Z617kPUE2DpN"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Luego creamos una función a la que -pasándole un dataset, los aspectos y el listado de valores posibles- reemplace el contenido de las columnas por los valores correspondientes."
   ],
   "metadata": {
    "collapsed": false,
    "id": "qpHzefm72DpO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Modificamos las columnas de los aspectos, para que sólo queden los valores correspondientes:"
   ],
   "metadata": {
    "collapsed": false,
    "id": "8A7lmncH2DpO"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "                          id    cocina pisos calefaccion   expensas  \\\n0   mQStJ0NPSYuW7WA/0yOYuA==                                          \n1   Gi/LqlLpBXSMH9vD5kWUcw==                                          \n2   iYU9D39208HZ55k43esCsQ==                    radiante              \n3   u8oPwCg2R/C105SlZ9nlaQ==  lavadero                                \n4   RZ744+VZFnLS5FWxmtTJ7A==                    radiante              \n5   NbzjXoT+aeAnxr2lTv1Whw==                    radiante              \n6   5lBJkaOpRzdbcOFuJ59/4A==  lavadero                                \n7   WUZ/JS1/1oszsRErSr8PJg==                                          \n8   EKIOdcAhuwcww5BfkZ+6ig==                                          \n9   QmnVieT3iXh1oktdzYLRlw==                                          \n10  hwKrPY/jtN9LHTfrBn0icQ==                                          \n11  22U4lOQGJ/V8qegwRwe8lw==                                          \n12  pcjSyDd82IYXeVAPrpXjyw==                                          \n13  GfWpjTvrEdhVibSYOUXiAA==                                          \n14  M5IUi8ASsbZEycYtMbzxdw==                                          \n15  MMvaHE4jydryetM6loC2nw==                                          \n16  8QDiKrZx64C0FxyfLsesHA==                                          \n17  70wNmuUXl6DK0PjTj/6/2A==                                          \n18  0doVMJvCbwNr0TYfUtkMQg==                              impuestos   \n19  zp/cmtmUY2AlxUYMnXBKbw==                                          \n\n         lavadero   balcon cochera           aire  \n0         comedor  terraza                         \n1                                                  \n2                  terraza                         \n3          cocina   salida                         \n4                  terraza                         \n5                  terraza                         \n6          cocina                                  \n7                                                  \n8                                                  \n9                                                  \n10                                                 \n11                                                 \n12                                                 \n13                                                 \n14                                                 \n15                                                 \n16                                                 \n17                                                 \n18                                                 \n19  independiente  terraza          acondicionado  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cocina</th>\n      <th>pisos</th>\n      <th>calefaccion</th>\n      <th>expensas</th>\n      <th>lavadero</th>\n      <th>balcon</th>\n      <th>cochera</th>\n      <th>aire</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>mQStJ0NPSYuW7WA/0yOYuA==</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>comedor</td>\n      <td>terraza</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Gi/LqlLpBXSMH9vD5kWUcw==</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>iYU9D39208HZ55k43esCsQ==</td>\n      <td></td>\n      <td></td>\n      <td>radiante</td>\n      <td></td>\n      <td></td>\n      <td>terraza</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>u8oPwCg2R/C105SlZ9nlaQ==</td>\n      <td>lavadero</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>cocina</td>\n      <td>salida</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RZ744+VZFnLS5FWxmtTJ7A==</td>\n      <td></td>\n      <td></td>\n      <td>radiante</td>\n      <td></td>\n      <td></td>\n      <td>terraza</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>NbzjXoT+aeAnxr2lTv1Whw==</td>\n      <td></td>\n      <td></td>\n      <td>radiante</td>\n      <td></td>\n      <td></td>\n      <td>terraza</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>5lBJkaOpRzdbcOFuJ59/4A==</td>\n      <td>lavadero</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>cocina</td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>WUZ/JS1/1oszsRErSr8PJg==</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>EKIOdcAhuwcww5BfkZ+6ig==</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>QmnVieT3iXh1oktdzYLRlw==</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>hwKrPY/jtN9LHTfrBn0icQ==</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>22U4lOQGJ/V8qegwRwe8lw==</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>pcjSyDd82IYXeVAPrpXjyw==</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>GfWpjTvrEdhVibSYOUXiAA==</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>M5IUi8ASsbZEycYtMbzxdw==</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>MMvaHE4jydryetM6loC2nw==</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>8QDiKrZx64C0FxyfLsesHA==</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>70wNmuUXl6DK0PjTj/6/2A==</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0doVMJvCbwNr0TYfUtkMQg==</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>impuestos</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>zp/cmtmUY2AlxUYMnXBKbw==</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>independiente</td>\n      <td>terraza</td>\n      <td></td>\n      <td>acondicionado</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limpiar_values_de_aspects(aux_df, aspectos, values)\n",
    "limpiar_values_de_aspects(aux_df_test, aspectos, values)\n",
    "aux_df.head(20)"
   ],
   "metadata": {
    "id": "WXhzGxCl2DpO",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "outputId": "3355d0c0-87e8-4707-b349-e4d9b468bfa9"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Por último hacemos el merge con el dataset original, teniendo en cuenta los IDs:"
   ],
   "metadata": {
    "collapsed": false,
    "id": "Ia2LxOLq2DpP"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "    start_date  end_date    latitud   longitud  property_rooms  \\\n0       737971    737991 -34.576973 -58.406591             7.0   \n1       737867    737868 -34.610046 -58.361382             4.0   \n2       737875    738097 -34.569770 -58.431032             4.0   \n3       738132    738182 -34.579756 -58.406144             3.0   \n4       737875    738097 -34.569770 -58.431032             4.0   \n5       737875    738097 -34.569770 -58.431032             4.0   \n6       738019    738182 -34.647545 -58.497062             5.0   \n7       737829    737871 -34.608300 -58.371200             5.0   \n8       737838    737847 -34.605406 -58.400957             1.0   \n9       737956    738048 -34.592467 -58.445158             1.0   \n10      737999    738001 -34.562379 -58.454491             3.0   \n11      737999    738001 -34.628692 -58.463322             3.0   \n12      737999    738001 -34.562379 -58.454491             3.0   \n13      737999    738001 -34.605478 -58.404722             3.0   \n14      737860    737946 -34.605862 -58.422360             3.0   \n15      737999    738002 -34.593817 -58.404138             3.0   \n16      737999    738001 -34.628692 -58.463322             3.0   \n17      737999    738001 -34.605478 -58.404722             3.0   \n18      737924    737924 -34.633013 -58.527117             2.0   \n19      737910    737918 -34.562379 -58.454491             5.0   \n\n    property_surface_total  place_l4_Agronomía  place_l4_Almagro  \\\n0                    415.0                   0                 0   \n1                    194.0                   0                 0   \n2                    260.0                   0                 0   \n3                    120.0                   0                 0   \n4                    165.0                   0                 0   \n5                    165.0                   0                 0   \n6                    132.0                   0                 0   \n7                    300.0                   0                 0   \n8                    325.0                   0                 0   \n9                    122.0                   0                 0   \n10                    50.0                   0                 0   \n11                    50.0                   0                 0   \n12                    50.0                   0                 0   \n13                    50.0                   0                 0   \n14                    50.0                   0                 1   \n15                    50.0                   0                 0   \n16                    50.0                   0                 0   \n17                    50.0                   0                 0   \n18                   240.0                   0                 0   \n19                   139.0                   0                 0   \n\n    place_l4_Balvanera  place_l4_Barracas  ...  property_type_Departamento  \\\n0                    0                  0  ...                           1   \n1                    0                  0  ...                           1   \n2                    0                  0  ...                           1   \n3                    0                  0  ...                           1   \n4                    0                  0  ...                           1   \n5                    0                  0  ...                           1   \n6                    0                  0  ...                           0   \n7                    0                  0  ...                           0   \n8                    0                  0  ...                           1   \n9                    0                  0  ...                           1   \n10                   0                  0  ...                           0   \n11                   0                  0  ...                           1   \n12                   0                  0  ...                           1   \n13                   0                  0  ...                           1   \n14                   0                  0  ...                           1   \n15                   0                  0  ...                           1   \n16                   0                  0  ...                           0   \n17                   0                  0  ...                           0   \n18                   0                  0  ...                           0   \n19                   0                  0  ...                           1   \n\n    property_type_PH    cocina  pisos  calefaccion   expensas       lavadero  \\\n0                  0                                                 comedor   \n1                  0                                                           \n2                  0                      radiante                             \n3                  0  lavadero                                        cocina   \n4                  0                      radiante                             \n5                  0                      radiante                             \n6                  1  lavadero                                        cocina   \n7                  0                                                           \n8                  0                                                           \n9                  0                                                           \n10                 1                                                           \n11                 0                                                           \n12                 0                                                           \n13                 0                                                           \n14                 0                                                           \n15                 0                                                           \n16                 1                                                           \n17                 1                                                           \n18                 0                                impuestos                  \n19                 0                                           independiente   \n\n     balcon  cochera           aire  \n0   terraza                          \n1                                    \n2   terraza                          \n3    salida                          \n4   terraza                          \n5   terraza                          \n6                                    \n7                                    \n8                                    \n9                                    \n10                                   \n11                                   \n12                                   \n13                                   \n14                                   \n15                                   \n16                                   \n17                                   \n18                                   \n19  terraza           acondicionado  \n\n[20 rows x 77 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>start_date</th>\n      <th>end_date</th>\n      <th>latitud</th>\n      <th>longitud</th>\n      <th>property_rooms</th>\n      <th>property_surface_total</th>\n      <th>place_l4_Agronomía</th>\n      <th>place_l4_Almagro</th>\n      <th>place_l4_Balvanera</th>\n      <th>place_l4_Barracas</th>\n      <th>...</th>\n      <th>property_type_Departamento</th>\n      <th>property_type_PH</th>\n      <th>cocina</th>\n      <th>pisos</th>\n      <th>calefaccion</th>\n      <th>expensas</th>\n      <th>lavadero</th>\n      <th>balcon</th>\n      <th>cochera</th>\n      <th>aire</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>737971</td>\n      <td>737991</td>\n      <td>-34.576973</td>\n      <td>-58.406591</td>\n      <td>7.0</td>\n      <td>415.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>comedor</td>\n      <td>terraza</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>737867</td>\n      <td>737868</td>\n      <td>-34.610046</td>\n      <td>-58.361382</td>\n      <td>4.0</td>\n      <td>194.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>737875</td>\n      <td>738097</td>\n      <td>-34.569770</td>\n      <td>-58.431032</td>\n      <td>4.0</td>\n      <td>260.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>radiante</td>\n      <td></td>\n      <td></td>\n      <td>terraza</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>738132</td>\n      <td>738182</td>\n      <td>-34.579756</td>\n      <td>-58.406144</td>\n      <td>3.0</td>\n      <td>120.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>lavadero</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>cocina</td>\n      <td>salida</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>737875</td>\n      <td>738097</td>\n      <td>-34.569770</td>\n      <td>-58.431032</td>\n      <td>4.0</td>\n      <td>165.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>radiante</td>\n      <td></td>\n      <td></td>\n      <td>terraza</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>737875</td>\n      <td>738097</td>\n      <td>-34.569770</td>\n      <td>-58.431032</td>\n      <td>4.0</td>\n      <td>165.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>radiante</td>\n      <td></td>\n      <td></td>\n      <td>terraza</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>738019</td>\n      <td>738182</td>\n      <td>-34.647545</td>\n      <td>-58.497062</td>\n      <td>5.0</td>\n      <td>132.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>lavadero</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>cocina</td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>737829</td>\n      <td>737871</td>\n      <td>-34.608300</td>\n      <td>-58.371200</td>\n      <td>5.0</td>\n      <td>300.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>737838</td>\n      <td>737847</td>\n      <td>-34.605406</td>\n      <td>-58.400957</td>\n      <td>1.0</td>\n      <td>325.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>737956</td>\n      <td>738048</td>\n      <td>-34.592467</td>\n      <td>-58.445158</td>\n      <td>1.0</td>\n      <td>122.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>737999</td>\n      <td>738001</td>\n      <td>-34.562379</td>\n      <td>-58.454491</td>\n      <td>3.0</td>\n      <td>50.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>737999</td>\n      <td>738001</td>\n      <td>-34.628692</td>\n      <td>-58.463322</td>\n      <td>3.0</td>\n      <td>50.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>737999</td>\n      <td>738001</td>\n      <td>-34.562379</td>\n      <td>-58.454491</td>\n      <td>3.0</td>\n      <td>50.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>737999</td>\n      <td>738001</td>\n      <td>-34.605478</td>\n      <td>-58.404722</td>\n      <td>3.0</td>\n      <td>50.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>737860</td>\n      <td>737946</td>\n      <td>-34.605862</td>\n      <td>-58.422360</td>\n      <td>3.0</td>\n      <td>50.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>737999</td>\n      <td>738002</td>\n      <td>-34.593817</td>\n      <td>-58.404138</td>\n      <td>3.0</td>\n      <td>50.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>737999</td>\n      <td>738001</td>\n      <td>-34.628692</td>\n      <td>-58.463322</td>\n      <td>3.0</td>\n      <td>50.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>737999</td>\n      <td>738001</td>\n      <td>-34.605478</td>\n      <td>-58.404722</td>\n      <td>3.0</td>\n      <td>50.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>737924</td>\n      <td>737924</td>\n      <td>-34.633013</td>\n      <td>-58.527117</td>\n      <td>2.0</td>\n      <td>240.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>impuestos</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>737910</td>\n      <td>737918</td>\n      <td>-34.562379</td>\n      <td>-58.454491</td>\n      <td>5.0</td>\n      <td>139.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>independiente</td>\n      <td>terraza</td>\n      <td></td>\n      <td>acondicionado</td>\n    </tr>\n  </tbody>\n</table>\n<p>20 rows × 77 columns</p>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_train_x.copy()\n",
    "df = pd.merge(df,aux_df, on=\"id\")\n",
    "df.drop(\"id\", inplace=True, axis=\"columns\")\n",
    "\n",
    "df_test = df_test_x.copy()\n",
    "df_test = pd.merge(df_test,aux_df_test, on=\"id\")\n",
    "df_test.drop(\"id\", inplace=True, axis=\"columns\")\n",
    "\n",
    "df.head(20)"
   ],
   "metadata": {
    "id": "I2x-X60t2DpP",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 914
    },
    "outputId": "9aa74e5a-0b67-4010-a31b-a2f67689e136"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exportación de Datos"
   ],
   "metadata": {
    "id": "rN3FutIEHrf2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Exportamos los datasets generados:"
   ],
   "metadata": {
    "id": "xd-CoUsZHtL9"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "if IN_COLAB:\n",
    "  path = '/content/drive/MyDrive/📔 Organización de Datos (75.06)/TPS/TP2/DATASETS/1a_df_descrip.csv'\n",
    "else:\n",
    "  path = 'DATASETS/1a_df_descrip.csv'\n",
    "\n",
    "df_descrip.to_csv(path)"
   ],
   "metadata": {
    "id": "qr1jlB8QH16Z"
   },
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if IN_COLAB:\n",
    "  path = '/content/drive/MyDrive/📔 Organización de Datos (75.06)/TPS/TP2/DATASETS/1a_df_ampliado.csv'\n",
    "else:\n",
    "  path = 'DATASETS/1a_df_ampliado.csv'\n",
    "\n",
    "df.to_csv(path)"
   ],
   "metadata": {
    "id": "QTsLoqr-IHOX"
   },
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.b Modelos\n",
    "___"
   ],
   "metadata": {
    "collapsed": false,
    "id": "fI1Fi95S2DpP"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Sin optimización de hiperparámetros"
   ],
   "metadata": {
    "id": "ldOrNGnEaE5H"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Entrenemos un modelo de XGBoost con los mismos hiperparámetros utilizados en el TP1."
   ],
   "metadata": {
    "id": "a2X0YkeUUL1X"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Realizamos One Hot Encoding para las nuevas variables cualitativas:"
   ],
   "metadata": {
    "collapsed": false,
    "id": "WqUMr9_r2DpQ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "   start_date  end_date    latitud   longitud  property_rooms  \\\n0      737971    737991 -34.576973 -58.406591             7.0   \n1      737867    737868 -34.610046 -58.361382             4.0   \n2      737875    738097 -34.569770 -58.431032             4.0   \n3      738132    738182 -34.579756 -58.406144             3.0   \n4      737875    738097 -34.569770 -58.431032             4.0   \n\n   property_surface_total  place_l4_Agronomía  place_l4_Almagro  \\\n0                   415.0                   0                 0   \n1                   194.0                   0                 0   \n2                   260.0                   0                 0   \n3                   120.0                   0                 0   \n4                   165.0                   0                 0   \n\n   place_l4_Balvanera  place_l4_Barracas  ...  balcon_corrido  balcon_frente  \\\n0                   0                  0  ...               0              0   \n1                   0                  0  ...               0              0   \n2                   0                  0  ...               0              0   \n3                   0                  0  ...               0              0   \n4                   0                  0  ...               0              0   \n\n   balcon_luminoso  balcon_salida  balcon_terraza  cochera_cubierta  \\\n0                0              0               1                 0   \n1                0              0               0                 0   \n2                0              0               1                 0   \n3                0              1               0                 0   \n4                0              0               1                 0   \n\n   cochera_fija  aire_acondicionado  aire_central  aire_split  \n0             0                   0             0           0  \n1             0                   0             0           0  \n2             0                   0             0           0  \n3             0                   0             0           0  \n4             0                   0             0           0  \n\n[5 rows x 95 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>start_date</th>\n      <th>end_date</th>\n      <th>latitud</th>\n      <th>longitud</th>\n      <th>property_rooms</th>\n      <th>property_surface_total</th>\n      <th>place_l4_Agronomía</th>\n      <th>place_l4_Almagro</th>\n      <th>place_l4_Balvanera</th>\n      <th>place_l4_Barracas</th>\n      <th>...</th>\n      <th>balcon_corrido</th>\n      <th>balcon_frente</th>\n      <th>balcon_luminoso</th>\n      <th>balcon_salida</th>\n      <th>balcon_terraza</th>\n      <th>cochera_cubierta</th>\n      <th>cochera_fija</th>\n      <th>aire_acondicionado</th>\n      <th>aire_central</th>\n      <th>aire_split</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>737971</td>\n      <td>737991</td>\n      <td>-34.576973</td>\n      <td>-58.406591</td>\n      <td>7.0</td>\n      <td>415.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>737867</td>\n      <td>737868</td>\n      <td>-34.610046</td>\n      <td>-58.361382</td>\n      <td>4.0</td>\n      <td>194.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>737875</td>\n      <td>738097</td>\n      <td>-34.569770</td>\n      <td>-58.431032</td>\n      <td>4.0</td>\n      <td>260.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>738132</td>\n      <td>738182</td>\n      <td>-34.579756</td>\n      <td>-58.406144</td>\n      <td>3.0</td>\n      <td>120.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>737875</td>\n      <td>738097</td>\n      <td>-34.569770</td>\n      <td>-58.431032</td>\n      <td>4.0</td>\n      <td>165.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 95 columns</p>\n</div>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummies = pd.get_dummies(df, columns=['cocina', 'pisos', 'lavadero', 'calefaccion', 'expensas', 'balcon', 'cochera', 'aire'], drop_first=True)\n",
    "df_test_dummies = pd.get_dummies(df_test, columns=['cocina', 'pisos', 'lavadero', 'calefaccion', 'expensas', 'balcon', 'cochera', 'aire'], drop_first=True)\n",
    "df_dummies.head(5)"
   ],
   "metadata": {
    "id": "5e0r2Yj-2DpQ",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "outputId": "9345f93a-6a15-48ed-ebd9-8004cb87637f"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "       start_date  end_date    latitud   longitud  property_rooms  \\\n0          737971    737991 -34.576973 -58.406591             7.0   \n1          737867    737868 -34.610046 -58.361382             4.0   \n2          737875    738097 -34.569770 -58.431032             4.0   \n3          738132    738182 -34.579756 -58.406144             3.0   \n4          737875    738097 -34.569770 -58.431032             4.0   \n...           ...       ...        ...        ...             ...   \n74246      737802    737946 -34.572157 -58.494807             3.0   \n74247      737797    737946 -34.583718 -58.484141             4.0   \n74248      737802    737946 -34.572512 -58.478717             5.0   \n74249      737802    737946 -34.572512 -58.478717             5.0   \n74250      737802    737946 -34.572512 -58.478717             5.0   \n\n       property_surface_total  place_l4_Agronomía  place_l4_Almagro  \\\n0                       415.0                   0                 0   \n1                       194.0                   0                 0   \n2                       260.0                   0                 0   \n3                       120.0                   0                 0   \n4                       165.0                   0                 0   \n...                       ...                 ...               ...   \n74246                     1.0                   0                 0   \n74247                     1.0                   0                 0   \n74248                     1.0                   0                 0   \n74249                     1.0                   0                 0   \n74250                     1.0                   0                 0   \n\n       place_l4_Balvanera  place_l4_Barracas  ...  balcon_corrido  \\\n0                       0                  0  ...               0   \n1                       0                  0  ...               0   \n2                       0                  0  ...               0   \n3                       0                  0  ...               0   \n4                       0                  0  ...               0   \n...                   ...                ...  ...             ...   \n74246                   0                  0  ...               0   \n74247                   0                  0  ...               0   \n74248                   0                  0  ...               0   \n74249                   0                  0  ...               0   \n74250                   0                  0  ...               0   \n\n       balcon_frente  balcon_luminoso  balcon_salida  balcon_terraza  \\\n0                  0                0              0               1   \n1                  0                0              0               0   \n2                  0                0              0               1   \n3                  0                0              1               0   \n4                  0                0              0               1   \n...              ...              ...            ...             ...   \n74246              1                0              0               0   \n74247              0                0              0               0   \n74248              0                0              0               0   \n74249              0                0              0               0   \n74250              0                0              0               0   \n\n       cochera_cubierta  cochera_fija  aire_acondicionado  aire_central  \\\n0                     0             0                   0             0   \n1                     0             0                   0             0   \n2                     0             0                   0             0   \n3                     0             0                   0             0   \n4                     0             0                   0             0   \n...                 ...           ...                 ...           ...   \n74246                 1             0                   0             0   \n74247                 0             0                   0             0   \n74248                 0             1                   0             0   \n74249                 0             1                   0             0   \n74250                 0             1                   0             0   \n\n       aire_split  \n0               0  \n1               0  \n2               0  \n3               0  \n4               0  \n...           ...  \n74246           0  \n74247           0  \n74248           0  \n74249           0  \n74250           0  \n\n[74251 rows x 95 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>start_date</th>\n      <th>end_date</th>\n      <th>latitud</th>\n      <th>longitud</th>\n      <th>property_rooms</th>\n      <th>property_surface_total</th>\n      <th>place_l4_Agronomía</th>\n      <th>place_l4_Almagro</th>\n      <th>place_l4_Balvanera</th>\n      <th>place_l4_Barracas</th>\n      <th>...</th>\n      <th>balcon_corrido</th>\n      <th>balcon_frente</th>\n      <th>balcon_luminoso</th>\n      <th>balcon_salida</th>\n      <th>balcon_terraza</th>\n      <th>cochera_cubierta</th>\n      <th>cochera_fija</th>\n      <th>aire_acondicionado</th>\n      <th>aire_central</th>\n      <th>aire_split</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>737971</td>\n      <td>737991</td>\n      <td>-34.576973</td>\n      <td>-58.406591</td>\n      <td>7.0</td>\n      <td>415.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>737867</td>\n      <td>737868</td>\n      <td>-34.610046</td>\n      <td>-58.361382</td>\n      <td>4.0</td>\n      <td>194.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>737875</td>\n      <td>738097</td>\n      <td>-34.569770</td>\n      <td>-58.431032</td>\n      <td>4.0</td>\n      <td>260.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>738132</td>\n      <td>738182</td>\n      <td>-34.579756</td>\n      <td>-58.406144</td>\n      <td>3.0</td>\n      <td>120.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>737875</td>\n      <td>738097</td>\n      <td>-34.569770</td>\n      <td>-58.431032</td>\n      <td>4.0</td>\n      <td>165.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>74246</th>\n      <td>737802</td>\n      <td>737946</td>\n      <td>-34.572157</td>\n      <td>-58.494807</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>74247</th>\n      <td>737797</td>\n      <td>737946</td>\n      <td>-34.583718</td>\n      <td>-58.484141</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>74248</th>\n      <td>737802</td>\n      <td>737946</td>\n      <td>-34.572512</td>\n      <td>-58.478717</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>74249</th>\n      <td>737802</td>\n      <td>737946</td>\n      <td>-34.572512</td>\n      <td>-58.478717</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>74250</th>\n      <td>737802</td>\n      <td>737946</td>\n      <td>-34.572512</td>\n      <td>-58.478717</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>74251 rows × 95 columns</p>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Entrenamos el modelo:"
   ],
   "metadata": {
    "id": "I6cp1CI3ZKLx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df_test_dummies"
   ],
   "metadata": {
    "id": "kQ5AadFSfxhE",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "044f7dba-5555-4d62-b84e-494ca9febd99"
   },
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "       start_date  end_date    latitud   longitud  property_rooms  \\\n0          738042    738059 -34.629398 -58.425852             2.0   \n1          738042    738052 -34.620748 -58.412004             3.0   \n2          738042    738059 -34.626595 -58.420019             4.0   \n3          738042    738182 -34.627566 -58.411937             4.0   \n4          738042    738043 -34.625298 -58.459998             3.0   \n...           ...       ...        ...        ...             ...   \n18600      737795    738416 -34.585935 -58.475726             2.0   \n18601      737795    737965 -34.571806 -58.479139             1.0   \n18602      737795    737798 -34.572312 -58.480049             3.0   \n18603      737795    738416 -34.629440 -58.442729             2.0   \n18604      737795    738098 -34.636285 -58.400321             3.0   \n\n       property_surface_total  place_l4_Agronomía  place_l4_Almagro  \\\n0                        62.0                   0                 0   \n1                        59.0                   0                 0   \n2                       111.0                   0                 0   \n3                       100.0                   0                 0   \n4                        57.0                   0                 0   \n...                       ...                 ...               ...   \n18600                    44.0                   0                 0   \n18601                    38.0                   0                 0   \n18602                    69.0                   0                 0   \n18603                    63.0                   0                 0   \n18604                    66.0                   0                 0   \n\n       place_l4_Balvanera  place_l4_Barracas  ...  balcon_corrido  \\\n0                       0                  0  ...               0   \n1                       0                  0  ...               0   \n2                       0                  0  ...               0   \n3                       0                  0  ...               0   \n4                       0                  0  ...               0   \n...                   ...                ...  ...             ...   \n18600                   0                  0  ...               0   \n18601                   0                  0  ...               0   \n18602                   0                  0  ...               0   \n18603                   0                  0  ...               0   \n18604                   0                  0  ...               0   \n\n       balcon_frente  balcon_luminoso  balcon_salida  balcon_terraza  \\\n0                  1                0              0               0   \n1                  0                0              1               0   \n2                  0                0              0               0   \n3                  0                0              0               0   \n4                  0                1              0               0   \n...              ...              ...            ...             ...   \n18600              1                0              0               0   \n18601              0                0              0               0   \n18602              1                0              0               0   \n18603              0                0              0               0   \n18604              0                0              0               0   \n\n       cochera_cubierta  cochera_fija  aire_acondicionado  aire_central  \\\n0                     0             0                   1             0   \n1                     0             1                   0             0   \n2                     0             0                   0             0   \n3                     0             0                   0             0   \n4                     0             0                   0             0   \n...                 ...           ...                 ...           ...   \n18600                 0             0                   0             0   \n18601                 0             0                   1             0   \n18602                 0             0                   1             0   \n18603                 0             0                   0             0   \n18604                 0             0                   1             0   \n\n       aire_split  \n0               0  \n1               0  \n2               0  \n3               0  \n4               0  \n...           ...  \n18600           0  \n18601           0  \n18602           0  \n18603           0  \n18604           0  \n\n[18605 rows x 95 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>start_date</th>\n      <th>end_date</th>\n      <th>latitud</th>\n      <th>longitud</th>\n      <th>property_rooms</th>\n      <th>property_surface_total</th>\n      <th>place_l4_Agronomía</th>\n      <th>place_l4_Almagro</th>\n      <th>place_l4_Balvanera</th>\n      <th>place_l4_Barracas</th>\n      <th>...</th>\n      <th>balcon_corrido</th>\n      <th>balcon_frente</th>\n      <th>balcon_luminoso</th>\n      <th>balcon_salida</th>\n      <th>balcon_terraza</th>\n      <th>cochera_cubierta</th>\n      <th>cochera_fija</th>\n      <th>aire_acondicionado</th>\n      <th>aire_central</th>\n      <th>aire_split</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>738042</td>\n      <td>738059</td>\n      <td>-34.629398</td>\n      <td>-58.425852</td>\n      <td>2.0</td>\n      <td>62.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>738042</td>\n      <td>738052</td>\n      <td>-34.620748</td>\n      <td>-58.412004</td>\n      <td>3.0</td>\n      <td>59.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>738042</td>\n      <td>738059</td>\n      <td>-34.626595</td>\n      <td>-58.420019</td>\n      <td>4.0</td>\n      <td>111.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>738042</td>\n      <td>738182</td>\n      <td>-34.627566</td>\n      <td>-58.411937</td>\n      <td>4.0</td>\n      <td>100.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>738042</td>\n      <td>738043</td>\n      <td>-34.625298</td>\n      <td>-58.459998</td>\n      <td>3.0</td>\n      <td>57.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>18600</th>\n      <td>737795</td>\n      <td>738416</td>\n      <td>-34.585935</td>\n      <td>-58.475726</td>\n      <td>2.0</td>\n      <td>44.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18601</th>\n      <td>737795</td>\n      <td>737965</td>\n      <td>-34.571806</td>\n      <td>-58.479139</td>\n      <td>1.0</td>\n      <td>38.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18602</th>\n      <td>737795</td>\n      <td>737798</td>\n      <td>-34.572312</td>\n      <td>-58.480049</td>\n      <td>3.0</td>\n      <td>69.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18603</th>\n      <td>737795</td>\n      <td>738416</td>\n      <td>-34.629440</td>\n      <td>-58.442729</td>\n      <td>2.0</td>\n      <td>63.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18604</th>\n      <td>737795</td>\n      <td>738098</td>\n      <td>-34.636285</td>\n      <td>-58.400321</td>\n      <td>3.0</td>\n      <td>66.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>18605 rows × 95 columns</p>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=0.3, enable_categorical=False,\n             gamma=0.1, gpu_id=-1, importance_type=None,\n             interaction_constraints='', learning_rate=0.3, max_delta_step=0,\n             max_depth=6, min_child_weight=5, missing=nan,\n             monotone_constraints='()', n_estimators=100, n_jobs=4,\n             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n             validate_parameters=1, verbosity=None)",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=0.3, enable_categorical=False,\n             gamma=0.1, gpu_id=-1, importance_type=None,\n             interaction_constraints=&#x27;&#x27;, learning_rate=0.3, max_delta_step=0,\n             max_depth=6, min_child_weight=5, missing=nan,\n             monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=4,\n             num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0,\n             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=&#x27;exact&#x27;,\n             validate_parameters=1, verbosity=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=0.3, enable_categorical=False,\n             gamma=0.1, gpu_id=-1, importance_type=None,\n             interaction_constraints=&#x27;&#x27;, learning_rate=0.3, max_delta_step=0,\n             max_depth=6, min_child_weight=5, missing=nan,\n             monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=4,\n             num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0,\n             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=&#x27;exact&#x27;,\n             validate_parameters=1, verbosity=None)</pre></div></div></div></div></div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_Regressor = XGBRegressor(min_child_weight = 5, max_depth = 6, learning_rate = 0.3, gamma = 0.1, colsample_bytree = 0.3)\n",
    "XGB_Regressor.fit(df_dummies, df_train_y_regresion)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hagamos las predicciones y veamos cómo resultaron las métricas del modelo:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se obtuvo un Score de 58.018%\n",
      "El error según la métrica 'Mean Square Error' de test es: 53023059874.91771\n",
      "El error según la métrica 'Root Mean Square Error' de test es: 230267.3660658794\n"
     ]
    }
   ],
   "source": [
    "prediccion_y_metricas_regresion(XGB_Regressor,df_test_dummies, df_test_y_regresion)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Importancia de features\n",
    "Graficamos los 15 features más importantes para el modelo con los hiperparámetros del TP1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0.5, 0, 'Xgboost Feature Importance')"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_idx = XGB_Regressor.feature_importances_.argsort()\n",
    "sorted_idx = sorted_idx[-15:]\n",
    "plt.barh(df_test_dummies.columns[sorted_idx], XGB_Regressor.feature_importances_[sorted_idx])\n",
    "plt.xlabel(\"Xgboost Feature Importance\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Podemos observar que el feature más importante es la ubicación en Puerto Madero, seguido de cantidad de habitaciones y ubicación en Palermo Chico."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Con optimización de hiperparámetros"
   ],
   "metadata": {
    "id": "CkJCoGXnaN1y"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Veamos cómo se comporta el score con la optimización de hiperparámetros:"
   ],
   "metadata": {
    "collapsed": false,
    "id": "Su2wKojB2DpR"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n                   estimator=XGBRegressor(base_score=None, booster=None,\n                                          colsample_bylevel=None,\n                                          colsample_bynode=None,\n                                          colsample_bytree=None,\n                                          enable_categorical=False, gamma=None,\n                                          gpu_id=None, importance_type=None,\n                                          interaction_constraints=None,\n                                          learning_rate=None,\n                                          max_delta_step=None, max_depth=No...\n                                          predictor=None, random_state=None,\n                                          reg_alpha=None, reg_lambda=None,\n                                          scale_pos_weight=None, subsample=None,\n                                          tree_method=None,\n                                          validate_parameters=None,\n                                          verbosity=None),\n                   n_iter=5,\n                   param_distributions={'colsample_bytree': [0.3, 0.4, 0.5, 0.7,\n                                                             0.8],\n                                        'gamma': [0.1, 0.2, 0.3, 0.4, 0.5],\n                                        'learning_rate': [0.2, 0.25, 0.3],\n                                        'max_depth': [4, 5, 6, 8, 10],\n                                        'min_child_weight': [1, 3, 5, 7, 9]},\n                   scoring=make_scorer(r2_score))",
      "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n                   estimator=XGBRegressor(base_score=None, booster=None,\n                                          colsample_bylevel=None,\n                                          colsample_bynode=None,\n                                          colsample_bytree=None,\n                                          enable_categorical=False, gamma=None,\n                                          gpu_id=None, importance_type=None,\n                                          interaction_constraints=None,\n                                          learning_rate=None,\n                                          max_delta_step=None, max_depth=No...\n                                          predictor=None, random_state=None,\n                                          reg_alpha=None, reg_lambda=None,\n                                          scale_pos_weight=None, subsample=None,\n                                          tree_method=None,\n                                          validate_parameters=None,\n                                          verbosity=None),\n                   n_iter=5,\n                   param_distributions={&#x27;colsample_bytree&#x27;: [0.3, 0.4, 0.5, 0.7,\n                                                             0.8],\n                                        &#x27;gamma&#x27;: [0.1, 0.2, 0.3, 0.4, 0.5],\n                                        &#x27;learning_rate&#x27;: [0.2, 0.25, 0.3],\n                                        &#x27;max_depth&#x27;: [4, 5, 6, 8, 10],\n                                        &#x27;min_child_weight&#x27;: [1, 3, 5, 7, 9]},\n                   scoring=make_scorer(r2_score))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n                   estimator=XGBRegressor(base_score=None, booster=None,\n                                          colsample_bylevel=None,\n                                          colsample_bynode=None,\n                                          colsample_bytree=None,\n                                          enable_categorical=False, gamma=None,\n                                          gpu_id=None, importance_type=None,\n                                          interaction_constraints=None,\n                                          learning_rate=None,\n                                          max_delta_step=None, max_depth=No...\n                                          predictor=None, random_state=None,\n                                          reg_alpha=None, reg_lambda=None,\n                                          scale_pos_weight=None, subsample=None,\n                                          tree_method=None,\n                                          validate_parameters=None,\n                                          verbosity=None),\n                   n_iter=5,\n                   param_distributions={&#x27;colsample_bytree&#x27;: [0.3, 0.4, 0.5, 0.7,\n                                                             0.8],\n                                        &#x27;gamma&#x27;: [0.1, 0.2, 0.3, 0.4, 0.5],\n                                        &#x27;learning_rate&#x27;: [0.2, 0.25, 0.3],\n                                        &#x27;max_depth&#x27;: [4, 5, 6, 8, 10],\n                                        &#x27;min_child_weight&#x27;: [1, 3, 5, 7, 9]},\n                   scoring=make_scorer(r2_score))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n             colsample_bynode=None, colsample_bytree=None,\n             enable_categorical=False, gamma=None, gpu_id=None,\n             importance_type=None, interaction_constraints=None,\n             learning_rate=None, max_delta_step=None, max_depth=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n             predictor=None, random_state=None, reg_alpha=None, reg_lambda=None,\n             scale_pos_weight=None, subsample=None, tree_method=None,\n             validate_parameters=None, verbosity=None)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n             colsample_bynode=None, colsample_bytree=None,\n             enable_categorical=False, gamma=None, gpu_id=None,\n             importance_type=None, interaction_constraints=None,\n             learning_rate=None, max_delta_step=None, max_depth=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n             predictor=None, random_state=None, reg_alpha=None, reg_lambda=None,\n             scale_pos_weight=None, subsample=None, tree_method=None,\n             validate_parameters=None, verbosity=None)</pre></div></div></div></div></div></div></div></div></div></div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_grid = {'learning_rate': [0.20, 0.25, 0.30],\n",
    "               'max_depth': [4, 5, 6, 8, 10],\n",
    "               'min_child_weight': [1, 3, 5, 7, 9],\n",
    "               'gamma': [0.1, 0.2 , 0.3, 0.4, 0.5],\n",
    "               'colsample_bytree' : [0.3, 0.4, 0.5, 0.7, 0.8]}\n",
    "\n",
    "randomCV = RandomizedSearchCV(estimator = XGBRegressor(),\n",
    "                              param_distributions = params_grid,\n",
    "                              scoring = make_scorer(r2_score),\n",
    "                              cv = StratifiedKFold(n_splits = 5),\n",
    "                              n_iter = 5)\n",
    "\n",
    "randomCV.fit(df_dummies, df_train_y_regresion)"
   ],
   "metadata": {
    "id": "7RTpJeq92DpS",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c628a9ba-c22a-41d7-fe70-c2cac713f798"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "{'min_child_weight': 3,\n 'max_depth': 10,\n 'learning_rate': 0.25,\n 'gamma': 0.1,\n 'colsample_bytree': 0.4}"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomCV.best_params_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se obtuvo un Score de 58.795%\n",
      "El error según la métrica 'Mean Square Error' de test es: 52042540459.91041\n",
      "El error según la métrica 'Root Mean Square Error' de test es: 228128.34207943213\n"
     ]
    }
   ],
   "source": [
    "prediccion_y_metricas_regresion(randomCV.best_estimator_,df_test_dummies, df_test_y_regresion)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Observamos que, si bien las métricas mejoraron, las diferencias al optimizar los parámetros no fueron muy significativas."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Importancia de features\n",
    "Graficamos los 15 features más importantes para el modelo con los hiperparámetros optimizados"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0.5, 0, 'Xgboost Feature Importance')"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_idx = randomCV.best_estimator_.feature_importances_.argsort()\n",
    "sorted_idx = sorted_idx[-15:]\n",
    "plt.barh(df_test_dummies.columns[sorted_idx], randomCV.best_estimator_.feature_importances_[sorted_idx])\n",
    "plt.xlabel(\"Xgboost Feature Importance\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Podemos ver que la ubicación en Puerto Madero tiene aún más peso que en el modelo anterior y también como algunos de los features con los que expandimos el dataset (calefaccion_radiante y cochera_fija) toman más protagonismo, al igual que la superficie total."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exportación del Modelo\n",
    "Finalmente exportamos el modelo utilizado para predecir, resultante de la optimización de hiperparámetros:"
   ],
   "metadata": {
    "id": "_f0JxWEL8GUY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "if IN_COLAB:\n",
    "  path = '/content/drive/MyDrive/📔 Organización de Datos (75.06)/TPS/TP2/MODELOS/XGB_Regressor.json'\n",
    "else:\n",
    "  path = './MODELOS/XGB_Regressor.json'\n",
    "\n",
    "randomCV.best_estimator_.save_model(path)"
   ],
   "metadata": {
    "id": "RNVI92fe8WEP",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9e1b9542-5eec-4f40-edbc-ebf7c8cecc42"
   },
   "execution_count": 51,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Redes Neuronales"
   ],
   "metadata": {
    "collapsed": false,
    "id": "HWpWT3GZ_TQT"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.a Regresión"
   ],
   "metadata": {
    "id": "2HjJDe4W_iY-"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.a.1 Preparación del dataset"
   ],
   "metadata": {
    "id": "5xI2H0xyYm_B"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "x_train_regresion = df_train_x.drop([\"id\"], axis=1).copy()\n",
    "y_train_regresion = df_train_y_regresion.copy()\n",
    "x_test_regresion = df_test_x.drop([\"id\"], axis=1).copy()\n",
    "y_test_regresion = df_test_y_regresion.copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Normalizamos las entradas con StandardScaler:"
   ],
   "metadata": {
    "collapsed": false,
    "id": "PKPRQVFS_TQT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "estandarizar(x_train_regresion, ['start_date', 'end_date', 'latitud', 'longitud', 'property_rooms', 'property_surface_total'])\n",
    "estandarizar(x_test_regresion, ['start_date', 'end_date', 'latitud', 'longitud', 'property_rooms', 'property_surface_total'])"
   ],
   "metadata": {
    "id": "s3xTEOkRlufG"
   },
   "execution_count": 53,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.a.2 Búsqueda del mejor modelo"
   ],
   "metadata": {
    "id": "NjqmQr4pYrEE"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creo una función que me permite generar un modelo a partir de sus hiperparámetros. Esta función tiene como parámetros la cantidad de nodos de la primera y anteúltima capa, la cantidad de capas ocultas, la función de activación y el optimizador. Todos los modelos que genera a excepción de los casos sin capas ocultas) tienen forma de 'pirámide'."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "cantidad_de_columnas = x_train_regresion.shape[1]\n",
    "\n",
    "def crear_modelo(hidden_layers, first_layer_nodes, last_layer_nodes, activation_func, optimizer):\n",
    "\n",
    "    sequential = Sequential()\n",
    "    sequential.add(keras.layers.Dense(cantidad_de_columnas, input_shape=(cantidad_de_columnas,), activation=activation_func))\n",
    "\n",
    "    if hidden_layers is 0 or hidden_layers is 1:\n",
    "        decremento = 0\n",
    "    else:\n",
    "        decremento = math.ceil((first_layer_nodes - last_layer_nodes) / (hidden_layers - 1))\n",
    "\n",
    "    for i in range (0, hidden_layers):\n",
    "        nodos = first_layer_nodes - decremento * i\n",
    "        sequential.add(Dense(nodos, activation=activation_func))\n",
    "\n",
    "    sequential.add(Dense(1, activation=activation_func))\n",
    "\n",
    "    sequential.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='mse',\n",
    "        metrics=['mse', 'mean_absolute_percentage_error']\n",
    "    )\n",
    "\n",
    "    return sequential\n",
    "\n",
    "\n",
    "modelo =  KerasRegressor(build_fn=crear_modelo, verbose = False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Luego busco el mejor modelo a partir de una grilla de parámetros arbitrarios con el método de 'GridSearchCV'. El criterio de mejor modelo es el que tenga menor error cuadrado, o lo que es equivalente, mayor error cuadrado negado. Nos limitamos en la cantidad de folds en el CV por el consumo temporal."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "param_grid = dict(\n",
    "    hidden_layers=[0, 1],\n",
    "    first_layer_nodes = [math.ceil(cantidad_de_columnas * 0.7), math.ceil(cantidad_de_columnas * 0.5)],\n",
    "    last_layer_nodes = [5, cantidad_de_columnas * 0.5],\n",
    "    activation_func = ['sigmoid', 'relu', 'tanh'],\n",
    "    batch_size = [100],\n",
    "    epochs = [30],\n",
    "    optimizer=['RMSprop', 'adam'],\n",
    ")\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator = modelo,\n",
    "    param_grid = param_grid,\n",
    "    cv=5,\n",
    "    error_score='raise',\n",
    "    scoring='neg_mean_squared_error',\n",
    "    verbose=3,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Entrenamos todos los modelos"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV 1/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-29239235185.519 total time=  14.6s\n",
      "[CV 2/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-28710824056.653 total time=  14.8s\n",
      "[CV 3/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-35295350407.247 total time=  15.3s\n",
      "[CV 4/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-58568012531.976 total time=  15.0s\n",
      "[CV 5/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-404399305824.783 total time=  15.0s\n",
      "[CV 1/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-29239235185.535 total time=  14.9s\n",
      "[CV 2/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-28710824056.660 total time=  15.5s\n",
      "[CV 3/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-35295350407.260 total time=  15.8s\n",
      "[CV 4/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-58568012531.993 total time=  15.7s\n",
      "[CV 5/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-404399305824.805 total time=  15.5s\n",
      "[CV 1/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-29239235185.519 total time=  14.6s\n",
      "[CV 2/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-28710824056.653 total time=  15.3s\n",
      "[CV 3/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-35295350407.247 total time=  14.9s\n",
      "[CV 4/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-58568012531.976 total time=  15.3s\n",
      "[CV 5/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-404399305824.783 total time=  14.8s\n",
      "[CV 1/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-29239235185.527 total time=  15.3s\n",
      "[CV 2/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-28710824056.666 total time=  15.1s\n",
      "[CV 3/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-35295350407.259 total time=  16.0s\n",
      "[CV 4/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-58568012531.993 total time=  15.3s\n",
      "[CV 5/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-404399305824.810 total time=  16.0s\n",
      "[CV 1/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-29239235185.519 total time=  16.3s\n",
      "[CV 2/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-28710824056.653 total time=  16.8s\n",
      "[CV 3/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-35295350407.247 total time=  17.4s\n",
      "[CV 4/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-58568012531.976 total time=  17.4s\n",
      "[CV 5/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-404399305824.783 total time=  16.5s\n",
      "[CV 1/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-29239235185.522 total time=  20.1s\n",
      "[CV 2/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-28710824056.670 total time=  18.6s\n",
      "[CV 3/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-35295350407.247 total time=  17.6s\n",
      "[CV 4/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-58568012531.988 total time=  17.8s\n",
      "[CV 5/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-404399305824.808 total time=  18.4s\n",
      "[CV 1/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-29239235185.519 total time=  16.1s\n",
      "[CV 2/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-28710824056.653 total time=  17.5s\n",
      "[CV 3/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-35295350407.247 total time=  17.8s\n",
      "[CV 4/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-58568012531.976 total time=  16.9s\n",
      "[CV 5/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-404399305824.783 total time=  17.2s\n",
      "[CV 1/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-29239235185.527 total time=  18.1s\n",
      "[CV 2/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-28710824056.670 total time=  17.8s\n",
      "[CV 3/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-35295350407.266 total time=  18.1s\n",
      "[CV 4/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-58568012531.980 total time=  18.6s\n",
      "[CV 5/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-404399305824.834 total time=  18.5s\n",
      "[CV 1/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-29239235185.519 total time=  14.2s\n",
      "[CV 2/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-28710824056.653 total time=  16.4s\n",
      "[CV 3/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-35295350407.247 total time=  14.9s\n",
      "[CV 4/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-58568012531.976 total time=  16.2s\n",
      "[CV 5/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-404399305824.783 total time=  14.9s\n",
      "[CV 1/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-29239235185.534 total time=  16.1s\n",
      "[CV 2/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-28710824056.661 total time=  15.3s\n",
      "[CV 3/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-35295350407.259 total time=  15.8s\n",
      "[CV 4/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-58568012531.984 total time=  16.0s\n",
      "[CV 5/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-404399305824.798 total time=  16.4s\n",
      "[CV 1/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-29239235185.519 total time=  14.7s\n",
      "[CV 2/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-28710824056.653 total time=  16.0s\n",
      "[CV 3/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-35295350407.247 total time=  15.1s\n",
      "[CV 4/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-58568012531.976 total time=  16.5s\n",
      "[CV 5/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-404399305824.783 total time=  15.1s\n",
      "[CV 1/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-29239235185.526 total time=  14.9s\n",
      "[CV 2/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-28710824056.663 total time=  16.0s\n",
      "[CV 3/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-35295350407.255 total time=  15.7s\n",
      "[CV 4/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-58568012531.989 total time=  15.7s\n",
      "[CV 5/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-404399305824.811 total time=  16.0s\n",
      "[CV 1/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-29239235185.519 total time=  16.3s\n",
      "[CV 2/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-28710824056.653 total time=  17.9s\n",
      "[CV 3/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-35295350407.247 total time=  17.3s\n",
      "[CV 4/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-58568012531.976 total time=  16.8s\n",
      "[CV 5/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-404399305824.783 total time=  17.7s\n",
      "[CV 1/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-29239235185.536 total time=  17.4s\n",
      "[CV 2/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-28710824056.672 total time=  17.3s\n",
      "[CV 3/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-35295350407.266 total time=  18.3s\n",
      "[CV 4/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-58568012532.024 total time=  18.6s\n",
      "[CV 5/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-404399305824.834 total time=  18.1s\n",
      "[CV 1/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-29239235185.519 total time=  16.4s\n",
      "[CV 2/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-28710824056.653 total time=  18.0s\n",
      "[CV 3/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-35295350407.247 total time=  17.9s\n",
      "[CV 4/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-58568012531.976 total time=  16.9s\n",
      "[CV 5/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-404399305824.783 total time=  17.4s\n",
      "[CV 1/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-29239235185.520 total time=  17.6s\n",
      "[CV 2/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-28710824056.662 total time=  17.8s\n",
      "[CV 3/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-35295350407.265 total time=  17.5s\n",
      "[CV 4/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-58568012531.988 total time=  18.6s\n",
      "[CV 5/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-404399305824.834 total time=  18.5s\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-15679314925.414 total time=  14.4s\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-16812663363.232 total time=  16.6s\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-21249292560.497 total time=  15.0s\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-36296949404.213 total time=  16.2s\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-340886778910.201 total time=  15.2s\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-14820032124.802 total time=  15.8s\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-14844887070.416 total time=  15.6s\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-19033522306.532 total time=  16.2s\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-31054425683.201 total time=  16.0s\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-332906095570.451 total time=  15.9s\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-16896521375.491 total time=  15.2s\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-16358123839.907 total time=  15.8s\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-20387854440.434 total time=  16.1s\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-33741022732.121 total time=  15.5s\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-345451118825.687 total time=  16.4s\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-14121125386.017 total time=  14.8s\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-14425232745.671 total time=  16.7s\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-19252137426.511 total time=  15.6s\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-34557700253.531 total time=  16.6s\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-330207517397.701 total time=  15.9s\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-53488865927.309 total time=  16.7s\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-5377812881.556 total time=  18.2s\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-4735907911.780 total time=  17.5s\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-4842373393.641 total time=  17.3s\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-168278489393.936 total time=  17.8s\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-54312939264.088 total time=  17.5s\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-5779825436.829 total time=  17.8s\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-5101916926.523 total time=  18.3s\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-5139023107.399 total time=  18.7s\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-167417170909.932 total time=  18.2s\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-51603235268.964 total time=  16.4s\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-5539528160.948 total time=  17.7s\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-4612926118.199 total time=  18.4s\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-4763323370.511 total time=  17.4s\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-167248486876.798 total time=  17.5s\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-52376771770.837 total time=  18.1s\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-5619397753.215 total time=  18.7s\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-4716956519.439 total time=  17.9s\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-4990138352.362 total time=  18.0s\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-166691371586.080 total time=  18.5s\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-15850930893.827 total time=  14.9s\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-15416444817.166 total time=  15.8s\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-20162670449.509 total time=  15.9s\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-38983400917.478 total time=  15.5s\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-346111692409.613 total time=  15.9s\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-14628191667.511 total time=  15.2s\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-14025507629.702 total time=  16.6s\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-18401717537.103 total time=  15.6s\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-33851533424.068 total time=  16.8s\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-334907654516.651 total time=  15.6s\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-15679651457.245 total time=  15.4s\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-16429924636.528 total time=  15.2s\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-21537230917.608 total time=  16.3s\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-37110700980.257 total time=  14.9s\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-342249914471.902 total time=  15.9s\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-13342827087.398 total time=  14.7s\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-15347960207.806 total time=  16.6s\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-18287412051.614 total time=  15.3s\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-33614138263.297 total time=  16.4s\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-328750644849.648 total time=  15.5s\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-53829584752.896 total time=  17.0s\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-5573778372.723 total time=  18.1s\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-4786530360.003 total time=  17.7s\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-4663551405.550 total time=  17.0s\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-170511486572.322 total time=  17.8s\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-55316662539.213 total time=  17.2s\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-5632096035.247 total time=  17.5s\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-5034877093.132 total time=  18.1s\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-4917470090.236 total time=  18.4s\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-170222314680.924 total time=  17.8s\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-53058014978.831 total time=  16.2s\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-5426652352.020 total time=  17.7s\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-4713889442.696 total time=  17.3s\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-4477669253.746 total time=  16.9s\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-168045808696.959 total time=  18.0s\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-56392501363.052 total time=  17.8s\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-5482003145.718 total time=  18.1s\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-4925235235.196 total time=  18.1s\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-5033870324.547 total time=  18.3s\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-170093213024.680 total time=  18.6s\n",
      "[CV 1/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-29239235185.519 total time=  14.2s\n",
      "[CV 2/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-28710824056.653 total time=  16.1s\n",
      "[CV 3/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-35295350407.247 total time=  15.0s\n",
      "[CV 4/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-58568012531.976 total time=  15.9s\n",
      "[CV 5/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-404399305824.783 total time=  14.9s\n",
      "[CV 1/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-29239235185.528 total time=  15.7s\n",
      "[CV 2/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-28710824056.656 total time=  15.2s\n",
      "[CV 3/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-35295350407.249 total time=  16.2s\n",
      "[CV 4/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-58568012531.978 total time=  15.8s\n",
      "[CV 5/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-404399305824.785 total time=  16.3s\n",
      "[CV 1/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-29239235185.519 total time=  14.7s\n",
      "[CV 2/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-28710824056.653 total time=  16.0s\n",
      "[CV 3/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-35295350407.247 total time=  15.5s\n",
      "[CV 4/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-58568012531.976 total time=  15.4s\n",
      "[CV 5/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-404399305824.783 total time=  15.3s\n",
      "[CV 1/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-29239235185.531 total time=  15.3s\n",
      "[CV 2/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-28710824056.657 total time=  15.6s\n",
      "[CV 3/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-35295350407.249 total time=  15.8s\n",
      "[CV 4/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-58568012531.978 total time=  16.1s\n",
      "[CV 5/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-404399305824.786 total time=  15.5s\n",
      "[CV 1/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-29239235185.519 total time=  17.3s\n",
      "[CV 2/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-28710824056.653 total time=  17.2s\n",
      "[CV 3/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-35295350407.247 total time=  17.2s\n",
      "[CV 4/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-58568012531.976 total time=  18.2s\n",
      "[CV 5/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-404399305824.783 total time=  18.1s\n",
      "[CV 1/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-29239235185.522 total time=  16.8s\n",
      "[CV 2/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-28710824056.654 total time=  18.3s\n",
      "[CV 3/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-35295350407.247 total time=  18.6s\n",
      "[CV 4/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-58568012531.977 total time=  18.6s\n",
      "[CV 5/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-404399305824.784 total time=  17.9s\n",
      "[CV 1/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-29239235185.519 total time=  16.6s\n",
      "[CV 2/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-28710824056.653 total time=  18.0s\n",
      "[CV 3/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-35295350407.247 total time=  17.5s\n",
      "[CV 4/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-58568012531.976 total time=  17.2s\n",
      "[CV 5/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-404399305824.783 total time=  17.4s\n",
      "[CV 1/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-29239235185.520 total time=  17.9s\n",
      "[CV 2/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-28710824056.654 total time=  17.6s\n",
      "[CV 3/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-35295350407.247 total time=  17.8s\n",
      "[CV 4/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-58568012531.977 total time=  18.7s\n",
      "[CV 5/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-404399305824.784 total time=  18.7s\n",
      "[CV 1/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-29239235185.519 total time=  14.3s\n",
      "[CV 2/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-28710824056.653 total time=  15.9s\n",
      "[CV 3/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-35295350407.247 total time=  15.2s\n",
      "[CV 4/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-58568012531.976 total time=  15.8s\n",
      "[CV 5/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-404399305824.783 total time=  15.1s\n",
      "[CV 1/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-29239235185.527 total time=  15.3s\n",
      "[CV 2/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-28710824056.657 total time=  15.6s\n",
      "[CV 3/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-35295350407.249 total time=  16.0s\n",
      "[CV 4/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-58568012531.978 total time=  15.8s\n",
      "[CV 5/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-404399305824.785 total time=  15.7s\n",
      "[CV 1/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-29239235185.519 total time=  15.0s\n",
      "[CV 2/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-28710824056.653 total time=  15.3s\n",
      "[CV 3/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-35295350407.247 total time=  15.5s\n",
      "[CV 4/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-58568012531.976 total time=  15.2s\n",
      "[CV 5/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-404399305824.783 total time=  15.4s\n",
      "[CV 1/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-29239235185.529 total time=  15.0s\n",
      "[CV 2/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-28710824056.656 total time=  16.0s\n",
      "[CV 3/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-35295350407.249 total time=  15.7s\n",
      "[CV 4/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-58568012531.978 total time=  16.5s\n",
      "[CV 5/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-404399305824.786 total time=  15.1s\n",
      "[CV 1/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-29239235185.519 total time=  17.4s\n",
      "[CV 2/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-28710824056.653 total time=  17.4s\n",
      "[CV 3/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-35295350407.247 total time=  16.8s\n",
      "[CV 4/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-58568012531.976 total time=  17.5s\n",
      "[CV 5/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-404399305824.783 total time=  17.6s\n",
      "[CV 1/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-29239235185.520 total time=  16.5s\n",
      "[CV 2/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-28710824056.654 total time=  18.3s\n",
      "[CV 3/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-35295350407.247 total time=  18.1s\n",
      "[CV 4/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-58568012531.977 total time=  17.4s\n",
      "[CV 5/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-404399305824.783 total time=  17.7s\n",
      "[CV 1/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-29239235185.519 total time=  17.3s\n",
      "[CV 2/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-28710824056.653 total time=  18.0s\n",
      "[CV 3/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-35295350407.247 total time=  17.5s\n",
      "[CV 4/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-58568012531.976 total time=  17.3s\n",
      "[CV 5/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-404399305824.783 total time=  17.6s\n",
      "[CV 1/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-29239235185.519 total time=  17.1s\n",
      "[CV 2/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-28710824056.654 total time=  17.6s\n",
      "[CV 3/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-35295350407.247 total time=  18.4s\n",
      "[CV 4/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-58568012531.977 total time=  18.5s\n",
      "[CV 5/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-404399305824.784 total time=  17.7s\n"
     ]
    }
   ],
   "source": [
    "grid_result = grid.fit(x_train_regresion, y_train_regresion)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Los parámetros y métricas del mejor modelo fueron:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El error absoluto porcentual promedio del mejor modelo fue de:  26.96661\n",
      "El error absoluto cuadrado promedio del mejor modelo fue de:  18100505000.0\n",
      "Los parámetros óptimizados fueron:  {'activation_func': 'relu', 'batch_size': 100, 'epochs': 30, 'first_layer_nodes': 49, 'hidden_layers': 1, 'last_layer_nodes': 34.5, 'optimizer': 'RMSprop'}\n"
     ]
    }
   ],
   "source": [
    "print(\"El error absoluto porcentual promedio del mejor modelo fue de: \", grid_result.best_estimator_.model.metrics[2].result().numpy())\n",
    "print(\"El error absoluto cuadrado promedio del mejor modelo fue de: \", grid_result.best_estimator_.model.metrics[1].result().numpy())\n",
    "print(\"Los parámetros óptimizados fueron: \", grid.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.a.3 Predicción"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582/582 [==============================] - 1s 1ms/step - loss: 163353624576.0000 - mse: 163353624576.0000 - mean_absolute_percentage_error: 57.0202\n"
     ]
    }
   ],
   "source": [
    "grid_predict = grid.best_estimator_.model.evaluate(x_test_regresion, y_test_regresion)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.a.4 Métricas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El error absoluto porcentual promedio fue de:  57.02020263671875\n",
      "El error absoluto cuadrado promedio (mse) fue de:  163353624576.0\n"
     ]
    }
   ],
   "source": [
    "print(\"El error absoluto porcentual promedio fue de: \", grid_predict[2])\n",
    "print(\"El error absoluto cuadrado promedio (mse) fue de: \", grid_predict[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Veamos cómo se comporta la función de pérdida del mejor modelo según la cantidad de épocas utilizadas:"
   ],
   "metadata": {
    "id": "vmBg6ev_ZO-e"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "{'verbose': 1, 'epochs': 1, 'steps': 582}"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epochs = range(60)\n",
    "# historia = grid_result.best_estimator_.model.history.history\n",
    "# historia\n",
    "# plt.plot(epochs, historia['mean_absolute_percentage_error'], color='orange', label='MSE')\n",
    "# plt.xlabel(\"epochs\")\n",
    "# plt.ylabel(\"MSE\")\n",
    "# plt.title('Error cuadrático medio por cantidad de épocas')\n",
    "# plt.legend()\n",
    "# print(grid_result.best_estimator_.model.metrics[0].result().numpy(), grid_result.best_estimator_.model.metrics[0].name)\n",
    "max(grid_result.cv_results_[\"mean_test_score\"])\n",
    "grid_result.best_estimator_.model.history.params"
   ],
   "metadata": {
    "id": "BzNqiJex_TQU",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "outputId": "214e1825-e3d1-4d66-f0db-9b0cdf7a2550"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El error según la métrica 'Mean Square Error' de test es: 163353668259.12692\n",
      "El error según la métrica 'Root Mean Square Error' de test es: 404170.34559592186\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(x_test_regresion)\n",
    "\n",
    "mse = metrics.mean_squared_error(\n",
    "    y_true  = y_test_regresion,\n",
    "    y_pred  = y_pred,\n",
    "    squared = True\n",
    ")\n",
    "\n",
    "print(f\"El error según la métrica 'Mean Square Error' de test es: {mse}\")\n",
    "\n",
    "rmse = metrics.mean_squared_error(\n",
    "    y_true  = y_test_regresion,\n",
    "    y_pred  = y_pred,\n",
    "    squared = False\n",
    ")\n",
    "\n",
    "print(f\"El error según la métrica 'Root Mean Square Error' de test es: {rmse}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.a.5 Exportación de Datos"
   ],
   "metadata": {
    "id": "BeRZVagKeKzO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finalmente, exportamos el modelo utilizado:"
   ],
   "metadata": {
    "id": "lO3v9OUzeKzP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "if IN_COLAB:\n",
    "  path = '/content/drive/MyDrive/📔 Organización de Datos (75.06)/TPS/TP2/MODELOS/Redes_Regressor.json'\n",
    "else:\n",
    "  path = './MODELOS/Redes_Regressor.json'\n",
    "\n",
    "joblib.dump(grid.best_estimator_.model, path)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ac67727c-79b0-4c22-bb79-7bd9362015f4",
    "id": "tSuqGenveKzP"
   },
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Salvador\\AppData\\Local\\Temp\\tmpeekvumao\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": "['./MODELOS/Redes_Regressor.json']"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.b Clasificación\n",
    "___"
   ],
   "metadata": {
    "collapsed": false,
    "id": "dXdWW-m9_TQV"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.b.1 Preparación del dataset"
   ],
   "metadata": {
    "id": "b176QcPLZj9N"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "x_train_clasificacion = df_train_x.drop([\"id\"], axis=1).copy()\n",
    "y_train_clasificacion = df_train_y_clasificacion.copy()\n",
    "x_test_clasificacion = df_test_x.drop([\"id\"], axis=1).copy()\n",
    "y_test_clasificacion = df_test_y_clasificacion.copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Normalizamos mediante Z-Score:"
   ],
   "metadata": {
    "collapsed": false,
    "id": "JPjRt6tTOWIL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "x_train_clasificacion[['start_date', 'end_date', 'latitud', 'longitud', 'property_rooms', 'property_surface_total']] = zscore(x_train_clasificacion[['start_date', 'end_date', 'latitud', 'longitud', 'property_rooms', 'property_surface_total']], axis=1)\n",
    "\n",
    "x_test_clasificacion[['start_date', 'end_date', 'latitud', 'longitud', 'property_rooms', 'property_surface_total']] = zscore(x_test_clasificacion[['start_date', 'end_date', 'latitud', 'longitud', 'property_rooms', 'property_surface_total']], axis=1)"
   ],
   "metadata": {
    "id": "qDlv11yi8sR1"
   },
   "execution_count": 68,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aplicamos One Hot encoding a la columna target de entrenamiento y test, para que tenga 3 columnas al igual que la salida del modelo:"
   ],
   "metadata": {
    "collapsed": false,
    "id": "IZ2XeEKi_TQW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "y_train_clasificacion = pd.get_dummies(y_train_clasificacion, columns=['tipo_precio_3'], drop_first=False)\n",
    "y_test_clasificacion = pd.get_dummies(y_test_clasificacion, columns=['tipo_precio_3'], drop_first=False)"
   ],
   "metadata": {
    "id": "2jzMgy7b5js1"
   },
   "execution_count": 69,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.b.2 Búsqueda del mejor modelo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Función auxiliar para que GridSearchCV realice el scoring de forma correcta."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "def my_categorical_accuracy(y_true, y_pred) :\n",
    "    y_pred_df = pd.DataFrame(data=y_pred, columns=['alto', 'bajo', 'medio'])\n",
    "    res = round(accuracy_score(y_true, y_pred_df), 2)\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creamos una función que permite generar un modelo a partir de sus hiperparámetros configurables.\n",
    "Esta función recibe como parámetros la cantidad de capas ocultas extra, la cantidad de nodos de la última capa oculta, la función de activación y metadata del clasificador."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "def crear_modelo(extra_hidden_layers, last_layer_nodes, activation_func, loss_func, meta):\n",
    "\n",
    "    n_features_in_ = meta[\"n_features_in_\"]\n",
    "    X_shape_ = meta[\"X_shape_\"]\n",
    "    n_classes_ = meta[\"n_classes_\"]\n",
    "\n",
    "    sequential = Sequential()\n",
    "    sequential.add(keras.layers.Dense(n_features_in_ * 0.7, input_shape=X_shape_[1:], activation=activation_func))\n",
    "\n",
    "    if last_layer_nodes > n_features_in_:\n",
    "        decremento = 0\n",
    "    elif extra_hidden_layers is 0 or extra_hidden_layers is 1:\n",
    "        decremento = 0\n",
    "    else:\n",
    "        decremento = math.ceil((n_features_in_ - last_layer_nodes) / (extra_hidden_layers - 1))\n",
    "\n",
    "    for i in range (0, extra_hidden_layers):\n",
    "        nodos = n_features_in_ - decremento * i\n",
    "        sequential.add(Dense(nodos, activation=activation_func))\n",
    "\n",
    "    sequential.add(Dense(n_classes_, activation='softmax'))\n",
    "\n",
    "    sequential.compile(\n",
    "        loss='categorical_crossentropy'\n",
    "    )\n",
    "    return sequential\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creamos un modelo base, necesario según la documentación de SciKeras - KerasClassifier.\n",
    "Este modelo base será editado por GridSearchCV al buscar los hiperparámetros."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "base_model = KerasClassifier(crear_modelo,\n",
    "                             loss_func=\"categorical_crossentropy\",\n",
    "                             extra_hidden_layers=1,\n",
    "                             last_layer_nodes=1,\n",
    "                             activation_func='sigmoid',\n",
    "                             )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Definimos los hiperparámetros posibles. Además de los necesarios por la función crear_modelo, agregamos diferentes optimizadores, learning rates y cantidad de épocas."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "param_grid = dict(\n",
    "    extra_hidden_layers=[0, 1],\n",
    "    last_layer_nodes = [10, 20],\n",
    "    activation_func = ['relu', 'softmax'],\n",
    "    batch_size = [100],\n",
    "    epochs = [5, 20],\n",
    "    optimizer__learning_rate = [0.001, 0.0001],\n",
    "    optimizer = [\"adam\", \"sge\"],\n",
    "    loss_func = [\"categorical_crossentropy\"],\n",
    ")\n",
    "\n",
    "gs = GridSearchCV(base_model,\n",
    "                  param_grid = param_grid,\n",
    "                  cv=5,\n",
    "                  scoring=make_scorer(my_categorical_accuracy),\n",
    "                  verbose=3,\n",
    "                  error_score='raise'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Entrenamos los diferentes modelos y obtenemos los mejores parámetros."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8447\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7959\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7934\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7920\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7916\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.150 total time=   4.4s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 909us/step - loss: 0.8761\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 880us/step - loss: 0.8056\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8028\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 892us/step - loss: 0.8016\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 981us/step - loss: 0.8012\n",
      "149/149 [==============================] - 0s 662us/step\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.520 total time=   3.5s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 887us/step - loss: 0.9158\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 884us/step - loss: 0.8576\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 874us/step - loss: 0.8555\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 965us/step - loss: 0.8547\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8544\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.290 total time=   3.6s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 2s 1ms/step - loss: 0.9135\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 928us/step - loss: 0.8608\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 990us/step - loss: 0.8588\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8581\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8574\n",
      "149/149 [==============================] - 0s 905us/step\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.380 total time=   4.5s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7320\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 909us/step - loss: 0.6890\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 906us/step - loss: 0.6862\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 865us/step - loss: 0.6853\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 875us/step - loss: 0.6848\n",
      "149/149 [==============================] - 0s 662us/step\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.010 total time=   3.6s\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 1s 847us/step - loss: 0.8380\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 0s 838us/step - loss: 0.7958\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 1s 840us/step - loss: 0.7929\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 1s 847us/step - loss: 0.7918\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7913\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.130 total time=   3.2s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8656\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8049\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8026\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8022\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8015\n",
      "149/149 [==============================] - 0s 831us/step\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.420 total time=   4.4s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 880us/step - loss: 0.9121\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 857us/step - loss: 0.8582\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 877us/step - loss: 0.8561\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 869us/step - loss: 0.8556\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 869us/step - loss: 0.8548\n",
      "149/149 [==============================] - 0s 662us/step\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.300 total time=   3.2s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 875us/step - loss: 0.9195\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 870us/step - loss: 0.8607\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8587\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8578\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8574\n",
      "149/149 [==============================] - 0s 993us/step\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.420 total time=   4.3s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7281\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6891\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6860\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6852\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 889us/step - loss: 0.6847\n",
      "149/149 [==============================] - 0s 730us/step\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.010 total time=   4.0s\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 1s 838us/step - loss: 0.8453\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 1s 865us/step - loss: 0.7969\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 1s 843us/step - loss: 0.7939\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 1s 879us/step - loss: 0.7924\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 1s 862us/step - loss: 0.7915\n",
      "149/149 [==============================] - 0s 669us/step\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.130 total time=   3.0s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 869us/step - loss: 0.8653\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8051\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8029\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8018\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8012\n",
      "149/149 [==============================] - 0s 892us/step\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.450 total time=   3.8s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9238\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8575\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8558\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8551\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 892us/step - loss: 0.8546\n",
      "149/149 [==============================] - 0s 669us/step\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.360 total time=   3.9s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 860us/step - loss: 0.9179\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 880us/step - loss: 0.8611\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 875us/step - loss: 0.8589\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 874us/step - loss: 0.8580\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 877us/step - loss: 0.8575\n",
      "149/149 [==============================] - 0s 797us/step\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.420 total time=   3.1s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7298\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6892\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6865\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6853\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6849\n",
      "149/149 [==============================] - 0s 824us/step\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.010 total time=   4.0s\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8412\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7952\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 1s 904us/step - loss: 0.7924\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 1s 858us/step - loss: 0.7917\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 1s 843us/step - loss: 0.7911\n",
      "149/149 [==============================] - 0s 669us/step\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.120 total time=   3.5s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 862us/step - loss: 0.8842\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 882us/step - loss: 0.8057\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 877us/step - loss: 0.8028\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 880us/step - loss: 0.8021\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 865us/step - loss: 0.8011\n",
      "149/149 [==============================] - 0s 669us/step\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.520 total time=   3.1s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9108\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8565\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8555\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8550\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8543\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.300 total time=   4.2s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9268\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 963us/step - loss: 0.8610\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 887us/step - loss: 0.8587\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 874us/step - loss: 0.8578\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 875us/step - loss: 0.8571\n",
      "149/149 [==============================] - 0s 716us/step\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.410 total time=   3.4s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 896us/step - loss: 0.7410\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 875us/step - loss: 0.6892\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 860us/step - loss: 0.6860\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 897us/step - loss: 0.6851\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 978us/step - loss: 0.6848\n",
      "149/149 [==============================] - 0s 953us/step\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.010 total time=   3.2s\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8443\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7956\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7928\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7917\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7913\n",
      "149/149 [==============================] - 0s 946us/step\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.130 total time=   4.1s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8784\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 889us/step - loss: 0.8053\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 882us/step - loss: 0.8031\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 882us/step - loss: 0.8019\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 882us/step - loss: 0.8011\n",
      "149/149 [==============================] - 0s 696us/step\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.500 total time=   3.3s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 875us/step - loss: 0.9188\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 882us/step - loss: 0.8576\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 865us/step - loss: 0.8556\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 988us/step - loss: 0.8551\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8549\n",
      "149/149 [==============================] - 0s 959us/step\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.300 total time=   3.4s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9176\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8610\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8591\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8579\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8576\n",
      "149/149 [==============================] - 0s 831us/step\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.390 total time=   3.9s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 911us/step - loss: 0.7373\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 889us/step - loss: 0.6891\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 894us/step - loss: 0.6861\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 892us/step - loss: 0.6853\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 889us/step - loss: 0.6849\n",
      "149/149 [==============================] - 0s 669us/step\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.010 total time=   3.2s\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 1s 877us/step - loss: 0.8360\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 1s 897us/step - loss: 0.7948\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7924\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7916\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7908\n",
      "149/149 [==============================] - 0s 885us/step\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.130 total time=   3.6s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8630\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8058\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8030\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8019\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8013\n",
      "149/149 [==============================] - 0s 716us/step\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.510 total time=   4.0s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 896us/step - loss: 0.9188\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 916us/step - loss: 0.8570\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 897us/step - loss: 0.8554\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 912us/step - loss: 0.8549\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 907us/step - loss: 0.8543\n",
      "149/149 [==============================] - 0s 716us/step\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.560 total time=   3.2s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 896us/step - loss: 0.9203\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8609\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8590\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8584\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8576\n",
      "149/149 [==============================] - 0s 953us/step\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.540 total time=   3.8s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7276\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6889\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6859\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6852\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 887us/step - loss: 0.6849\n",
      "149/149 [==============================] - 0s 682us/step\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.010 total time=   3.8s\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 1s 860us/step - loss: 0.8356\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 1s 870us/step - loss: 0.7953\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 1s 867us/step - loss: 0.7926\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 1s 857us/step - loss: 0.7917\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 1s 907us/step - loss: 0.7910\n",
      "149/149 [==============================] - 0s 716us/step\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.140 total time=   3.1s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 907us/step - loss: 0.8748\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8052\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8029\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8016\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8011\n",
      "149/149 [==============================] - 0s 899us/step\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.510 total time=   3.9s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9107\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8578\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 880us/step - loss: 0.8551\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 906us/step - loss: 0.8545\n",
      "149/149 [==============================] - 0s 689us/step\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.300 total time=   3.7s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 874us/step - loss: 0.9148\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 875us/step - loss: 0.8610\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 901us/step - loss: 0.8594\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 880us/step - loss: 0.8583\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 880us/step - loss: 0.8578\n",
      "149/149 [==============================] - 0s 662us/step\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.460 total time=   3.1s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7293\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6898\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6862\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6856\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6848\n",
      "149/149 [==============================] - 0s 953us/step\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.010 total time=   4.0s\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8400\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7957\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 1s 906us/step - loss: 0.7929\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 1s 902us/step - loss: 0.7916\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 1s 914us/step - loss: 0.7910\n",
      "149/149 [==============================] - 0s 723us/step\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.140 total time=   3.7s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8697\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 921us/step - loss: 0.8060\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 936us/step - loss: 0.8031\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 901us/step - loss: 0.8019\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8013\n",
      "149/149 [==============================] - 0s 926us/step\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.520 total time=   3.5s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9169\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8576\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8559\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8551\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8545\n",
      "149/149 [==============================] - 0s 905us/step\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.470 total time=   4.4s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 933us/step - loss: 0.9216\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 924us/step - loss: 0.8608\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 912us/step - loss: 0.8589\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 951us/step - loss: 0.8581\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 907us/step - loss: 0.8577\n",
      "149/149 [==============================] - 0s 730us/step\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.420 total time=   3.3s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 875us/step - loss: 0.7385\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 864us/step - loss: 0.6890\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6863\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6855\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6849\n",
      "149/149 [==============================] - 0s 845us/step\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.010 total time=   3.9s\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8228\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7954\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7933\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7924\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 1s 993us/step - loss: 0.7917\n",
      "149/149 [==============================] - 0s 757us/step\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.090 total time=   4.3s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8412\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8048\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 992us/step - loss: 0.8037\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 998us/step - loss: 0.8023\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 993us/step - loss: 0.8012\n",
      "149/149 [==============================] - 0s 716us/step\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.430 total time=   3.6s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8894\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8588\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8568\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8552\n",
      "149/149 [==============================] - 0s 926us/step\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.410 total time=   4.5s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8977\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8613\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8596\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 990us/step - loss: 0.8581\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 988us/step - loss: 0.8578\n",
      "149/149 [==============================] - 0s 716us/step\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.370 total time=   3.8s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7216\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6887\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6867\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6864\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6859\n",
      "149/149 [==============================] - 0s 865us/step\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.010 total time=   4.0s\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8270\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7953\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7932\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7920\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 1s 983us/step - loss: 0.7916\n",
      "149/149 [==============================] - 0s 723us/step\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.130 total time=   4.4s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 998us/step - loss: 0.8430\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 995us/step - loss: 0.8057\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8034\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8018\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 992us/step - loss: 0.8015\n",
      "149/149 [==============================] - 0s 730us/step\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.530 total time=   3.6s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8966\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8580\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8571\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8549\n",
      "149/149 [==============================] - 0s 973us/step\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.290 total time=   4.8s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8926\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8615\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8595\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 993us/step - loss: 0.8585\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1000us/step - loss: 0.8576\n",
      "149/149 [==============================] - 0s 716us/step\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.450 total time=   3.7s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7186\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6880\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6865\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6855\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6853\n",
      "149/149 [==============================] - 0s 885us/step\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.010 total time=   4.2s\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8229\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7939\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7927\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7921\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 1s 985us/step - loss: 0.7913\n",
      "149/149 [==============================] - 0s 764us/step\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.120 total time=   4.3s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8448\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8062\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8043\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8029\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8017\n",
      "149/149 [==============================] - 0s 743us/step\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.420 total time=   3.7s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8910\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8582\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8569\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8549\n",
      "149/149 [==============================] - 0s 959us/step\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.380 total time=   4.8s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9015\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 988us/step - loss: 0.8618\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8596\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8589\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8578\n",
      "149/149 [==============================] - 0s 716us/step\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.370 total time=   3.6s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7143\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6886\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6870\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6866\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6858\n",
      "149/149 [==============================] - 0s 966us/step\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.010 total time=   4.3s\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8195\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7950\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7932\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7926\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7917\n",
      "149/149 [==============================] - 0s 811us/step\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.130 total time=   4.3s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8474\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8054\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8031\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 993us/step - loss: 0.8020\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8014\n",
      "149/149 [==============================] - 0s 851us/step\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.530 total time=   3.6s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8930\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8581\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8569\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8559\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8550\n",
      "149/149 [==============================] - 0s 946us/step\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.390 total time=   4.7s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8958\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8612\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8594\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8586\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8583\n",
      "149/149 [==============================] - 0s 791us/step\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.450 total time=   3.6s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7159\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 990us/step - loss: 0.6883\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6865\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6861\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6856\n",
      "149/149 [==============================] - 0s 899us/step\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.010 total time=   4.2s\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8304\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7948\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7930\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7921\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 1s 988us/step - loss: 0.7912\n",
      "149/149 [==============================] - 0s 757us/step\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.090 total time=   4.2s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 998us/step - loss: 0.8404\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8047\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8029\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 997us/step - loss: 0.8015\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8012\n",
      "149/149 [==============================] - 0s 966us/step\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.480 total time=   3.6s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8916\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8596\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8569\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
      "149/149 [==============================] - 0s 986us/step\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.290 total time=   4.6s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8921\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 987us/step - loss: 0.8608\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 997us/step - loss: 0.8592\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 993us/step - loss: 0.8585\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8575\n",
      "149/149 [==============================] - 0s 716us/step\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.420 total time=   3.6s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7171\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6878\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6864\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6859\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6854\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.010 total time=   4.6s\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8191\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7949\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7925\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 1s 970us/step - loss: 0.7917\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 1s 993us/step - loss: 0.7915\n",
      "149/149 [==============================] - 0s 696us/step\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.120 total time=   4.0s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8448\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 998us/step - loss: 0.8061\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 995us/step - loss: 0.8036\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8023\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8015\n",
      "149/149 [==============================] - 0s 932us/step\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.450 total time=   3.8s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8913\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8581\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8571\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8555\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8552\n",
      "149/149 [==============================] - 0s 865us/step\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.420 total time=   4.6s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 993us/step - loss: 0.8921\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 971us/step - loss: 0.8612\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 993us/step - loss: 0.8590\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8582\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 988us/step - loss: 0.8578\n",
      "149/149 [==============================] - 0s 689us/step\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.420 total time=   3.6s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7241\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6882\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6867\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6865\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6857\n",
      "149/149 [==============================] - 0s 959us/step\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.010 total time=   4.3s\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8194\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7944\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7931\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7923\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 1s 997us/step - loss: 0.7915\n",
      "149/149 [==============================] - 0s 777us/step\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.060 total time=   4.3s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 992us/step - loss: 0.8434\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 995us/step - loss: 0.8054\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1000us/step - loss: 0.8034\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8026\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8014\n",
      "149/149 [==============================] - 0s 851us/step\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.470 total time=   3.8s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8897\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8588\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8571\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 977us/step - loss: 0.8558\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
      "149/149 [==============================] - 0s 959us/step\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.310 total time=   4.5s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8984\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8616\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8600\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8585\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8579\n",
      "149/149 [==============================] - 0s 743us/step\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.380 total time=   4.0s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7097\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6882\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6865\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6859\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6855\n",
      "149/149 [==============================] - 0s 851us/step\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.010 total time=   4.2s\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8249\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7943\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7927\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7918\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7914\n",
      "149/149 [==============================] - 0s 784us/step\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.090 total time=   4.4s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8418\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 981us/step - loss: 0.8056\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 987us/step - loss: 0.8032\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 988us/step - loss: 0.8020\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8015\n",
      "149/149 [==============================] - 0s 696us/step\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.460 total time=   3.6s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9017\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8583\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8575\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8565\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8551\n",
      "149/149 [==============================] - 0s 831us/step\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.300 total time=   4.6s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8958\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8611\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 985us/step - loss: 0.8593\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8583\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 992us/step - loss: 0.8578\n",
      "149/149 [==============================] - 0s 730us/step\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.410 total time=   3.8s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7168\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6891\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6867\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6861\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6856\n",
      "149/149 [==============================] - 0s 858us/step\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.010 total time=   4.1s\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8433\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7950\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7925\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7920\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 1s 943us/step - loss: 0.7912\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 1s 862us/step - loss: 0.7906\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 1s 860us/step - loss: 0.7905\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 1s 847us/step - loss: 0.7900\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 1s 863us/step - loss: 0.7898\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 0s 831us/step - loss: 0.7895\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 1s 845us/step - loss: 0.7897\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 1s 858us/step - loss: 0.7894\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 1s 879us/step - loss: 0.7894\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 1s 840us/step - loss: 0.7892\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7894\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7892\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7892\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7890\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7892\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7890\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.150 total time=  12.6s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8705\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 896us/step - loss: 0.8060\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 886us/step - loss: 0.8031\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 880us/step - loss: 0.8018\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 889us/step - loss: 0.8012\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 894us/step - loss: 0.8006\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 887us/step - loss: 0.8005\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 916us/step - loss: 0.7999\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 887us/step - loss: 0.7998\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 887us/step - loss: 0.7997\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7994\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7991\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7989\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7989\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7988\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7984\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7985\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7984\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 992us/step - loss: 0.7985\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 901us/step - loss: 0.7983\n",
      "149/149 [==============================] - 0s 797us/step\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.470 total time=  12.8s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 902us/step - loss: 0.9180\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 886us/step - loss: 0.8576\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 902us/step - loss: 0.8558\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 880us/step - loss: 0.8548\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 887us/step - loss: 0.8545\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 879us/step - loss: 0.8542\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8538\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8538\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8534\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8534\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 990us/step - loss: 0.8527\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 887us/step - loss: 0.8526\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 884us/step - loss: 0.8527\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 877us/step - loss: 0.8524\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 892us/step - loss: 0.8523\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 933us/step - loss: 0.8524\n",
      "149/149 [==============================] - 0s 662us/step\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.300 total time=  12.2s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 865us/step - loss: 0.9140\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 867us/step - loss: 0.8610\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 872us/step - loss: 0.8589\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8587\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8580\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8577\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8574\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8568\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8564\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 892us/step - loss: 0.8557\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 869us/step - loss: 0.8556\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 902us/step - loss: 0.8552\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 869us/step - loss: 0.8554\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 877us/step - loss: 0.8553\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 865us/step - loss: 0.8553\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 884us/step - loss: 0.8552\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 859us/step - loss: 0.8552\n",
      "149/149 [==============================] - 0s 655us/step\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.420 total time=  12.4s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7241\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6888\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6858\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6852\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6845\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6846\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6840\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6841\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 904us/step - loss: 0.6840\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 860us/step - loss: 0.6838\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 889us/step - loss: 0.6837\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 859us/step - loss: 0.6836\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 872us/step - loss: 0.6837\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 864us/step - loss: 0.6835\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 857us/step - loss: 0.6835\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 865us/step - loss: 0.6834\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 864us/step - loss: 0.6834\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 970us/step - loss: 0.6833\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6835\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6832\n",
      "149/149 [==============================] - 0s 851us/step\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.010 total time=  12.7s\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8544\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7981\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7939\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7923\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7915\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 1s 857us/step - loss: 0.7910\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 1s 874us/step - loss: 0.7904\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 1s 841us/step - loss: 0.7902\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 0s 831us/step - loss: 0.7902\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 1s 841us/step - loss: 0.7900\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 0s 836us/step - loss: 0.7897\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 1s 850us/step - loss: 0.7897\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 1s 850us/step - loss: 0.7896\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 1s 850us/step - loss: 0.7895\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 1s 912us/step - loss: 0.7894\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7891\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7891\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7894\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7893\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7892\n",
      "149/149 [==============================] - 0s 932us/step\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.140 total time=  12.4s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8770\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8057\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 901us/step - loss: 0.8031\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 892us/step - loss: 0.8021\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 884us/step - loss: 0.8013\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 892us/step - loss: 0.8011\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 896us/step - loss: 0.8008\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 899us/step - loss: 0.8003\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 880us/step - loss: 0.8000\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 901us/step - loss: 0.7998\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 891us/step - loss: 0.7994\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7993\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7991\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7990\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7988\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7988\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7987\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7986\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7984\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 938us/step - loss: 0.7982\n",
      "149/149 [==============================] - 0s 662us/step\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.470 total time=  13.0s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 880us/step - loss: 0.9147\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 882us/step - loss: 0.8572\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 879us/step - loss: 0.8557\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 865us/step - loss: 0.8551\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 880us/step - loss: 0.8544\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 880us/step - loss: 0.8540\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 880us/step - loss: 0.8538\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8534\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8534\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8532\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8528\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 963us/step - loss: 0.8526\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 887us/step - loss: 0.8525\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 874us/step - loss: 0.8528\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 874us/step - loss: 0.8526\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 884us/step - loss: 0.8525\n",
      "149/149 [==============================] - 0s 662us/step\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.350 total time=  12.5s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 875us/step - loss: 0.9172\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 891us/step - loss: 0.8599\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 877us/step - loss: 0.8582\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 963us/step - loss: 0.8578\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8569\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8564\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8564\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8564\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 889us/step - loss: 0.8556\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 894us/step - loss: 0.8556\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 865us/step - loss: 0.8555\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 886us/step - loss: 0.8555\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 872us/step - loss: 0.8554\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 896us/step - loss: 0.8553\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 875us/step - loss: 0.8551\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 884us/step - loss: 0.8550\n",
      "149/149 [==============================] - 0s 676us/step\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.460 total time=  12.4s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7270\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6895\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6865\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6852\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6849\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6843\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6842\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6836\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 921us/step - loss: 0.6837\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 902us/step - loss: 0.6838\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 896us/step - loss: 0.6837\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 894us/step - loss: 0.6836\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 906us/step - loss: 0.6833\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 887us/step - loss: 0.6833\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 901us/step - loss: 0.6831\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 899us/step - loss: 0.6832\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 909us/step - loss: 0.6831\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 931us/step - loss: 0.6831\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6830\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6829\n",
      "149/149 [==============================] - 0s 919us/step\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.010 total time=  13.0s\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8395\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7964\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7934\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7919\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7914\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 1s 885us/step - loss: 0.7907\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 1s 867us/step - loss: 0.7904\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 1s 899us/step - loss: 0.7902\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 1s 867us/step - loss: 0.7901\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 1s 882us/step - loss: 0.7899\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 1s 870us/step - loss: 0.7896\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 1s 894us/step - loss: 0.7897\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 1s 875us/step - loss: 0.7895\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 1s 879us/step - loss: 0.7895\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7896\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7894\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7894\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7893\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7892\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7893\n",
      "149/149 [==============================] - 0s 899us/step\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.130 total time=  13.0s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 956us/step - loss: 0.8593\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 875us/step - loss: 0.8044\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 879us/step - loss: 0.8022\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 862us/step - loss: 0.8013\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 880us/step - loss: 0.8010\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 857us/step - loss: 0.8005\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 882us/step - loss: 0.8001\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 864us/step - loss: 0.7998\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 870us/step - loss: 0.7997\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 892us/step - loss: 0.7992\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7991\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7991\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7990\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7987\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7987\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7985\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7985\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7987\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 896us/step - loss: 0.7986\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 889us/step - loss: 0.7984\n",
      "149/149 [==============================] - 0s 649us/step\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.510 total time=  12.9s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 897us/step - loss: 0.9122\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 896us/step - loss: 0.8575\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 891us/step - loss: 0.8555\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 892us/step - loss: 0.8551\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 880us/step - loss: 0.8542\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 879us/step - loss: 0.8543\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8541\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8538\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8536\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8535\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8533\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8535\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8531\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8531\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 971us/step - loss: 0.8530\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 896us/step - loss: 0.8530\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 879us/step - loss: 0.8528\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 886us/step - loss: 0.8527\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 891us/step - loss: 0.8526\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 882us/step - loss: 0.8525\n",
      "149/149 [==============================] - 0s 649us/step\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.370 total time=  12.5s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 884us/step - loss: 0.9263\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 852us/step - loss: 0.8607\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 0s 838us/step - loss: 0.8585\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8578\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8576\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8573\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8568\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8566\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8558\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 941us/step - loss: 0.8555\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 864us/step - loss: 0.8556\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 872us/step - loss: 0.8555\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 0s 835us/step - loss: 0.8553\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 0s 771us/step - loss: 0.8554\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 0s 763us/step - loss: 0.8552\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 907us/step - loss: 0.8553\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 864us/step - loss: 0.8553\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 0s 790us/step - loss: 0.8551\n",
      "149/149 [==============================] - 0s 818us/step\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.410 total time=  12.1s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7250\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6881\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6858\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6849\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6845\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6842\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6839\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6839\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 892us/step - loss: 0.6837\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 864us/step - loss: 0.6836\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 879us/step - loss: 0.6832\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 882us/step - loss: 0.6833\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 879us/step - loss: 0.6835\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 867us/step - loss: 0.6832\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 877us/step - loss: 0.6830\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 901us/step - loss: 0.6834\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 872us/step - loss: 0.6831\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 874us/step - loss: 0.6832\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 870us/step - loss: 0.6832\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6829\n",
      "149/149 [==============================] - 0s 858us/step\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.010 total time=  12.7s\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8394\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7956\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 1s 966us/step - loss: 0.7927\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 1s 956us/step - loss: 0.7916\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 0s 745us/step - loss: 0.7910\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 0s 747us/step - loss: 0.7905\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 1s 912us/step - loss: 0.7903\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7901\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7899\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 1s 875us/step - loss: 0.7898\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 1s 857us/step - loss: 0.7894\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 1s 874us/step - loss: 0.7895\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 1s 858us/step - loss: 0.7894\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 0s 838us/step - loss: 0.7894\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 1s 847us/step - loss: 0.7893\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 0s 830us/step - loss: 0.7889\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 1s 848us/step - loss: 0.7890\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 1s 841us/step - loss: 0.7888\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 1s 848us/step - loss: 0.7892\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7889\n",
      "149/149 [==============================] - 0s 980us/step\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.140 total time=  11.9s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8718\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8062\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8036\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8019\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8012\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8007\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 879us/step - loss: 0.8001\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 896us/step - loss: 0.7999\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 875us/step - loss: 0.7994\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 879us/step - loss: 0.7994\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 869us/step - loss: 0.7992\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 902us/step - loss: 0.7990\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 869us/step - loss: 0.7987\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 865us/step - loss: 0.7987\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 859us/step - loss: 0.7986\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7982\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7984\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7982\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7980\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7982\n",
      "149/149 [==============================] - 0s 838us/step\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.520 total time=  12.9s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9139\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8574\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 995us/step - loss: 0.8560\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 896us/step - loss: 0.8553\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 899us/step - loss: 0.8547\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 889us/step - loss: 0.8541\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 877us/step - loss: 0.8540\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 896us/step - loss: 0.8538\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 886us/step - loss: 0.8536\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 880us/step - loss: 0.8533\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 891us/step - loss: 0.8528\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 966us/step - loss: 0.8530\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8529\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8528\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8525\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8523\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8521\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8522\n",
      "149/149 [==============================] - 0s 635us/step\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.350 total time=  13.0s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 870us/step - loss: 0.9246\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 859us/step - loss: 0.8616\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 862us/step - loss: 0.8592\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 867us/step - loss: 0.8582\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 872us/step - loss: 0.8579\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 865us/step - loss: 0.8576\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 877us/step - loss: 0.8574\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 865us/step - loss: 0.8568\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8567\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8568\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8564\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8558\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1000us/step - loss: 0.8558\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 867us/step - loss: 0.8558\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 889us/step - loss: 0.8558\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 850us/step - loss: 0.8556\n",
      "149/149 [==============================] - 0s 642us/step\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.420 total time=  12.4s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 887us/step - loss: 0.7383\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 896us/step - loss: 0.6892\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 882us/step - loss: 0.6861\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 884us/step - loss: 0.6849\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 921us/step - loss: 0.6846\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6841\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6838\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6834\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6836\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6835\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6832\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6834\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6831\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 896us/step - loss: 0.6829\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 879us/step - loss: 0.6831\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 884us/step - loss: 0.6829\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 870us/step - loss: 0.6827\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 918us/step - loss: 0.6828\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 865us/step - loss: 0.6828\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 889us/step - loss: 0.6827\n",
      "149/149 [==============================] - 0s 642us/step\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.010 total time=  12.5s\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 1s 884us/step - loss: 0.8438\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 1s 865us/step - loss: 0.7948\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7921\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7915\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7908\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7907\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7904\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7902\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7901\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7899\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7898\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 1s 885us/step - loss: 0.7896\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 1s 890us/step - loss: 0.7897\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 1s 863us/step - loss: 0.7894\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 1s 875us/step - loss: 0.7895\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 1s 872us/step - loss: 0.7895\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 1s 885us/step - loss: 0.7894\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 1s 865us/step - loss: 0.7893\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 1s 889us/step - loss: 0.7893\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 1s 872us/step - loss: 0.7895\n",
      "149/149 [==============================] - 0s 689us/step\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.120 total time=  12.4s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8696\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8055\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8033\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8024\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8017\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8013\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8008\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 929us/step - loss: 0.8001\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 901us/step - loss: 0.8000\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 897us/step - loss: 0.7998\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 896us/step - loss: 0.7994\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 886us/step - loss: 0.7994\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 887us/step - loss: 0.7992\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 891us/step - loss: 0.7992\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 892us/step - loss: 0.7991\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 914us/step - loss: 0.7989\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 981us/step - loss: 0.7989\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7987\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7988\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7987\n",
      "149/149 [==============================] - 0s 892us/step\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.470 total time=  13.4s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9207\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8579\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8558\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 933us/step - loss: 0.8551\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 880us/step - loss: 0.8546\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 865us/step - loss: 0.8543\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 894us/step - loss: 0.8538\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 867us/step - loss: 0.8537\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 879us/step - loss: 0.8534\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 879us/step - loss: 0.8534\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 877us/step - loss: 0.8534\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 864us/step - loss: 0.8531\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 960us/step - loss: 0.8530\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8529\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8528\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8528\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
      "149/149 [==============================] - 0s 791us/step\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.350 total time=  12.9s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 872us/step - loss: 0.9110\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 870us/step - loss: 0.8608\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 882us/step - loss: 0.8593\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 869us/step - loss: 0.8582\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 877us/step - loss: 0.8578\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 886us/step - loss: 0.8571\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 865us/step - loss: 0.8568\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 872us/step - loss: 0.8567\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 874us/step - loss: 0.8566\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8558\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8555\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 968us/step - loss: 0.8551\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 886us/step - loss: 0.8553\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 872us/step - loss: 0.8554\n",
      "149/149 [==============================] - 0s 676us/step\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.420 total time=  12.4s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 892us/step - loss: 0.7276\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 884us/step - loss: 0.6884\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 897us/step - loss: 0.6857\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 887us/step - loss: 0.6849\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 882us/step - loss: 0.6844\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1000us/step - loss: 0.6840\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6838\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6833\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6835\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6832\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6833\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6833\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6832\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6831\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 882us/step - loss: 0.6831\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 897us/step - loss: 0.6829\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 897us/step - loss: 0.6830\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 896us/step - loss: 0.6827\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 879us/step - loss: 0.6827\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 896us/step - loss: 0.6828\n",
      "149/149 [==============================] - 0s 682us/step\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.010 total time=  12.5s\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 1s 899us/step - loss: 0.8395\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 1s 880us/step - loss: 0.7962\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7933\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7922\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7912\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7911\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7904\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7904\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7902\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7899\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 1s 924us/step - loss: 0.7897\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 1s 877us/step - loss: 0.7896\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 1s 889us/step - loss: 0.7895\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 1s 868us/step - loss: 0.7896\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 1s 879us/step - loss: 0.7893\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 1s 884us/step - loss: 0.7893\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 1s 902us/step - loss: 0.7893\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 1s 879us/step - loss: 0.7893\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 1s 875us/step - loss: 0.7892\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 1s 981us/step - loss: 0.7892\n",
      "149/149 [==============================] - 0s 865us/step\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.150 total time=  12.5s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8650\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 968us/step - loss: 0.8050\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8034\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8023\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8016\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8007\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 949us/step - loss: 0.8003\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 848us/step - loss: 0.8000\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 0s 822us/step - loss: 0.7998\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 845us/step - loss: 0.7993\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 0s 837us/step - loss: 0.7995\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 842us/step - loss: 0.7991\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 0s 832us/step - loss: 0.7990\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 862us/step - loss: 0.7988\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 0s 805us/step - loss: 0.7989\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 840us/step - loss: 0.7988\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 843us/step - loss: 0.7988\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 997us/step - loss: 0.7985\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7986\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 993us/step - loss: 0.7982\n",
      "149/149 [==============================] - 0s 662us/step\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.480 total time=  11.6s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9084\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8571\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8551\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 929us/step - loss: 0.8547\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 880us/step - loss: 0.8545\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 865us/step - loss: 0.8543\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 877us/step - loss: 0.8538\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 850us/step - loss: 0.8536\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 906us/step - loss: 0.8533\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 869us/step - loss: 0.8533\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 880us/step - loss: 0.8528\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 860us/step - loss: 0.8528\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 955us/step - loss: 0.8528\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8527\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8525\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8525\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
      "149/149 [==============================] - 0s 851us/step\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.350 total time=  13.1s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 976us/step - loss: 0.9237\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 891us/step - loss: 0.8620\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 891us/step - loss: 0.8595\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 887us/step - loss: 0.8584\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 912us/step - loss: 0.8581\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 907us/step - loss: 0.8575\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 887us/step - loss: 0.8570\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 884us/step - loss: 0.8567\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 894us/step - loss: 0.8563\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 960us/step - loss: 0.8563\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8559\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8553\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8552\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 914us/step - loss: 0.8553\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 894us/step - loss: 0.8552\n",
      "149/149 [==============================] - 0s 635us/step\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.410 total time=  12.7s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 892us/step - loss: 0.7227\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 862us/step - loss: 0.6878\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 869us/step - loss: 0.6858\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 886us/step - loss: 0.6855\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 872us/step - loss: 0.6852\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 872us/step - loss: 0.6849\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 860us/step - loss: 0.6845\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 887us/step - loss: 0.6844\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 872us/step - loss: 0.6841\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6842\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6836\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6837\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6835\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6835\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6834\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6834\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6833\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 948us/step - loss: 0.6833\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 867us/step - loss: 0.6832\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 875us/step - loss: 0.6833\n",
      "149/149 [==============================] - 0s 628us/step\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.010 total time=  12.4s\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 1s 865us/step - loss: 0.8309\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 1s 895us/step - loss: 0.7953\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 1s 863us/step - loss: 0.7927\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 1s 882us/step - loss: 0.7920\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 1s 879us/step - loss: 0.7913\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 1s 978us/step - loss: 0.7906\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7906\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7903\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7899\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7899\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7897\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7895\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7896\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7896\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 1s 879us/step - loss: 0.7894\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 1s 841us/step - loss: 0.7893\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 1s 860us/step - loss: 0.7894\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 1s 860us/step - loss: 0.7893\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 1s 858us/step - loss: 0.7893\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 1s 858us/step - loss: 0.7889\n",
      "149/149 [==============================] - 0s 649us/step\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.130 total time=  12.2s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 886us/step - loss: 0.8712\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 899us/step - loss: 0.8057\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8032\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8024\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8017\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8012\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8007\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8003\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7998\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7997\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7995\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 906us/step - loss: 0.7996\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 889us/step - loss: 0.7992\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 891us/step - loss: 0.7989\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 891us/step - loss: 0.7990\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 894us/step - loss: 0.7987\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 891us/step - loss: 0.7987\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 892us/step - loss: 0.7986\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 892us/step - loss: 0.7986\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 891us/step - loss: 0.7983\n",
      "149/149 [==============================] - 0s 939us/step\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.450 total time=  12.7s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9144\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 993us/step - loss: 0.8570\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8559\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8547\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8545\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8541\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 904us/step - loss: 0.8539\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 887us/step - loss: 0.8536\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 907us/step - loss: 0.8534\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 901us/step - loss: 0.8530\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 877us/step - loss: 0.8534\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 906us/step - loss: 0.8530\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 880us/step - loss: 0.8527\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 894us/step - loss: 0.8528\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 892us/step - loss: 0.8526\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8525\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8528\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8524\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.350 total time=  13.2s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9166\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8607\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8591\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 894us/step - loss: 0.8583\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 914us/step - loss: 0.8575\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 899us/step - loss: 0.8571\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 892us/step - loss: 0.8570\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 901us/step - loss: 0.8566\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 901us/step - loss: 0.8563\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 892us/step - loss: 0.8563\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 875us/step - loss: 0.8559\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 894us/step - loss: 0.8557\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8555\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8551\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8549\n",
      "149/149 [==============================] - 0s 777us/step\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.390 total time=  13.2s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 887us/step - loss: 0.7316\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 882us/step - loss: 0.6882\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 906us/step - loss: 0.6859\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 884us/step - loss: 0.6854\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 891us/step - loss: 0.6850\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 897us/step - loss: 0.6843\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 886us/step - loss: 0.6841\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 892us/step - loss: 0.6840\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 897us/step - loss: 0.6837\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6838\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6838\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6838\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6837\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6833\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6835\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6833\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6835\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 877us/step - loss: 0.6833\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 894us/step - loss: 0.6830\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 882us/step - loss: 0.6830\n",
      "149/149 [==============================] - 0s 642us/step\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.010 total time=  12.6s\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 1s 847us/step - loss: 0.8424\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 1s 879us/step - loss: 0.7960\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 1s 865us/step - loss: 0.7932\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 1s 863us/step - loss: 0.7920\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 1s 843us/step - loss: 0.7915\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7909\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7907\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7904\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7901\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7900\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7897\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7898\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7893\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7897\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 1s 882us/step - loss: 0.7894\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 1s 890us/step - loss: 0.7892\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 1s 860us/step - loss: 0.7893\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 1s 867us/step - loss: 0.7892\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 1s 867us/step - loss: 0.7890\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 1s 858us/step - loss: 0.7892\n",
      "149/149 [==============================] - 0s 709us/step\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.110 total time=  12.3s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 907us/step - loss: 0.8657\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 924us/step - loss: 0.8048\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8027\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8021\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8012\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8007\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8007\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8001\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7999\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7998\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 983us/step - loss: 0.7994\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 882us/step - loss: 0.7994\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 897us/step - loss: 0.7991\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 886us/step - loss: 0.7992\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 896us/step - loss: 0.7990\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 884us/step - loss: 0.7989\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 889us/step - loss: 0.7989\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 877us/step - loss: 0.7987\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 926us/step - loss: 0.7986\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 990us/step - loss: 0.7985\n",
      "149/149 [==============================] - 0s 885us/step\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.500 total time=  12.7s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9154\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8578\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8558\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8553\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 0s 806us/step - loss: 0.8548\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 902us/step - loss: 0.8545\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8544\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8541\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 981us/step - loss: 0.8538\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 870us/step - loss: 0.8539\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 901us/step - loss: 0.8535\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 884us/step - loss: 0.8533\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 884us/step - loss: 0.8531\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 929us/step - loss: 0.8532\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 891us/step - loss: 0.8533\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 889us/step - loss: 0.8530\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 887us/step - loss: 0.8528\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8528\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
      "149/149 [==============================] - 0s 932us/step\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.420 total time=  12.9s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9121\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8606\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8589\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8582\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8578\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 891us/step - loss: 0.8574\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 892us/step - loss: 0.8568\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 904us/step - loss: 0.8566\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 929us/step - loss: 0.8563\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 884us/step - loss: 0.8561\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 897us/step - loss: 0.8558\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 897us/step - loss: 0.8557\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 894us/step - loss: 0.8556\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 882us/step - loss: 0.8557\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8553\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8555\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8553\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8551\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8549\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8550\n",
      "149/149 [==============================] - 0s 973us/step\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.410 total time=  13.1s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7325\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 904us/step - loss: 0.6886\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 884us/step - loss: 0.6862\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 918us/step - loss: 0.6853\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 896us/step - loss: 0.6846\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 944us/step - loss: 0.6844\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 924us/step - loss: 0.6841\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 906us/step - loss: 0.6839\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 914us/step - loss: 0.6839\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 901us/step - loss: 0.6837\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6835\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6834\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6833\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6834\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6832\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6833\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6831\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6831\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 919us/step - loss: 0.6832\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 923us/step - loss: 0.6832\n",
      "149/149 [==============================] - 0s 696us/step\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.010 total time=  12.9s\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 1s 995us/step - loss: 0.8230\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 1s 985us/step - loss: 0.7950\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 1s 998us/step - loss: 0.7930\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 1s 992us/step - loss: 0.7922\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 1s 995us/step - loss: 0.7913\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7908\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7907\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7910\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7905\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7904\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7901\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7901\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7901\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7902\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 1s 985us/step - loss: 0.7901\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 1s 971us/step - loss: 0.7901\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 1s 987us/step - loss: 0.7901\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 1s 997us/step - loss: 0.7898\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 1s 997us/step - loss: 0.7898\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 1s 986us/step - loss: 0.7898\n",
      "149/149 [==============================] - 0s 709us/step\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.080 total time=  13.9s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8471\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8062\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8039\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8023\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8014\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8009\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8004\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8000\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8001\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7995\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7997\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7994\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7995\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7990\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7991\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7991\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.470 total time=  15.3s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8886\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8586\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8569\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8550\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8547\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8542\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8540\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8536\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8537\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8533\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8532\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8532\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8529\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8525\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8524\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 956us/step - loss: 0.8524\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 998us/step - loss: 0.8525\n",
      "149/149 [==============================] - 0s 743us/step\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.350 total time=  14.6s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8997\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8609\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8595\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8583\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8578\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8570\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8567\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8567\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8559\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8559\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8558\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8555\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
      "149/149 [==============================] - 0s 953us/step\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.410 total time=  14.7s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 2s 1ms/step - loss: 0.7110\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6882\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6867\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6861\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6851\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6853\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6849\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6845\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6845\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6846\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6843\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6843\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6843\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6837\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6840\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6841\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6838\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6838\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6836\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6835\n",
      "149/149 [==============================] - 0s 784us/step\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.010 total time=  15.9s\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8237\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 1s 992us/step - loss: 0.7951\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7931\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 1s 998us/step - loss: 0.7923\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 1s 980us/step - loss: 0.7914\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7909\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7908\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7907\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7903\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7901\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7900\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7901\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7898\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7896\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7899\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 1s 988us/step - loss: 0.7894\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7898\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 1s 987us/step - loss: 0.7896\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7894\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 1s 983us/step - loss: 0.7894\n",
      "149/149 [==============================] - 0s 730us/step\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.100 total time=  14.0s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8394\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8049\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8031\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8023\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8014\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8010\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8009\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8001\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 993us/step - loss: 0.8003\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 998us/step - loss: 0.7999\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7996\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7993\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 998us/step - loss: 0.7992\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7994\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 997us/step - loss: 0.7994\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7993\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7989\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7989\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7990\n",
      "149/149 [==============================] - 0s 953us/step\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.500 total time=  15.1s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8890\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8583\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 980us/step - loss: 0.8569\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 963us/step - loss: 0.8558\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 975us/step - loss: 0.8550\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 966us/step - loss: 0.8548\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 973us/step - loss: 0.8543\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 980us/step - loss: 0.8542\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 981us/step - loss: 0.8539\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8539\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8535\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8534\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8535\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8533\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8533\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8529\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8531\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8531\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8529\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8529\n",
      "149/149 [==============================] - 0s 689us/step\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.340 total time=  13.8s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8931\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8612\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8597\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8585\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8576\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8572\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8571\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8566\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8566\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8559\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8558\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1000us/step - loss: 0.8558\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8558\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8558\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
      "149/149 [==============================] - 0s 980us/step\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.420 total time=  14.4s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7156\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6879\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6869\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6861\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6855\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6854\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6848\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6848\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6848\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6845\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6844\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6843\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 998us/step - loss: 0.6843\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6843\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6841\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6841\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6839\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6838\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6838\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6838\n",
      "149/149 [==============================] - 0s 905us/step\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.010 total time=  15.5s\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 1s 990us/step - loss: 0.8190\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 1s 993us/step - loss: 0.7942\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 1s 993us/step - loss: 0.7923\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 1s 995us/step - loss: 0.7918\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 1s 998us/step - loss: 0.7912\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 1s 980us/step - loss: 0.7910\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 1s 993us/step - loss: 0.7906\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7905\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7900\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7901\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7901\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7897\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7899\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7897\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7897\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 1s 992us/step - loss: 0.7898\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 1s 970us/step - loss: 0.7896\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7897\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 1s 978us/step - loss: 0.7895\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 1s 990us/step - loss: 0.7894\n",
      "149/149 [==============================] - 0s 723us/step\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.130 total time=  13.8s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 995us/step - loss: 0.8452\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8051\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8033\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8022\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8012\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8007\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8005\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8002\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7999\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7996\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7991\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 995us/step - loss: 0.7991\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 997us/step - loss: 0.7992\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7988\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7987\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7988\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7985\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7987\n",
      "149/149 [==============================] - 0s 986us/step\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.470 total time=  14.8s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8944\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8589\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8566\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8558\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 983us/step - loss: 0.8550\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 995us/step - loss: 0.8548\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 998us/step - loss: 0.8543\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8540\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 995us/step - loss: 0.8539\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 997us/step - loss: 0.8536\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 992us/step - loss: 0.8534\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8534\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8534\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8532\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8531\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8527\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8529\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 988us/step - loss: 0.8527\n",
      "149/149 [==============================] - 0s 757us/step\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.370 total time=  14.5s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9024\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8615\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8599\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8590\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8580\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8575\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 998us/step - loss: 0.8569\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8565\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8566\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8559\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8555\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1000us/step - loss: 0.8556\n",
      "149/149 [==============================] - 0s 709us/step\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.410 total time=  14.1s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7186\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6879\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6867\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6861\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6852\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6854\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6847\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6847\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6844\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6844\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6839\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6842\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6837\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 993us/step - loss: 0.6838\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6840\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6837\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6836\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6834\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6836\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6834\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.010 total time=  14.7s\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8249\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7949\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7930\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7922\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7915\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 1s 983us/step - loss: 0.7907\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7908\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 1s 981us/step - loss: 0.7904\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 1s 987us/step - loss: 0.7900\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7898\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 1s 975us/step - loss: 0.7899\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7896\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7895\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7897\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7896\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7894\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7894\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7896\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7894\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 1s 983us/step - loss: 0.7896\n",
      "149/149 [==============================] - 0s 696us/step\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.120 total time=  14.6s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8398\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8056\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8034\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 992us/step - loss: 0.8023\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8018\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8005\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8004\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7997\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7999\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7997\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7996\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7993\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7993\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 995us/step - loss: 0.7990\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7990\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 998us/step - loss: 0.7987\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7986\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7985\n",
      "149/149 [==============================] - 0s 743us/step\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.510 total time=  14.2s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8898\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8577\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8566\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8553\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8549\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8543\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8540\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8535\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8537\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8533\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 997us/step - loss: 0.8532\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8533\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8529\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8529\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8527\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8525\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8528\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8527\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8525\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.370 total time=  14.9s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8981\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8609\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8592\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1000us/step - loss: 0.8582\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8575\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8572\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8569\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8563\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8563\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 998us/step - loss: 0.8562\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 992us/step - loss: 0.8561\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8558\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8558\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8555\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8555\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8553\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1000us/step - loss: 0.8554\n",
      "149/149 [==============================] - 0s 682us/step\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.450 total time=  14.8s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7165\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6883\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6869\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 993us/step - loss: 0.6861\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6859\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6856\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6852\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6850\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6847\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6844\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6841\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6841\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6838\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6840\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 993us/step - loss: 0.6838\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6838\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6837\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6840\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6839\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6837\n",
      "149/149 [==============================] - 0s 736us/step\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.010 total time=  14.1s\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8279\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7946\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7925\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7918\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7915\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7910\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7907\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 1s 998us/step - loss: 0.7906\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7906\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7904\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 1s 987us/step - loss: 0.7901\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 1s 1000us/step - loss: 0.7903\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 1s 990us/step - loss: 0.7902\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7900\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7901\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7902\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7898\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7897\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7897\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7897\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.140 total time=  14.9s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8418\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8062\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8037\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 997us/step - loss: 0.8025\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8016\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8013\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8010\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 995us/step - loss: 0.8002\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8001\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7998\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7998\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7994\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7991\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7991\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7993\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7989\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7988\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 995us/step - loss: 0.7992\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7988\n",
      "149/149 [==============================] - 0s 757us/step\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.480 total time=  14.3s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8911\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8589\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 997us/step - loss: 0.8571\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8555\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8547\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8545\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8544\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8540\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8537\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8537\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8534\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1000us/step - loss: 0.8532\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8534\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 992us/step - loss: 0.8530\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8528\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8529\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8529\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8527\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8529\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.370 total time=  14.2s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8959\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8608\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8593\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8584\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8581\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8571\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8570\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8567\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 997us/step - loss: 0.8565\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1000us/step - loss: 0.8563\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8558\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8555\n",
      "149/149 [==============================] - 0s 736us/step\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.420 total time=  15.2s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7109\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6882\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6868\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6858\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6856\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6853\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6853\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6846\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6844\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6844\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6843\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6842\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6841\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6839\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6838\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6837\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6831\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6837\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6833\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6835\n",
      "149/149 [==============================] - 0s 709us/step\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.010 total time=  14.2s\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8228\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7951\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7932\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7925\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7912\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7912\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7909\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7906\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 1s 1000us/step - loss: 0.7905\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 1s 993us/step - loss: 0.7904\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 1s 988us/step - loss: 0.7903\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7900\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7901\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 1s 987us/step - loss: 0.7901\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 1s 997us/step - loss: 0.7899\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 1s 988us/step - loss: 0.7901\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7900\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7895\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7896\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7895\n",
      "149/149 [==============================] - 0s 973us/step\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.140 total time=  14.8s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8478\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8054\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8038\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8023\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8015\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8011\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8007\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8001\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8001\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7998\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7995\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7997\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7996\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7991\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7988\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7990\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7990\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7991\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7985\n",
      "149/149 [==============================] - 0s 730us/step\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.520 total time=  14.8s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8914\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8584\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8573\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8559\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8550\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8541\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8544\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8540\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8538\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8535\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8534\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 928us/step - loss: 0.8532\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 891us/step - loss: 0.8532\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 978us/step - loss: 0.8530\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8528\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8529\n",
      "149/149 [==============================] - 0s 730us/step\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.350 total time=  14.1s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8978\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8614\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8592\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8587\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8579\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8576\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8571\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8569\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8564\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8563\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8559\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8559\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8558\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8555\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
      "149/149 [==============================] - 0s 912us/step\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.420 total time=  15.1s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 2s 1ms/step - loss: 0.7189\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6880\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1000us/step - loss: 0.6869\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6860\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6859\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6856\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6849\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 995us/step - loss: 0.6848\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6845\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6844\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6845\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6840\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6841\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6841\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6839\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6841\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6840\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6838\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6838\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6840\n",
      "149/149 [==============================] - 0s 743us/step\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.010 total time=  15.0s\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8268\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 1s 1000us/step - loss: 0.7949\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 1s 987us/step - loss: 0.7926\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 1s 981us/step - loss: 0.7918\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7914\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7909\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7907\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7903\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7903\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7898\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7901\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7899\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 1s 993us/step - loss: 0.7897\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7898\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 1s 987us/step - loss: 0.7898\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 1s 997us/step - loss: 0.7897\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 1s 985us/step - loss: 0.7895\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 1s 998us/step - loss: 0.7897\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7898\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7898\n",
      "149/149 [==============================] - 0s 919us/step\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.110 total time=  14.0s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8399\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8061\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8036\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8022\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8015\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8011\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8005\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8003\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7999\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1000us/step - loss: 0.7996\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7995\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7993\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7990\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7994\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7991\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7991\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7990\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7991\n",
      "149/149 [==============================] - 0s 777us/step\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.460 total time=  15.1s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8967\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 993us/step - loss: 0.8581\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 997us/step - loss: 0.8557\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8551\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8542\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8540\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8539\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8535\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8535\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8534\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8533\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8531\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8532\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8529\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8525\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8528\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
      "149/149 [==============================] - 0s 696us/step\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.300 total time=  14.0s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8900\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 997us/step - loss: 0.8615\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8595\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8586\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8580\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8571\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8569\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8567\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8564\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1000us/step - loss: 0.8562\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 990us/step - loss: 0.8556\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1000us/step - loss: 0.8558\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8555\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8551\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8552\n",
      "149/149 [==============================] - 0s 939us/step\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.410 total time=  14.6s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7129\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6885\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6871\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6862\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6859\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6855\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1000us/step - loss: 0.6849\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6851\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6845\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 998us/step - loss: 0.6846\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6845\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6842\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6841\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6842\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6843\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6840\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6840\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6841\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6840\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6841\n",
      "149/149 [==============================] - 0s 709us/step\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.010 total time=  14.9s\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 1s 993us/step - loss: 0.8233\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 1s 985us/step - loss: 0.7953\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 1s 993us/step - loss: 0.7938\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 1s 976us/step - loss: 0.7923\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 1s 985us/step - loss: 0.7919\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 1s 998us/step - loss: 0.7914\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7906\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7904\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7903\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7903\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7902\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7904\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7902\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7900\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 1s 988us/step - loss: 0.7897\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 1s 988us/step - loss: 0.7901\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 1s 997us/step - loss: 0.7900\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 1s 990us/step - loss: 0.7900\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 1s 993us/step - loss: 0.7900\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 1s 981us/step - loss: 0.7900\n",
      "149/149 [==============================] - 0s 709us/step\n",
      "[CV 1/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.090 total time=  13.8s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8380\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8053\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8033\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8019\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8016\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8009\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8003\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8006\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7999\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7996\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7993\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7991\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7988\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7988\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7988\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7987\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7988\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7986\n",
      "149/149 [==============================] - 0s 757us/step\n",
      "[CV 2/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.470 total time=  14.9s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8950\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8590\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8571\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 998us/step - loss: 0.8561\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 998us/step - loss: 0.8556\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8549\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 997us/step - loss: 0.8545\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8543\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8537\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1000us/step - loss: 0.8539\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8536\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8532\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8532\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8532\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8531\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8528\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8529\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8528\n",
      "149/149 [==============================] - 0s 709us/step\n",
      "[CV 3/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.300 total time=  14.5s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9017\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8615\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8599\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8586\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8581\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8578\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8570\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8569\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8567\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8565\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8566\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8565\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 918us/step - loss: 0.8557\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 914us/step - loss: 0.8560\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 923us/step - loss: 0.8559\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 911us/step - loss: 0.8558\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 968us/step - loss: 0.8558\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
      "149/149 [==============================] - 0s 716us/step\n",
      "[CV 4/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.420 total time=  14.3s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7152\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6880\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6866\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6863\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6858\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6854\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6850\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6846\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 997us/step - loss: 0.6846\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6844\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6844\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 997us/step - loss: 0.6843\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6842\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6840\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6840\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6839\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6841\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6840\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6840\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6842\n",
      "149/149 [==============================] - 0s 993us/step\n",
      "[CV 5/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.010 total time=  15.1s\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9546\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 1s 936us/step - loss: 0.8764\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 1s 911us/step - loss: 0.8367\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 1s 899us/step - loss: 0.8180\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 1s 906us/step - loss: 0.8086\n",
      "149/149 [==============================] - 0s 689us/step\n",
      "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.080 total time=   3.5s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 907us/step - loss: 1.0125\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 955us/step - loss: 0.9215\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 914us/step - loss: 0.8585\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 919us/step - loss: 0.8281\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8136\n",
      "149/149 [==============================] - 0s 993us/step\n",
      "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.480 total time=   3.6s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0619\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9560\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8937\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8729\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8650\n",
      "149/149 [==============================] - 0s 750us/step\n",
      "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.300 total time=   4.2s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 914us/step - loss: 1.0590\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 911us/step - loss: 0.9621\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 901us/step - loss: 0.9025\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 918us/step - loss: 0.8797\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 916us/step - loss: 0.8702\n",
      "149/149 [==============================] - 0s 709us/step\n",
      "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.410 total time=   3.2s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 921us/step - loss: 0.8807\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 918us/step - loss: 0.7666\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7195\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6999\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6929\n",
      "149/149 [==============================] - 0s 851us/step\n",
      "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.000 total time=   3.8s\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9491\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8729\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8334\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8168\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 1s 852us/step - loss: 0.8080\n",
      "149/149 [==============================] - 0s 615us/step\n",
      "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.080 total time=   4.0s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 911us/step - loss: 1.0071\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 933us/step - loss: 0.9183\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 960us/step - loss: 0.8581\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 931us/step - loss: 0.8289\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 918us/step - loss: 0.8140\n",
      "149/149 [==============================] - 0s 676us/step\n",
      "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.460 total time=   3.3s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 916us/step - loss: 1.0627\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 912us/step - loss: 0.9593\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8948\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8743\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8663\n",
      "149/149 [==============================] - 0s 946us/step\n",
      "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.300 total time=   3.8s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0633\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9691\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9045\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 993us/step - loss: 0.8799\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 943us/step - loss: 0.8698\n",
      "149/149 [==============================] - 0s 709us/step\n",
      "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.420 total time=   4.0s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 951us/step - loss: 0.8789\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 902us/step - loss: 0.7713\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 909us/step - loss: 0.7220\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 912us/step - loss: 0.7022\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 911us/step - loss: 0.6947\n",
      "149/149 [==============================] - 0s 655us/step\n",
      "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.000 total time=   3.3s\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 1s 916us/step - loss: 0.9541\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8773\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8351\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8170\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8081\n",
      "149/149 [==============================] - 0s 919us/step\n",
      "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.080 total time=   4.0s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0102\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9229\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8606\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 944us/step - loss: 0.8311\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 921us/step - loss: 0.8163\n",
      "149/149 [==============================] - 0s 676us/step\n",
      "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.460 total time=   3.9s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 923us/step - loss: 1.0666\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 928us/step - loss: 0.9684\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 916us/step - loss: 0.8995\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 928us/step - loss: 0.8751\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 921us/step - loss: 0.8657\n",
      "149/149 [==============================] - 0s 682us/step\n",
      "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.300 total time=   3.3s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0624\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9669\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9027\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8783\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8692\n",
      "149/149 [==============================] - 0s 973us/step\n",
      "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.380 total time=   4.3s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8802\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7706\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 957us/step - loss: 0.7234\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 966us/step - loss: 0.7022\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 963us/step - loss: 0.6944\n",
      "149/149 [==============================] - 0s 716us/step\n",
      "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.000 total time=   3.8s\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 1s 971us/step - loss: 0.9578\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 1s 956us/step - loss: 0.8785\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 1s 978us/step - loss: 0.8361\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8171\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8070\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.080 total time=   3.8s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0096\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9200\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8594\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8300\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8154\n",
      "149/149 [==============================] - 0s 763us/step\n",
      "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.460 total time=   4.5s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 949us/step - loss: 1.0629\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9600\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 956us/step - loss: 0.8964\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 968us/step - loss: 0.8744\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 939us/step - loss: 0.8660\n",
      "149/149 [==============================] - 0s 676us/step\n",
      "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.300 total time=   3.5s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0576\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9599\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9010\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8790\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8702\n",
      "149/149 [==============================] - 0s 872us/step\n",
      "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.380 total time=   4.5s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8739\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7667\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7215\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 919us/step - loss: 0.7013\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 909us/step - loss: 0.6942\n",
      "149/149 [==============================] - 0s 709us/step\n",
      "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.000 total time=   3.8s\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 1s 885us/step - loss: 0.9499\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 1s 902us/step - loss: 0.8730\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 1s 887us/step - loss: 0.8346\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 1s 892us/step - loss: 0.8175\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 1s 879us/step - loss: 0.8088\n",
      "149/149 [==============================] - 0s 723us/step\n",
      "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.090 total time=   3.2s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0094\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9184\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8589\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8304\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8157\n",
      "149/149 [==============================] - 0s 926us/step\n",
      "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.460 total time=   4.5s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0609\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 926us/step - loss: 0.9574\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 906us/step - loss: 0.8947\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 916us/step - loss: 0.8741\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 924us/step - loss: 0.8660\n",
      "149/149 [==============================] - 0s 676us/step\n",
      "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.300 total time=   3.4s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 931us/step - loss: 1.0577\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 919us/step - loss: 0.9584\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 951us/step - loss: 0.9023\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8799\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8699\n",
      "149/149 [==============================] - 0s 993us/step\n",
      "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.380 total time=   3.8s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8711\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7644\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7199\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7016\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6948\n",
      "149/149 [==============================] - 0s 696us/step\n",
      "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.000 total time=   4.3s\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 1s 892us/step - loss: 0.9558\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 1s 911us/step - loss: 0.8795\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 1s 882us/step - loss: 0.8356\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 1s 895us/step - loss: 0.8163\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 1s 895us/step - loss: 0.8073\n",
      "149/149 [==============================] - 0s 676us/step\n",
      "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.080 total time=   3.2s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 909us/step - loss: 1.0087\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 981us/step - loss: 0.9182\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8582\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8297\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8149\n",
      "149/149 [==============================] - 0s 959us/step\n",
      "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.490 total time=   3.9s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0623\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9613\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8977\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8756\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 902us/step - loss: 0.8658\n",
      "149/149 [==============================] - 0s 655us/step\n",
      "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.350 total time=   4.0s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 921us/step - loss: 1.0631\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 941us/step - loss: 0.9691\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 933us/step - loss: 0.9036\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 931us/step - loss: 0.8784\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 931us/step - loss: 0.8689\n",
      "149/149 [==============================] - 0s 662us/step\n",
      "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.410 total time=   3.3s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8802\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7680\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7176\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7001\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6933\n",
      "149/149 [==============================] - 0s 946us/step\n",
      "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.000 total time=   4.2s\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9514\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8764\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 1s 939us/step - loss: 0.8348\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 1s 894us/step - loss: 0.8165\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 1s 911us/step - loss: 0.8069\n",
      "149/149 [==============================] - 0s 682us/step\n",
      "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.080 total time=   3.6s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 918us/step - loss: 1.0094\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 924us/step - loss: 0.9196\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 919us/step - loss: 0.8550\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 904us/step - loss: 0.8273\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 921us/step - loss: 0.8152\n",
      "149/149 [==============================] - 0s 973us/step\n",
      "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.460 total time=   3.3s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0630\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9647\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8990\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8736\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8642\n",
      "149/149 [==============================] - 0s 986us/step\n",
      "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.300 total time=   4.5s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0618\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 906us/step - loss: 0.9631\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 921us/step - loss: 0.9017\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 919us/step - loss: 0.8796\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 906us/step - loss: 0.8705\n",
      "149/149 [==============================] - 0s 669us/step\n",
      "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.380 total time=   3.3s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 894us/step - loss: 0.8733\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 921us/step - loss: 0.7677\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 909us/step - loss: 0.7222\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7019\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6947\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.000 total time=   3.8s\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9534\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8687\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8323\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8157\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8079\n",
      "149/149 [==============================] - 0s 682us/step\n",
      "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.080 total time=   4.1s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 911us/step - loss: 1.0067\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 916us/step - loss: 0.9190\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 911us/step - loss: 0.8570\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 918us/step - loss: 0.8282\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 929us/step - loss: 0.8154\n",
      "149/149 [==============================] - 0s 696us/step\n",
      "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.450 total time=   3.3s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 914us/step - loss: 1.0588\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 990us/step - loss: 0.9563\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8938\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8728\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8646\n",
      "149/149 [==============================] - 0s 926us/step\n",
      "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.300 total time=   3.9s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0608\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9660\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9043\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8793\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 909us/step - loss: 0.8691\n",
      "149/149 [==============================] - 0s 669us/step\n",
      "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.380 total time=   3.9s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 926us/step - loss: 0.8748\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 919us/step - loss: 0.7656\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 916us/step - loss: 0.7175\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 911us/step - loss: 0.7005\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 912us/step - loss: 0.6941\n",
      "149/149 [==============================] - 0s 696us/step\n",
      "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.000 total time=   3.3s\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9678\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 1s 2ms/step - loss: 0.9206\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8620\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8302\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8186\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.060 total time=   5.1s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0302\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9813\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8921\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8491\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8358\n",
      "149/149 [==============================] - 0s 797us/step\n",
      "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.470 total time=   4.0s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0881\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0300\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9303\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8948\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8851\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.320 total time=   4.6s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 1.0839\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0334\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9376\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8989\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8873\n",
      "149/149 [==============================] - 0s 791us/step\n",
      "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.350 total time=   4.5s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8958\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8153\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7627\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7353\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7280\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.000 total time=   4.3s\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9679\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9211\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8630\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8309\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8190\n",
      "149/149 [==============================] - 0s 818us/step\n",
      "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.080 total time=   4.8s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0302\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9884\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9000\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8523\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8373\n",
      "149/149 [==============================] - 0s 797us/step\n",
      "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.480 total time=   3.9s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 2s 2ms/step - loss: 1.0886\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0373\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9345\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8959\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8858\n",
      "149/149 [==============================] - 0s 993us/step\n",
      "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.320 total time=   5.6s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0844\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0331\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9358\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8984\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8878\n",
      "149/149 [==============================] - 0s 818us/step\n",
      "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.390 total time=   3.9s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9052\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8164\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.7657\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7365\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7265\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.000 total time=   4.9s\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9689\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9180\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8613\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8305\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8183\n",
      "149/149 [==============================] - 0s 899us/step\n",
      "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.070 total time=   4.2s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0300\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9843\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8960\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8515\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8368\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.480 total time=   4.6s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0881\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 1.0359\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9349\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8965\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8864\n",
      "149/149 [==============================] - 0s 784us/step\n",
      "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.320 total time=   4.6s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0832\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0266\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9321\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8975\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8877\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.390 total time=   4.1s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9058\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8150\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7641\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7368\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7288\n",
      "149/149 [==============================] - 0s 777us/step\n",
      "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.000 total time=   4.8s\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9700\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9205\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8620\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8308\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8195\n",
      "149/149 [==============================] - 0s 838us/step\n",
      "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.080 total time=   3.8s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0328\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9853\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8949\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8496\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8365\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.480 total time=   5.1s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0876\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0267\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9318\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8967\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8863\n",
      "149/149 [==============================] - 0s 784us/step\n",
      "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.320 total time=   4.1s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0840\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0343\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9365\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8984\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8875\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.360 total time=   4.6s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.9019\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8158\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7659\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7386\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7303\n",
      "149/149 [==============================] - 0s 804us/step\n",
      "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.000 total time=   4.5s\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9706\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9203\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8627\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8312\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8193\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.070 total time=   4.1s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0324\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9861\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8968\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8499\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8361\n",
      "149/149 [==============================] - 0s 912us/step\n",
      "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.480 total time=   5.0s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0879\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0322\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9329\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8957\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8862\n",
      "149/149 [==============================] - 0s 777us/step\n",
      "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.310 total time=   3.9s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0839\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0363\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9380\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8981\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8868\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.350 total time=   5.1s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8979\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8194\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7708\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7362\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7276\n",
      "149/149 [==============================] - 0s 838us/step\n",
      "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.000 total time=   4.0s\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9697\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9240\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8664\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8319\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8187\n",
      "149/149 [==============================] - 0s 946us/step\n",
      "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.060 total time=   4.7s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 1.0314\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9872\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8999\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8518\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8368\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.470 total time=   4.5s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0882\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0343\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9338\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8973\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8875\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.320 total time=   4.4s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0837\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 1.0318\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.9339\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8976\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8871\n",
      "149/149 [==============================] - 0s 797us/step\n",
      "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.390 total time=   4.8s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8994\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8126\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7587\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7340\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7273\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.000 total time=   4.1s\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9693\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9214\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8641\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 1s 2ms/step - loss: 0.8314\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8191\n",
      "149/149 [==============================] - 0s 851us/step\n",
      "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.060 total time=   5.0s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0319\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9861\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8987\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8511\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8361\n",
      "149/149 [==============================] - 0s 811us/step\n",
      "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.470 total time=   4.0s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 2s 1ms/step - loss: 1.0883\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 1.0368\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9337\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8953\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8857\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.320 total time=   5.7s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0830\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0289\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9365\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9003\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8889\n",
      "149/149 [==============================] - 0s 770us/step\n",
      "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.390 total time=   3.9s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8981\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8159\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7650\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7356\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7283\n",
      "149/149 [==============================] - 0s 953us/step\n",
      "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.000 total time=   4.8s\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 1s 2ms/step - loss: 0.9700\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9212\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8653\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8318\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8188\n",
      "149/149 [==============================] - 0s 777us/step\n",
      "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.060 total time=   4.4s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0320\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9868\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8964\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8504\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8364\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.480 total time=   4.4s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 1.0873\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0287\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9332\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8979\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8877\n",
      "149/149 [==============================] - 0s 777us/step\n",
      "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.320 total time=   4.7s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0833\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0312\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9362\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9000\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8883\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.390 total time=   4.0s\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.9027\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8155\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7650\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7377\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7297\n",
      "149/149 [==============================] - 0s 993us/step\n",
      "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.000 total time=   5.1s\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 1s 895us/step - loss: 0.9492\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 1s 892us/step - loss: 0.8737\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 1s 907us/step - loss: 0.8328\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 1s 901us/step - loss: 0.8160\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 1s 902us/step - loss: 0.8074\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 1s 906us/step - loss: 0.8013\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 1s 894us/step - loss: 0.7976\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 1s 894us/step - loss: 0.7957\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7945\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7937\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7930\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7925\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7921\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7917\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7914\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7911\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7909\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 1s 897us/step - loss: 0.7907\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 1s 895us/step - loss: 0.7905\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 1s 885us/step - loss: 0.7903\n",
      "149/149 [==============================] - 0s 723us/step\n",
      "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.070 total time=  12.7s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 912us/step - loss: 1.0129\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 923us/step - loss: 0.9230\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 923us/step - loss: 0.8579\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 928us/step - loss: 0.8269\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8135\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8080\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8056\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8042\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 993us/step - loss: 0.8032\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 929us/step - loss: 0.8025\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 960us/step - loss: 0.8020\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 923us/step - loss: 0.8015\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 924us/step - loss: 0.8010\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 923us/step - loss: 0.8004\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 951us/step - loss: 0.8000\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7996\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7989\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7987\n",
      "149/149 [==============================] - 0s 682us/step\n",
      "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.460 total time=  13.1s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0630\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 916us/step - loss: 0.9635\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 934us/step - loss: 0.8974\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 923us/step - loss: 0.8753\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 923us/step - loss: 0.8674\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 926us/step - loss: 0.8624\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 924us/step - loss: 0.8589\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8567\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8547\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8543\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8540\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8537\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8536\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8535\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 928us/step - loss: 0.8533\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 976us/step - loss: 0.8532\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 928us/step - loss: 0.8531\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 918us/step - loss: 0.8531\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 921us/step - loss: 0.8530\n",
      "149/149 [==============================] - 0s 669us/step\n",
      "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.350 total time=  13.2s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 943us/step - loss: 1.0596\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 919us/step - loss: 0.9620\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9026\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8793\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8697\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8649\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8621\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8604\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8592\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8584\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 998us/step - loss: 0.8579\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 914us/step - loss: 0.8574\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 924us/step - loss: 0.8571\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 928us/step - loss: 0.8568\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 921us/step - loss: 0.8566\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 953us/step - loss: 0.8564\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8563\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 961us/step - loss: 0.8560\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
      "149/149 [==============================] - 0s 966us/step\n",
      "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.420 total time=  13.6s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8701\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7671\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7213\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7021\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6950\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6910\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 936us/step - loss: 0.6888\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 904us/step - loss: 0.6872\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 923us/step - loss: 0.6863\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 926us/step - loss: 0.6856\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 916us/step - loss: 0.6851\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 921us/step - loss: 0.6847\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 921us/step - loss: 0.6843\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 919us/step - loss: 0.6839\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6838\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6836\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6834\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6832\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6831\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6829\n",
      "149/149 [==============================] - 0s 926us/step\n",
      "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.010 total time=  13.8s\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9488\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 1s 914us/step - loss: 0.8759\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 1s 911us/step - loss: 0.8363\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 1s 904us/step - loss: 0.8174\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 1s 926us/step - loss: 0.8074\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 1s 899us/step - loss: 0.8019\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 1s 921us/step - loss: 0.7986\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 1s 897us/step - loss: 0.7962\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 1s 914us/step - loss: 0.7945\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 1s 953us/step - loss: 0.7934\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7925\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7919\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7915\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7911\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7908\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7906\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7903\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7902\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 0s 831us/step - loss: 0.7900\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 1s 890us/step - loss: 0.7899\n",
      "149/149 [==============================] - 0s 757us/step\n",
      "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.100 total time=  12.9s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0106\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 892us/step - loss: 0.9224\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 906us/step - loss: 0.8583\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 907us/step - loss: 0.8273\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 896us/step - loss: 0.8146\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 902us/step - loss: 0.8085\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 973us/step - loss: 0.8056\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8039\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8029\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8020\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8015\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8012\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8007\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8004\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8001\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7998\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 973us/step - loss: 0.7995\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7994\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 891us/step - loss: 0.7990\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 887us/step - loss: 0.7990\n",
      "149/149 [==============================] - 0s 703us/step\n",
      "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.460 total time=  13.2s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 907us/step - loss: 1.0650\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 911us/step - loss: 0.9649\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8982\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8760\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8677\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8625\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8593\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8573\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8553\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8547\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 901us/step - loss: 0.8544\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 906us/step - loss: 0.8541\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 904us/step - loss: 0.8538\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 906us/step - loss: 0.8537\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 923us/step - loss: 0.8536\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 918us/step - loss: 0.8535\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 902us/step - loss: 0.8533\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 902us/step - loss: 0.8532\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8532\n",
      "149/149 [==============================] - 0s 858us/step\n",
      "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.300 total time=  12.9s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0572\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9576\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9017\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8803\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8712\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8664\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 955us/step - loss: 0.8635\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 912us/step - loss: 0.8615\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 904us/step - loss: 0.8602\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 892us/step - loss: 0.8595\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 896us/step - loss: 0.8589\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 894us/step - loss: 0.8582\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 896us/step - loss: 0.8578\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 886us/step - loss: 0.8575\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 911us/step - loss: 0.8571\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8568\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8564\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8564\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
      "149/149 [==============================] - 0s 845us/step\n",
      "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.420 total time=  13.3s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8700\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7682\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 958us/step - loss: 0.7198\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 894us/step - loss: 0.7014\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 897us/step - loss: 0.6943\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 887us/step - loss: 0.6906\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 891us/step - loss: 0.6885\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 897us/step - loss: 0.6871\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 901us/step - loss: 0.6862\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 889us/step - loss: 0.6856\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 901us/step - loss: 0.6851\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6847\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6843\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6840\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6837\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6835\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6832\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6832\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6830\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 985us/step - loss: 0.6828\n",
      "149/149 [==============================] - 0s 669us/step\n",
      "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.010 total time=  13.1s\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 1s 880us/step - loss: 0.9535\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 1s 880us/step - loss: 0.8679\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 1s 867us/step - loss: 0.8318\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 1s 867us/step - loss: 0.8144\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 1s 870us/step - loss: 0.8053\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 1s 877us/step - loss: 0.8004\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 1s 882us/step - loss: 0.7976\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 1s 885us/step - loss: 0.7960\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 1s 877us/step - loss: 0.7946\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7934\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7927\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7920\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7914\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7910\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7906\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7904\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 1s 968us/step - loss: 0.7902\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 1s 909us/step - loss: 0.7900\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 1s 877us/step - loss: 0.7899\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 1s 877us/step - loss: 0.7897\n",
      "149/149 [==============================] - 0s 676us/step\n",
      "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.090 total time=  12.4s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 911us/step - loss: 1.0081\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 882us/step - loss: 0.9151\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 909us/step - loss: 0.8560\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 914us/step - loss: 0.8297\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 899us/step - loss: 0.8176\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8101\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8062\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8044\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8031\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8023\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8018\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8013\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 995us/step - loss: 0.8008\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 948us/step - loss: 0.8004\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 902us/step - loss: 0.8000\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 886us/step - loss: 0.7996\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 899us/step - loss: 0.7994\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 896us/step - loss: 0.7992\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 886us/step - loss: 0.7990\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 928us/step - loss: 0.7988\n",
      "149/149 [==============================] - 0s 689us/step\n",
      "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.480 total time=  12.5s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 914us/step - loss: 1.0598\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9559\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8941\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8727\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8646\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8604\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8581\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8569\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 909us/step - loss: 0.8552\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 912us/step - loss: 0.8549\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 907us/step - loss: 0.8546\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 919us/step - loss: 0.8543\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 921us/step - loss: 0.8541\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 933us/step - loss: 0.8539\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 911us/step - loss: 0.8537\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 912us/step - loss: 0.8536\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 909us/step - loss: 0.8535\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8533\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8532\n",
      "149/149 [==============================] - 0s 953us/step\n",
      "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.300 total time=  13.0s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0594\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9591\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9003\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8791\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8701\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 968us/step - loss: 0.8656\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 912us/step - loss: 0.8628\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 923us/step - loss: 0.8610\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 902us/step - loss: 0.8597\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 929us/step - loss: 0.8588\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 907us/step - loss: 0.8581\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 912us/step - loss: 0.8575\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 921us/step - loss: 0.8571\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 948us/step - loss: 0.8568\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 961us/step - loss: 0.8565\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 963us/step - loss: 0.8563\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8559\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8559\n",
      "149/149 [==============================] - 0s 939us/step\n",
      "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.420 total time=  13.0s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8745\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7660\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7203\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7017\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 934us/step - loss: 0.6946\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 899us/step - loss: 0.6908\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 901us/step - loss: 0.6885\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 897us/step - loss: 0.6870\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 902us/step - loss: 0.6862\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 901us/step - loss: 0.6856\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 897us/step - loss: 0.6850\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 904us/step - loss: 0.6846\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 960us/step - loss: 0.6843\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6841\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6839\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6838\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6836\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6835\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6834\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6832\n",
      "149/149 [==============================] - 0s 878us/step\n",
      "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.010 total time=  13.3s\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 1s 887us/step - loss: 0.9510\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 1s 879us/step - loss: 0.8705\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 1s 880us/step - loss: 0.8314\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 1s 885us/step - loss: 0.8159\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 1s 887us/step - loss: 0.8082\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 1s 884us/step - loss: 0.8029\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 1s 884us/step - loss: 0.7986\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 1s 885us/step - loss: 0.7959\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 1s 892us/step - loss: 0.7944\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7933\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7927\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7920\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7916\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7912\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 1s 998us/step - loss: 0.7909\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7907\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7905\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 1s 1000us/step - loss: 0.7903\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 1s 884us/step - loss: 0.7901\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 1s 899us/step - loss: 0.7899\n",
      "149/149 [==============================] - 0s 669us/step\n",
      "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.080 total time=  12.6s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 916us/step - loss: 1.0093\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 911us/step - loss: 0.9186\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 923us/step - loss: 0.8583\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 921us/step - loss: 0.8272\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 912us/step - loss: 0.8143\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8090\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8062\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8044\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8032\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8024\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8017\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8012\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8007\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 953us/step - loss: 0.8003\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 916us/step - loss: 0.7997\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 919us/step - loss: 0.7993\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 911us/step - loss: 0.7991\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 924us/step - loss: 0.7988\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 914us/step - loss: 0.7987\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 926us/step - loss: 0.7985\n",
      "149/149 [==============================] - 0s 703us/step\n",
      "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.500 total time=  13.0s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 938us/step - loss: 1.0608\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9573\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8963\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8737\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8647\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8600\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8576\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 923us/step - loss: 0.8547\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 924us/step - loss: 0.8543\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 923us/step - loss: 0.8541\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 921us/step - loss: 0.8539\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 924us/step - loss: 0.8536\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 919us/step - loss: 0.8536\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 928us/step - loss: 0.8533\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 923us/step - loss: 0.8532\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8531\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
      "149/149 [==============================] - 0s 919us/step\n",
      "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.350 total time=  13.5s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0608\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9643\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9019\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8792\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 963us/step - loss: 0.8698\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 916us/step - loss: 0.8649\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 919us/step - loss: 0.8620\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 912us/step - loss: 0.8600\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 938us/step - loss: 0.8588\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 933us/step - loss: 0.8580\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 921us/step - loss: 0.8575\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 914us/step - loss: 0.8571\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 912us/step - loss: 0.8568\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8566\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8563\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8558\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
      "149/149 [==============================] - 0s 872us/step\n",
      "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.420 total time=  13.7s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 939us/step - loss: 0.8815\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 931us/step - loss: 0.7687\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 918us/step - loss: 0.7205\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 918us/step - loss: 0.7019\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 928us/step - loss: 0.6947\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 916us/step - loss: 0.6907\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 931us/step - loss: 0.6886\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 919us/step - loss: 0.6870\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6860\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6853\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6847\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6843\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6840\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6837\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6835\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6833\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6832\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 928us/step - loss: 0.6830\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 919us/step - loss: 0.6829\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 907us/step - loss: 0.6828\n",
      "149/149 [==============================] - 0s 689us/step\n",
      "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.010 total time=  13.1s\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 1s 874us/step - loss: 0.9541\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 1s 879us/step - loss: 0.8729\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 1s 880us/step - loss: 0.8341\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 1s 965us/step - loss: 0.8168\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8067\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8008\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7979\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7961\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7949\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7939\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7931\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7926\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 1s 885us/step - loss: 0.7919\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 1s 880us/step - loss: 0.7915\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 1s 882us/step - loss: 0.7911\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 1s 880us/step - loss: 0.7908\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 1s 877us/step - loss: 0.7905\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 1s 872us/step - loss: 0.7903\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 1s 884us/step - loss: 0.7901\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 1s 880us/step - loss: 0.7900\n",
      "149/149 [==============================] - 0s 669us/step\n",
      "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.080 total time=  12.9s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0084\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9195\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8595\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8309\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8154\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8080\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8049\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8033\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 929us/step - loss: 0.8024\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 931us/step - loss: 0.8016\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 911us/step - loss: 0.8012\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 926us/step - loss: 0.8008\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 923us/step - loss: 0.8005\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 929us/step - loss: 0.8003\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 924us/step - loss: 0.8000\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 923us/step - loss: 0.7998\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 981us/step - loss: 0.7994\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7991\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7988\n",
      "149/149 [==============================] - 0s 953us/step\n",
      "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.480 total time=  13.7s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0620\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9620\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8981\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8746\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 936us/step - loss: 0.8654\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 914us/step - loss: 0.8608\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 921us/step - loss: 0.8583\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 923us/step - loss: 0.8568\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 892us/step - loss: 0.8558\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 899us/step - loss: 0.8552\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 911us/step - loss: 0.8548\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 919us/step - loss: 0.8543\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 970us/step - loss: 0.8541\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8539\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8536\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8534\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8533\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8531\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8531\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8528\n",
      "149/149 [==============================] - 0s 824us/step\n",
      "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.350 total time=  13.5s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 896us/step - loss: 1.0580\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 902us/step - loss: 0.9592\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 894us/step - loss: 0.8993\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 902us/step - loss: 0.8767\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 909us/step - loss: 0.8678\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 902us/step - loss: 0.8635\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 921us/step - loss: 0.8611\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 892us/step - loss: 0.8597\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 978us/step - loss: 0.8588\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8581\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8577\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8573\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8570\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8568\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8566\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8564\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 911us/step - loss: 0.8563\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 906us/step - loss: 0.8560\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 891us/step - loss: 0.8560\n",
      "149/149 [==============================] - 0s 669us/step\n",
      "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.420 total time=  12.7s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 909us/step - loss: 0.8794\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 960us/step - loss: 0.7665\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 916us/step - loss: 0.7189\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 916us/step - loss: 0.7008\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 923us/step - loss: 0.6941\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6903\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6883\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6869\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6860\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6853\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6848\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6844\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6841\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 938us/step - loss: 0.6838\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 919us/step - loss: 0.6835\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 924us/step - loss: 0.6833\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 919us/step - loss: 0.6832\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 938us/step - loss: 0.6830\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 934us/step - loss: 0.6829\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 906us/step - loss: 0.6828\n",
      "149/149 [==============================] - 0s 689us/step\n",
      "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.010 total time=  12.9s\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 1s 882us/step - loss: 0.9513\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8717\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8350\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8177\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8086\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8029\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7980\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7950\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7935\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 1s 906us/step - loss: 0.7926\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 1s 892us/step - loss: 0.7919\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 1s 872us/step - loss: 0.7915\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 1s 895us/step - loss: 0.7912\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 1s 926us/step - loss: 0.7908\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 1s 902us/step - loss: 0.7906\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 1s 874us/step - loss: 0.7904\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 1s 874us/step - loss: 0.7902\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 1s 879us/step - loss: 0.7900\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7898\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7897\n",
      "149/149 [==============================] - 0s 986us/step\n",
      "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.080 total time=  13.0s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0099\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9182\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8586\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8313\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8155\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 912us/step - loss: 0.8085\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 892us/step - loss: 0.8054\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 923us/step - loss: 0.8039\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 916us/step - loss: 0.8029\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 899us/step - loss: 0.8023\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 899us/step - loss: 0.8018\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 896us/step - loss: 0.8013\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 896us/step - loss: 0.8009\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 896us/step - loss: 0.8005\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8002\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7998\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7995\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7993\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7990\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7988\n",
      "149/149 [==============================] - 0s 939us/step\n",
      "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.490 total time=  13.0s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0640\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 985us/step - loss: 0.9651\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 939us/step - loss: 0.8985\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 916us/step - loss: 0.8750\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 894us/step - loss: 0.8661\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 897us/step - loss: 0.8615\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 887us/step - loss: 0.8585\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 904us/step - loss: 0.8567\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 894us/step - loss: 0.8557\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 904us/step - loss: 0.8550\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8544\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8542\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8539\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8537\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8535\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8533\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8531\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 992us/step - loss: 0.8529\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 899us/step - loss: 0.8528\n",
      "149/149 [==============================] - 0s 716us/step\n",
      "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.350 total time=  13.1s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 923us/step - loss: 1.0615\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 899us/step - loss: 0.9664\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 897us/step - loss: 0.9040\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 907us/step - loss: 0.8796\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 897us/step - loss: 0.8699\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 901us/step - loss: 0.8650\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8622\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8604\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8593\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8583\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8576\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8571\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8568\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8565\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8564\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 892us/step - loss: 0.8562\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 896us/step - loss: 0.8561\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 896us/step - loss: 0.8560\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 901us/step - loss: 0.8558\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 904us/step - loss: 0.8558\n",
      "149/149 [==============================] - 0s 709us/step\n",
      "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.420 total time=  12.7s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 924us/step - loss: 0.8814\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 909us/step - loss: 0.7697\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 993us/step - loss: 0.7220\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7022\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6947\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6908\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6886\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6872\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6864\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6857\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6851\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 914us/step - loss: 0.6847\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 907us/step - loss: 0.6844\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 928us/step - loss: 0.6841\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 924us/step - loss: 0.6839\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 912us/step - loss: 0.6837\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 897us/step - loss: 0.6835\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 916us/step - loss: 0.6833\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 919us/step - loss: 0.6832\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6831\n",
      "149/149 [==============================] - 0s 892us/step\n",
      "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.010 total time=  13.0s\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9506\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8755\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8342\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8166\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8072\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8010\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 1s 954us/step - loss: 0.7977\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 1s 894us/step - loss: 0.7959\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 1s 949us/step - loss: 0.7948\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 1s 895us/step - loss: 0.7940\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 1s 914us/step - loss: 0.7932\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 1s 906us/step - loss: 0.7926\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 1s 901us/step - loss: 0.7921\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 1s 890us/step - loss: 0.7917\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 1s 895us/step - loss: 0.7913\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7910\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7908\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7904\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7904\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7902\n",
      "149/149 [==============================] - 0s 926us/step\n",
      "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.070 total time=  13.7s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0092\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9199\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 884us/step - loss: 0.8599\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 894us/step - loss: 0.8317\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 897us/step - loss: 0.8156\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 894us/step - loss: 0.8085\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 892us/step - loss: 0.8054\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8038\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 958us/step - loss: 0.8029\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 936us/step - loss: 0.8023\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8018\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8014\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8010\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8006\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8004\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7999\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7995\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7993\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7991\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 926us/step - loss: 0.7988\n",
      "149/149 [==============================] - 0s 709us/step\n",
      "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.490 total time=  13.5s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 921us/step - loss: 1.0607\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 939us/step - loss: 0.9606\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 934us/step - loss: 0.8973\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 923us/step - loss: 0.8749\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 918us/step - loss: 0.8662\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 891us/step - loss: 0.8612\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8582\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8566\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8550\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8545\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8543\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8540\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 998us/step - loss: 0.8537\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 929us/step - loss: 0.8536\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 901us/step - loss: 0.8535\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 897us/step - loss: 0.8533\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 899us/step - loss: 0.8532\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 896us/step - loss: 0.8531\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 886us/step - loss: 0.8530\n",
      "149/149 [==============================] - 0s 689us/step\n",
      "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.300 total time=  12.7s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 891us/step - loss: 1.0588\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 906us/step - loss: 0.9599\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9011\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8786\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8690\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8644\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8617\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8600\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8589\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8579\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 968us/step - loss: 0.8574\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 897us/step - loss: 0.8571\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 897us/step - loss: 0.8568\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 889us/step - loss: 0.8565\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 892us/step - loss: 0.8565\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 904us/step - loss: 0.8563\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 894us/step - loss: 0.8562\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 892us/step - loss: 0.8562\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 912us/step - loss: 0.8561\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
      "149/149 [==============================] - 0s 865us/step\n",
      "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.420 total time=  12.8s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8768\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7683\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7210\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7018\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6945\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6907\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 939us/step - loss: 0.6885\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 916us/step - loss: 0.6870\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 919us/step - loss: 0.6860\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 924us/step - loss: 0.6853\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 916us/step - loss: 0.6848\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 914us/step - loss: 0.6844\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 916us/step - loss: 0.6841\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 924us/step - loss: 0.6838\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 926us/step - loss: 0.6835\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6833\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6831\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6831\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6829\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6828\n",
      "149/149 [==============================] - 0s 1000us/step\n",
      "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.000 total time=  13.8s\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9510\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8737\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 1s 879us/step - loss: 0.8331\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 1s 862us/step - loss: 0.8152\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 1s 868us/step - loss: 0.8060\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 1s 868us/step - loss: 0.8011\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 1s 877us/step - loss: 0.7981\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 1s 885us/step - loss: 0.7960\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 1s 870us/step - loss: 0.7944\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 1s 862us/step - loss: 0.7932\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 1s 897us/step - loss: 0.7921\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7915\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7910\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7905\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7903\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7902\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7900\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7898\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 1s 992us/step - loss: 0.7897\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 1s 887us/step - loss: 0.7896\n",
      "149/149 [==============================] - 0s 682us/step\n",
      "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.080 total time=  12.6s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 909us/step - loss: 1.0105\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 894us/step - loss: 0.9240\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 894us/step - loss: 0.8615\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 907us/step - loss: 0.8320\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 896us/step - loss: 0.8195\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 897us/step - loss: 0.8111\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 936us/step - loss: 0.8063\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8041\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8029\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8022\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8016\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8011\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8007\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8004\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7999\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 971us/step - loss: 0.7996\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 943us/step - loss: 0.7993\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 891us/step - loss: 0.7990\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 918us/step - loss: 0.7988\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 904us/step - loss: 0.7986\n",
      "149/149 [==============================] - 0s 655us/step\n",
      "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.480 total time=  12.7s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 909us/step - loss: 1.0627\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 924us/step - loss: 0.9614\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 923us/step - loss: 0.8982\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8747\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8658\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8613\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8587\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8572\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8548\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 912us/step - loss: 0.8544\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 904us/step - loss: 0.8540\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 916us/step - loss: 0.8537\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 904us/step - loss: 0.8535\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 923us/step - loss: 0.8534\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 929us/step - loss: 0.8532\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 918us/step - loss: 0.8531\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 911us/step - loss: 0.8531\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 918us/step - loss: 0.8530\n",
      "149/149 [==============================] - 0s 669us/step\n",
      "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.300 total time=  12.9s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0575\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9588\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9005\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8786\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8697\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8651\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8622\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8604\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 896us/step - loss: 0.8593\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 904us/step - loss: 0.8585\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 896us/step - loss: 0.8580\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 923us/step - loss: 0.8575\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 911us/step - loss: 0.8572\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 901us/step - loss: 0.8570\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 904us/step - loss: 0.8567\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 894us/step - loss: 0.8565\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 896us/step - loss: 0.8564\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
      "149/149 [==============================] - 0s 872us/step\n",
      "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.420 total time=  13.2s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8826\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7745\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7231\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7025\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 921us/step - loss: 0.6950\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 929us/step - loss: 0.6909\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 933us/step - loss: 0.6886\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 911us/step - loss: 0.6871\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 906us/step - loss: 0.6860\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 906us/step - loss: 0.6854\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 914us/step - loss: 0.6848\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 914us/step - loss: 0.6843\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 904us/step - loss: 0.6840\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6837\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6835\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6833\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6831\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6830\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6829\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6828\n",
      "149/149 [==============================] - 0s 824us/step\n",
      "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.010 total time=  13.6s\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9721\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9173\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8588\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8292\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8181\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8116\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8072\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8043\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8022\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8005\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 1s 2ms/step - loss: 0.7990\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7977\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7964\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7954\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7946\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7942\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7938\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7935\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7931\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7928\n",
      "149/149 [==============================] - 0s 770us/step\n",
      "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.050 total time=  15.0s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0300\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9834\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8947\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8497\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8362\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8313\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8290\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8274\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8258\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8234\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8196\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8155\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8120\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8094\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8073\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8061\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8052\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8045\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8038\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8033\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.480 total time=  15.6s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 1.0886\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0377\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9361\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8960\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8861\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8795\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8744\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8706\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8670\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8634\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8605\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8584\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8572\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8563\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8558\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8552\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8549\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8547\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8544\n",
      "149/149 [==============================] - 0s 804us/step\n",
      "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.300 total time=  15.6s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0843\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0358\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9373\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8973\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8873\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8822\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8781\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8749\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8722\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8695\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8667\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8644\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8625\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8612\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8603\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8594\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8588\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8583\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8580\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8578\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.420 total time=  15.8s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9006\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8159\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7649\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7353\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7277\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7231\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7180\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7091\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6983\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6926\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6902\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.6890\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6880\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6872\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6867\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.6862\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6858\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6854\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6852\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6850\n",
      "149/149 [==============================] - 0s 811us/step\n",
      "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.000 total time=  15.8s\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9707\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9152\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8576\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8292\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 1s 2ms/step - loss: 0.8177\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8113\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8072\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8043\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8023\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8008\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7995\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7981\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7969\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7959\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7949\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7942\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7936\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7931\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7929\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7928\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.050 total time=  15.7s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0296\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9850\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8964\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8495\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8355\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8306\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8280\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8258\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8233\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8200\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8165\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8131\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8107\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8087\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8074\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8063\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8053\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8048\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8041\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8037\n",
      "149/149 [==============================] - 0s 797us/step\n",
      "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.480 total time=  15.9s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0882\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0382\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9403\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8994\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8879\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8818\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8760\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8714\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8671\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8634\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8604\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8583\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8572\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8563\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8555\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8552\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8550\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8547\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8545\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.340 total time=  16.0s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 2s 1ms/step - loss: 1.0830\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0275\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9326\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8981\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8875\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8828\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8789\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8751\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8722\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8693\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8669\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8647\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8631\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8618\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8608\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8599\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8592\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8588\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8584\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8580\n",
      "149/149 [==============================] - 0s 757us/step\n",
      "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.420 total time=  15.9s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9025\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8136\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7618\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7349\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7276\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7238\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7215\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7195\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7167\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7101\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6987\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6925\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6906\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6892\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6884\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6876\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6871\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6866\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6863\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6860\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.000 total time=  15.6s\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9714\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9221\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8644\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8316\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8194\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8128\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8082\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8052\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8030\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8013\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7998\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7985\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7973\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7960\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7950\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7942\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7938\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7934\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7932\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7928\n",
      "149/149 [==============================] - 0s 764us/step\n",
      "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.050 total time=  15.3s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0332\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9891\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8998\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8504\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8365\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8313\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8286\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8265\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8243\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8214\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8176\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8134\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8102\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8082\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8069\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8060\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8052\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8046\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8042\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8037\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.460 total time=  15.6s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0878\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0314\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9321\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8955\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8864\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8808\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8757\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8713\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8683\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8653\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8626\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8603\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8587\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8575\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8567\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8561\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8551\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8550\n",
      "149/149 [==============================] - 0s 777us/step\n",
      "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.350 total time=  15.7s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0835\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0317\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9374\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9000\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8887\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8832\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8786\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8742\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8702\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8672\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8649\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8633\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8620\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8612\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8606\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8601\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8595\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8592\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8588\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8584\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.420 total time=  15.6s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8995\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8185\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7716\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7403\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7305\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7230\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7106\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6989\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6934\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6907\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6894\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6882\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6875\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6869\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6863\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.6860\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6856\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6852\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6851\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6849\n",
      "149/149 [==============================] - 0s 750us/step\n",
      "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.000 total time=  15.8s\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9693\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9199\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8634\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8308\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8182\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8112\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8067\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8041\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8022\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8009\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7996\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7984\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7968\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7957\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7947\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7942\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7938\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7936\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7932\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7929\n",
      "149/149 [==============================] - 0s 797us/step\n",
      "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.040 total time=  14.6s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 1.0301\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9857\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9002\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8525\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8369\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8314\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8287\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8265\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8242\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8209\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8167\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8132\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8110\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8095\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8083\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8073\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8063\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8054\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8047\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8040\n",
      "149/149 [==============================] - 0s 791us/step\n",
      "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.490 total time=  16.1s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0882\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0340\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9347\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8972\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8855\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8785\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8740\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8706\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8679\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8647\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8618\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8595\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8578\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8569\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8563\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8552\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8549\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8547\n",
      "149/149 [==============================] - 0s 919us/step\n",
      "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.300 total time=  15.0s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0834\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0285\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9352\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8984\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8878\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8826\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8783\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8741\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8706\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8674\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8650\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8630\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8615\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8607\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8599\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8593\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8589\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8586\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8583\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8581\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.420 total time=  16.1s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9016\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8158\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7646\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7358\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7284\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7248\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7224\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7205\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7186\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7155\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7090\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6983\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6924\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6903\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6891\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6883\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6877\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6871\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6865\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6862\n",
      "149/149 [==============================] - 0s 770us/step\n",
      "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.000 total time=  14.9s\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9713\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9177\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8605\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8302\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8181\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8115\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8071\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8044\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8025\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8011\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7997\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7985\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7972\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7960\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7950\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7943\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7936\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7933\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7931\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7927\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.050 total time=  15.9s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0305\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9896\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9028\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8533\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8371\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8310\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8279\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8249\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8210\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8165\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8128\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8108\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8094\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8080\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8069\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8061\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8053\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8047\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8041\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8034\n",
      "149/149 [==============================] - 0s 764us/step\n",
      "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.510 total time=  15.1s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0875\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0251\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9274\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8946\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8861\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8814\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8771\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8735\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8703\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8675\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8646\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8619\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8597\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8581\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8571\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8564\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8559\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8555\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8553\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8550\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.340 total time=  16.0s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0835\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0313\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9366\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8992\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8877\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8820\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8776\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8737\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8699\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8667\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8641\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8621\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8610\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8600\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8593\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8589\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8585\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8583\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8580\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8578\n",
      "149/149 [==============================] - 0s 757us/step\n",
      "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.420 total time=  15.1s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8995\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8130\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7611\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7364\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7282\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7210\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7100\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6976\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6924\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6905\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6893\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6884\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6876\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6872\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6867\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6863\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6859\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6857\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6855\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6853\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.000 total time=  16.1s\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9678\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9190\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8611\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8309\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8197\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8133\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8090\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8060\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8039\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8022\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8009\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7994\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7978\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 1s 2ms/step - loss: 0.7965\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7953\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7946\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7942\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7938\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7936\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7934\n",
      "149/149 [==============================] - 0s 743us/step\n",
      "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.050 total time=  15.0s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0323\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9889\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9024\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8522\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8365\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8309\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8277\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8247\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8212\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8170\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8137\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8115\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8099\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8086\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8074\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8063\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8054\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8047\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8042\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8037\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.480 total time=  15.9s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0877\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0318\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9320\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8955\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8856\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8791\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8746\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8714\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8684\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8650\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8612\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8585\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8570\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8552\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8550\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8548\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8546\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8544\n",
      "149/149 [==============================] - 0s 770us/step\n",
      "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.300 total time=  15.2s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0832\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0275\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9327\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8983\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8882\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8833\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8799\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8763\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8725\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8689\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8658\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8634\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8620\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8611\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8604\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8599\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8594\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8590\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8586\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8584\n",
      "149/149 [==============================] - 0s 973us/step\n",
      "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.420 total time=  16.1s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.9006\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8155\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7647\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7370\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7293\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7250\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7215\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7171\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7080\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6973\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.6924\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6905\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6892\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6883\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6876\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6871\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6866\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6862\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6859\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6857\n",
      "149/149 [==============================] - 0s 797us/step\n",
      "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.000 total time=  15.7s\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9718\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9197\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 1s 2ms/step - loss: 0.8628\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 1s 2ms/step - loss: 0.8310\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8186\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8115\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8069\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8037\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8015\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7996\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7979\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7964\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7955\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7949\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7943\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7941\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7937\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7934\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7932\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7929\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.050 total time=  16.2s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0316\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9837\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8930\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8491\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8360\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8311\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8287\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8266\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8242\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8202\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8156\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8117\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8091\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8073\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8062\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8054\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8043\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8036\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8028\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8021\n",
      "149/149 [==============================] - 0s 791us/step\n",
      "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.500 total time=  15.4s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0881\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0335\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9322\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8953\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8858\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8806\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8760\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8715\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8676\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8644\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8617\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8594\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8577\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8566\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8551\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8548\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8546\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8545\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.350 total time=  16.1s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 2s 1ms/step - loss: 1.0833\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0272\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9313\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8967\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8866\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8812\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8767\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8733\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8700\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8672\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8649\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8631\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8621\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8610\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8604\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8598\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8591\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8588\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8585\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8583\n",
      "149/149 [==============================] - 0s 791us/step\n",
      "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.420 total time=  15.5s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9010\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8152\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7634\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7355\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7252\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7127\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6993\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6930\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6904\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6892\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6882\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6875\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6870\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6865\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6862\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6860\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6856\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6854\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6853\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6851\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.000 total time=  15.5s\n",
      "Epoch 1/20\n",
      "594/594 [==============================] - 1s 2ms/step - loss: 0.9709\n",
      "Epoch 2/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.9193\n",
      "Epoch 3/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8624\n",
      "Epoch 4/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8310\n",
      "Epoch 5/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8181\n",
      "Epoch 6/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8111\n",
      "Epoch 7/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8066\n",
      "Epoch 8/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8037\n",
      "Epoch 9/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8017\n",
      "Epoch 10/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.8004\n",
      "Epoch 11/20\n",
      "594/594 [==============================] - 1s 2ms/step - loss: 0.7993\n",
      "Epoch 12/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7980\n",
      "Epoch 13/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7970\n",
      "Epoch 14/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7958\n",
      "Epoch 15/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7950\n",
      "Epoch 16/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7941\n",
      "Epoch 17/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7938\n",
      "Epoch 18/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7933\n",
      "Epoch 19/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7931\n",
      "Epoch 20/20\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.7929\n",
      "149/149 [==============================] - 0s 804us/step\n",
      "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.050 total time=  15.4s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0303\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9876\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8978\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8507\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8366\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8314\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8289\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8268\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8242\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8208\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8168\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8134\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8108\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8090\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8075\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8064\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8056\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8049\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8046\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8041\n",
      "149/149 [==============================] - 0s 1ms/step\n",
      "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.520 total time=  15.9s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 1.0881\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0324\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9324\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8954\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8854\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8797\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8747\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8710\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8677\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8643\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8609\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8587\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8574\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8565\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8560\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8555\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8552\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8550\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8548\n",
      "149/149 [==============================] - 0s 777us/step\n",
      "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.310 total time=  15.5s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0839\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 1.0337\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9369\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8991\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8882\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8828\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8784\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8741\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8701\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8669\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8644\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8626\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8614\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8606\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8599\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8594\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8590\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8588\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8585\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.8583\n",
      "149/149 [==============================] - 0s 784us/step\n",
      "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.420 total time=  15.8s\n",
      "Epoch 1/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.9036\n",
      "Epoch 2/20\n",
      "595/595 [==============================] - 1s 2ms/step - loss: 0.8167\n",
      "Epoch 3/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7656\n",
      "Epoch 4/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7374\n",
      "Epoch 5/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7296\n",
      "Epoch 6/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7255\n",
      "Epoch 7/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7228\n",
      "Epoch 8/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7208\n",
      "Epoch 9/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7186\n",
      "Epoch 10/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7150\n",
      "Epoch 11/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.7074\n",
      "Epoch 12/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6970\n",
      "Epoch 13/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6913\n",
      "Epoch 14/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6892\n",
      "Epoch 15/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6880\n",
      "Epoch 16/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6873\n",
      "Epoch 17/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6866\n",
      "Epoch 18/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6863\n",
      "Epoch 19/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6859\n",
      "Epoch 20/20\n",
      "595/595 [==============================] - 1s 1ms/step - loss: 0.6857\n",
      "149/149 [==============================] - 0s 770us/step\n",
      "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.000 total time=  15.5s\n",
      "Epoch 1/5\n",
      "743/743 [==============================] - 1s 850us/step - loss: 0.8958\n",
      "Epoch 2/5\n",
      "743/743 [==============================] - 1s 863us/step - loss: 0.8505\n",
      "Epoch 3/5\n",
      "743/743 [==============================] - 1s 861us/step - loss: 0.8490\n",
      "Epoch 4/5\n",
      "743/743 [==============================] - 1s 856us/step - loss: 0.8486\n",
      "Epoch 5/5\n",
      "743/743 [==============================] - 1s 1ms/step - loss: 0.8483\n",
      "Los parámetros óptimizados fueron:  {'activation_func': 'relu', 'batch_size': 100, 'epochs': 5, 'extra_hidden_layers': 0, 'last_layer_nodes': 20, 'loss_func': 'categorical_crossentropy', 'optimizer': 'adam', 'optimizer__learning_rate': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "gs.fit(x_train_clasificacion, y_train_clasificacion)\n",
    "print(\"Los parámetros óptimizados fueron: \", gs.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Predecimos con el dataset de test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - 0s 978us/step\n"
     ]
    }
   ],
   "source": [
    "y_pr = gs.predict(x_test_clasificacion)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.b.4 Métricas\n",
    "Transformamos el array devuelto por el modelo a un dataframe de iguales columnas que y_test_clasificacion"
   ],
   "metadata": {
    "id": "W-KMjjHwaFjg"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "y_pr_df = pd.DataFrame(data=y_pr, columns=['alto', 'bajo', 'medio'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calculamos las métricas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.57\n",
      "Precision: 0.58\n",
      "Recall: 0.5\n",
      "F1 Score: 0.51\n"
     ]
    }
   ],
   "source": [
    "metricas_clasificacion(y_test_clasificacion, y_pr_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.b.5 Exportación de Datos"
   ],
   "metadata": {
    "id": "5SsWSPw1fJYm"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finalmente, exportamos el modelo utilizado:"
   ],
   "metadata": {
    "id": "IlgF2MmmfJYn"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "\n",
    "if IN_COLAB:\n",
    "  path = '/content/drive/MyDrive/📔 Organización de Datos (75.06)/TPS/TP2/MODELOS/Redes_Classifier.json'\n",
    "else:\n",
    "  path = './MODELOS/Redes_Classifier.json'\n",
    "\n",
    "joblib.dump(gs.best_estimator_, path)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "48479ec0-085c-4964-aa1d-b771dc5643e4",
    "id": "yjKFj8TjfJYn"
   },
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Salvador\\AppData\\Local\\Temp\\tmpsufktigt\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": "['./MODELOS/Redes_Classifier.json']"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JDpREdwKxB6m"
   },
   "source": [
    "## 3. Ensamble de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KvLq10beDadg"
   },
   "source": [
    "### 3.1 Ensamble Híbrido: Voting - Clasificación\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EAT6HU3buhLU"
   },
   "source": [
    "#### 3.1.1 Preparación del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZNjL2W-vZvC"
   },
   "source": [
    "Para la parte de ensambles, lo que haremos será utilizar nuevamente el dataset al cual se le aplicó una reducción de su dimensionalidad en el trabajo práctico n°1. \n",
    "\n",
    "Para esto lo que haremos será trabajar con una copia del dataset modificado al inicio del trabajo, el cual usa como base el reducido mencionado anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fDp1eW_cHfxt"
   },
   "source": [
    "Para nuestra variable `target`, utilizaremos como convención la misma que fue planteada para el tp1. Ésta consiste en subdividir a la variable pxm2 (precio por metro cuadrado) en 3 intervalos, 25% a bajo, 50% a medio y el otro 25% restante a alto. A su vez, se hará la separación tambien por tipo de propiedad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7T0ZW9l-dcqI"
   },
   "outputs": [],
   "source": [
    "x_train_voting = x_train_clasificacion\n",
    "y_train_voting = y_train_clasificacion\n",
    "\n",
    "x_test_voting = x_test_clasificacion\n",
    "y_test_voting = y_test_clasificacion"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "A modo de finalización de este trabajo, haremos un pequeño repaso sobre todos los puntos que analizamos y sus respectivos resultados y/o observaciones hechos por nosotros:\n",
    "\n",
    "Sobre el análisis realizado en el apartado de **procesamiento del lenguaje natural**, y en particular haciendo referencia a las métricas que obtuvimos luego del entrenamiento y predicción con el dataset producto de la ampliación, utilizando el modelo XGBoost, pudimos observar que si bien aún las métricas no nos resultan del todo satisfactorias cumplen con el objetivo de mejorar las resultantes del trabajo anterior. Más allá de que la cantidad de aciertos continúa sin incrementar, tanto el error MSE como el RMSE decrecieron ofreciendo mejores resultados. Por otro lado, el coeficiente de determinación se incrementó notoriamente llegando casi a un 0.9%. \n",
    "\n",
    "En cuanto a lo referido sobre **redes neuronales**, la comparación será directamente en base a los nuevos modelos ya que el dataset utilizado es compartido en ambos trabajos. Dicho esto, el error cometido en el modelo de regresión es significativamente pequeño. Teniendo en cuenta los resultantes del TP1, si utilizamos el menor luego de que éstos tuvieron su optimización de parámetros correspondiente, notamos que el que mejor performa es XGBoost con un MSE de 51650994876 (al cual de todas formas le atribuímos arrastre de error en nuestro planteo). Utilizando redes neuronales cometemos tan solo un error cuadrático medio equivalente a 1.36. Por otro lado, en lo que respecta al modelo de clasificación, obtuvimos resultados bastante similares. Si bien tanto el accuracy, precisión y F1-Score dieron distintos, la diferencia es de tan solo uno/dos puntos. Con esto concluimos que para clasificación no se notan mejoras por sobre los modelos utilizados en el trabajo anterior.\n",
    "\n",
    "Como último requerimiento se pidió estudiar las métricas tanto para regresión como clasificación pero haciendo uso de **ensambles**, en particular de tipo híbridos. En lo que respecta al utilizado para clasificación (Voting) obtuvimos mejores resultados para las métricas de Accuracy, Recall y F1-Score. Sin embargo, aunque en Precisión disminuyó un poco, esta diferencia continúa siendo no significativa. Pasando al ensamble de regresión (Stacking) el MSE resultante que obtuvimos fue 238481755830. Creemos que nuevamente estamos cometiendo involuntariamente algún arrastre de error en alguno de los incisos desarrollados, ya que este error es incluso mayor a los cometidos en los modelos individuales desarrollados en el TP1, y no estaría respetando la regla principal de ‘*La sabiduría de las multitudes*’."
   ],
   "metadata": {
    "id": "CE40zH4PI4xY"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bajo = y_train_voting['bajo'].sum() + y_test_voting[y_test_voting == 'bajo'].count()\n",
    "medio = y_train_voting['medio'].sum() + y_test_voting[y_test_voting == 'medio'].count()\n",
    "alto = y_train_voting['alto'].sum() + y_test_voting[y_test_voting == 'alto'].count()\n",
    "\n",
    "print(f\"Se observaron: \\n - {round(bajo,3)} registros de tipo 'bajo'. \\n - {round(medio,3)} registros de tipo 'medio'. \\n - {round(alto,3)} registros de tipo 'alto'.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.1.2 Definición del Ensamble"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para el tipo de ensamble **voting**, lo que necesitaremos será contar con `n` cantidad de modelos previamente entrenados para luego someterlos a una votación. De la misma, saldrá la clasificación para la nueva instancia en base a lo que indique la mayoría de ellos."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Elegimos tomar como modelos los mismos empleados en el TP1:\n",
    "\n",
    "\n",
    "*   Árbol de Decisión\n",
    "*   Random Forest\n",
    "*   KNN\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dcs_clf = DecisionTreeClassifier()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "knn_clf = KNeighborsClassifier()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Una vez que contamos con los modelos que vamos a utilizar en el ensamble, procedemos a su creación. En este caso particular decidimos utilizar el tipo de votación hard el cual utilizará la regla de la mayoría. Por otro lado, utilizamos el hiperparámetro `estimators` para definir como nos vamos a referir a dichos modelos."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vot_clf = VotingClassifier(estimators = [('dcs', dcs_clf), ('rnd', rnd_clf), ('knn', knn_clf)], voting = 'hard')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.1.3 Entrenamiento y Predicción"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Reorganizamos los valores predichos para que queden en una sola columna, y comparamos con el conjunto de prueba:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_train_voting_arr = np.apply_along_axis(convert_b_m_a, axis=1, arr=y_train_voting)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Seguimos reacomodando los valores para poder calcular las métricas correspondientes, notemos que no pueden guardarse valores equivalentes al string 'medio' en el array:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.unique(y_train_voting_arr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aplicamos estrategias de transformación de datos:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_train_voting_arr = np.where(y_train_voting_arr == 'medi', 'medio', y_train_voting_arr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.unique(y_train_voting_arr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finalmente, entrenamos el ensamle:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vot_clf.fit(x_train_voting, y_train_voting_arr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred_voting = vot_clf.predict(x_test_voting)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.1.4 Métricas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para poder determinar que tan bueno resulto el modelo, lo que haremos será observar las `métricas` resultantes de una predicción con los datos de test. Recordemos que nuestras funcinoes de metricas fueron definidas al inicio de este trabajo."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metricas_clasificacion(y_test_voting, y_pred_voting)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A su vez, también podemos visualizar los mismos a través de la siguiente matriz de confusión."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(y_test_voting, y_pred_voting)\n",
    "sns.heatmap(matrix,cmap='GnBu',annot=True,fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.1.4 Exportación de Datos"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finalmente, exportamos el modelo utilizado:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "  path = '/content/drive/MyDrive/📔 Organización de Datos (75.06)/TPS/TP2/MODELOS/Voting_Classifier.joblib'\n",
    "else:\n",
    "  path = './MODELOS/Voting_Classifier.joblib'\n",
    "\n",
    "dump(vot_clf, path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2 Ensamble Híbrido: Stacking - Regresión\n",
    "___"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.1.1 Preparación del dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nuevamente, utilizamos los datasets de train y test previamente separados:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train_stacking = x_train_regresion\n",
    "y_train_stacking = y_train_regresion\n",
    "\n",
    "x_test_stacking = x_test_regresion\n",
    "y_test_stacking = y_test_regresion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2.2 Definición del Ensamble\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lo que haremos en esta nueva sección, será implementar un nuevo tipo de ensable híbrido con la salvedad de que esta vez utilizaremos el tipo `cascading`.\n",
    "El mismo se basa en el entrenamiento de distintos `modelos base`, y a su vez utilizará un `meta-modelo` el cual realizará su predicción en base a las predicciones de los diferentes modelos comentados anteriormente.\n",
    "\n",
    "Como es indicado por el enunciado del trabajo se utilizarán modelos de regresión. En particular, decidimos trabajar con:\n",
    "\n",
    "\n",
    "*   KNN\n",
    "*   XGBoost\n",
    "*   AdaBoost\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "knn_rgs = KNeighborsRegressor()\n",
    "xgb_rgs = XGBRegressor()\n",
    "adb_rgs = AdaBoostRegressor()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Luego utilizamos los mismos para definir nuestro modelo base, en el cual luego se basará el meta-modelo."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "base_models = [('KNN', knn_rgs),\n",
    "               ('XGBoost', xgb_rgs),\n",
    "               ('AdaBoost', adb_rgs)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Como mencionamos, a continuación los utilizaremos para definir nuestro meta-modelo. Para este último, decidimos emplear el modelo de regresión logistica."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "meta_model = GradientBoostingRegressor()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creamos nuestro ensamble indicando como modelos estimadores Knn, XGBoost y AdaBoost, y como estimador final el modelo de Regresión Lineal."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "s = 5\n",
    "n = 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stacking_model = StackingRegressor(estimators=base_models,\n",
    "                                    final_estimator=meta_model,\n",
    "                                    passthrough=True,\n",
    "                                    cv=s,\n",
    "                                    verbose=n)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2.3 Entrenamiento y Predicción"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_scores = defaultdict()\n",
    "\n",
    "for name, model in base_models:\n",
    "    print('Evaluating {}'.format(name))\n",
    "    scores = evaluate_model(model, x_train_stacking, y_train_stacking, s, n)\n",
    "    model_scores[name] = scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Veamos cómo resultaron los scores de los modelos:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_results(model_scores, name='stacking_model_cv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Entrenamos el modelo:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stacking_model.fit(x_train_stacking, y_train_stacking)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finalmente haremos la predicción:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred_stacking = stacking_model.predict(x_test_stacking)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2.4 Métricas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para poder evaluar la performance que obtuvo nuestro modelo utilizaremos la métrica de evaluación del error cuadrático medio (MSE) como se pide por enunciado."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mse = metrics.mean_squared_error(\n",
    "        y_true  = y_test_stacking,\n",
    "        y_pred  = y_pred_stacking,\n",
    "        squared = True\n",
    "       )\n",
    "\n",
    "print(f\"El error según la métrica 'Mean Square Error' de test es: {mse}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2.4 Exportación de Datos"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finalmente, exportamos el modelo utilizado:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "  path = '/content/drive/MyDrive/📔 Organización de Datos (75.06)/TPS/TP2/MODELOS/Stacking_Regressor.joblib'\n",
    "else:\n",
    "  path = './MODELOS/Stacking_Regressor.joblib'\n",
    "\n",
    "dump(stacking_model, path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusiones"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "EAT6HU3buhLU",
    "_kG7ZRlKuaxT",
    "D8sgMCouvLx-"
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

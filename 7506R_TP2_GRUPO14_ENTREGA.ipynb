{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "______________________________________\n",
        "# <center>**Trabajo Practico Nº2 para la Materia *Organización de Datos***</center>\n",
        "\n",
        "*Integrantes*:\n",
        "- 103963\tCarolina Di Matteo\tcdimatteo@fi.uba.ar\n",
        "- 101231\tPablo Salvador Dimartino\tpdimartino@fi.uba.ar\n",
        "- 100113\tJuan Sebastian Burgos\tjsburgos@fi.uba.ar\n",
        "- 104415\tValentina Laura Correa\tvcorrea@fi.uba.ar\n",
        "\n",
        "*Grupo*: 14\n",
        "\n",
        "*Repositorio*: [github](https://github.com/valencorrea/7506R-2C2022-GRUPO14)\n",
        "\n",
        "*Curso*: Rodriguez\n",
        "\n",
        "*Cuatrimestre*: 2c2022\n",
        "\n",
        "Datos provistos por [properati](https://www.properati.com.ar).\n",
        "______________________________________\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "ALhQpMoS2Do2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introducción"
      ],
      "metadata": {
        "id": "jrObdaVTw13E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El presente trabajo práctico es una continuación del ‘TP1: Propiedades en Venta’. \n",
        "\n",
        "En la entrega anterior se propuso aplicar técnicas de análisis exploratorio, preprocesamiento de datos, agrupamiento, clasificación y regresión. Siguiendo esta línea, y con el objetivo de continuar resolviendo problemas reales de ciencia de datos, en esta segunda parte se implementarán nuevos modelos predictivos a partir de los anteriormente mencionados. \n",
        "\n",
        "En esta oportunidad se buscará demostrar los conocimientos adquiridos sobre procesamiento del lenguaje natural, redes neuronales y ensamble de modelos. Para esto se utilizarán tanto datasets provistos por la materia, tomados de la página de la empresa Properati, como los generados por el grupo en el trabajo anterior."
      ],
      "metadata": {
        "id": "8Tot765gvLP2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Setup"
      ],
      "metadata": {
        "id": "civIgEQKvQ6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importación de bibliotecas"
      ],
      "metadata": {
        "id": "vrqonJJjvVay"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: visualkeras in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (0.0.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from visualkeras) (9.2.0)\n",
            "Requirement already satisfied: numpy>=1.18.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from visualkeras) (1.21.5)\n",
            "Requirement already satisfied: aggdraw>=1.3.11 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from visualkeras) (1.3.15)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "import joblib as joblib\n",
        "\n",
        "pip install visualkeras"
      ],
      "metadata": {
        "id": "h6RrCiyq2Do7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e7b3e93-b112-4351-a933-5d45f291d371"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikeras[tensorflow] in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (0.10.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from scikeras[tensorflow]) (1.1.3)\n",
            "Requirement already satisfied: packaging>=0.21 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from scikeras[tensorflow]) (21.3)\n",
            "Requirement already satisfied: tensorflow>=2.11.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from scikeras[tensorflow]) (2.11.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from packaging>=0.21->scikeras[tensorflow]) (3.0.9)\n",
            "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (2.2.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (1.21.5)\n",
            "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow>=2.11.0->scikeras[tensorflow]) (2.11.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (2.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (0.29.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (2.11.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (4.3.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (0.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (3.7.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (1.16.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (65.5.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (14.0.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (1.14.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (2.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (3.19.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (1.42.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (2.11.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (2.11.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (3.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (0.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (2.28.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (2.0.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (2.6.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (0.6.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (1.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (1.26.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (2.0.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow>=2.11.0->scikeras[tensorflow]) (3.2.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install scikeras[tensorflow]"
      ],
      "metadata": {
        "id": "QIKWBNdoNtwF",
        "outputId": "9ff64a3e-596b-48c8-e9bd-f346f7e29079"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikeras[tensorflow-cpu] in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (0.10.0)\n",
            "Requirement already satisfied: packaging>=0.21 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from scikeras[tensorflow-cpu]) (21.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from scikeras[tensorflow-cpu]) (1.1.3)\n",
            "Requirement already satisfied: tensorflow-cpu>=2.11.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from scikeras[tensorflow-cpu]) (2.11.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from packaging>=0.21->scikeras[tensorflow-cpu]) (3.0.9)\n",
            "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras[tensorflow-cpu]) (1.21.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras[tensorflow-cpu]) (2.2.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras[tensorflow-cpu]) (1.7.3)\n",
            "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras[tensorflow-cpu]) (1.1.1)\n",
            "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (2.11.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (0.29.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (2.1.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (1.3.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (65.5.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (2.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (1.14.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (0.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (1.6.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (4.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (2.11.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (1.42.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (3.19.6)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (2.11.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (14.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (3.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (0.37.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (0.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (2.28.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (0.6.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (2.6.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (2.0.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (4.7.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (1.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (1.26.12)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (2022.12.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow-cpu>=2.11.0->scikeras[tensorflow-cpu]) (3.2.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install scikeras[tensorflow-cpu]"
      ],
      "metadata": {
        "id": "pcSe1TB8NtwH",
        "outputId": "2458284f-b1e7-4388-bdaa-db176e94189a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install unidecode"
      ],
      "metadata": {
        "id": "vdZzPMc93I-C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "045bdfc2-9805-43c2-c41d-1cd20aa7efce"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unidecode in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (1.2.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install types-all"
      ],
      "metadata": {
        "id": "7SrZ6Pvh8b_K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aff2586-af7e-4665-9009-c3ba548ce286"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: types-all in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (1.0.0)\n",
            "Requirement already satisfied: types-contextvars in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (2.4.7)\n",
            "Requirement already satisfied: types-Deprecated in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.2.9)\n",
            "Requirement already satisfied: types-backports in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.1.3)\n",
            "Requirement already satisfied: types-tabulate in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.9.0.0)\n",
            "Requirement already satisfied: types-chardet in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (5.0.4.1)\n",
            "Requirement already satisfied: types-PyJWT in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.7.1)\n",
            "Requirement already satisfied: types-colorama in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.4.15.4)\n",
            "Requirement already satisfied: types-backports-abc in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.5.2)\n",
            "Requirement already satisfied: types-pycurl in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (7.45.2.0)\n",
            "Requirement already satisfied: types-kazoo in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.1.3)\n",
            "Requirement already satisfied: types-pysftp in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.2.17)\n",
            "Requirement already satisfied: types-ujson in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (5.6.0.0)\n",
            "Requirement already satisfied: types-polib in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.1.12.1)\n",
            "Requirement already satisfied: types-DateTimeRange in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.2.8)\n",
            "Requirement already satisfied: types-paramiko in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (2.12.0.1)\n",
            "Requirement already satisfied: types-itsdangerous in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.1.6)\n",
            "Requirement already satisfied: types-Werkzeug in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.0.9)\n",
            "Requirement already satisfied: types-dateparser in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.1.4.4)\n",
            "Requirement already satisfied: types-aiofiles in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (22.1.0.4)\n",
            "Requirement already satisfied: types-python-dateutil in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (2.8.19.5)\n",
            "Requirement already satisfied: types-redis in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (4.3.21.6)\n",
            "Requirement already satisfied: types-pathlib2 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (2.3.0)\n",
            "Requirement already satisfied: types-simplejson in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (3.18.0.0)\n",
            "Requirement already satisfied: types-dataclasses in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.6.6)\n",
            "Requirement already satisfied: types-pyaudio in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.2.16.4)\n",
            "Requirement already satisfied: types-requests in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (2.28.11.6)\n",
            "Requirement already satisfied: types-ipaddress in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.0.8)\n",
            "Requirement already satisfied: types-xxhash in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (3.0.5.1)\n",
            "Requirement already satisfied: types-maxminddb in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.5.0)\n",
            "Requirement already satisfied: types-cachetools in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (5.2.1)\n",
            "Requirement already satisfied: types-singledispatch in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (3.7.5.1)\n",
            "Requirement already satisfied: types-toml in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.10.8.1)\n",
            "Requirement already satisfied: types-mypy-extensions in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.4.24)\n",
            "Requirement already satisfied: types-docutils in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.19.1.1)\n",
            "Requirement already satisfied: types-pyvmomi in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (8.0.0.0)\n",
            "Requirement already satisfied: types-emoji in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (2.1.0.1)\n",
            "Requirement already satisfied: types-termcolor in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.1.6)\n",
            "Requirement already satisfied: types-PyMySQL in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.0.19.1)\n",
            "Requirement already satisfied: types-pkg-resources in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.1.3)\n",
            "Requirement already satisfied: types-PyYAML in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (6.0.12.2)\n",
            "Requirement already satisfied: types-scribe in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (2.0.0)\n",
            "Requirement already satisfied: types-characteristic in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (14.3.7)\n",
            "Requirement already satisfied: types-Routes in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (2.5.0)\n",
            "Requirement already satisfied: types-fb303 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.0.0)\n",
            "Requirement already satisfied: types-waitress in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (2.1.4.3)\n",
            "Requirement already satisfied: types-docopt in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.6.11)\n",
            "Requirement already satisfied: types-protobuf in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (4.21.0.2)\n",
            "Requirement already satisfied: types-Markdown in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (3.4.2.1)\n",
            "Requirement already satisfied: types-frozendict in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (2.0.9)\n",
            "Requirement already satisfied: types-orjson in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (3.6.2)\n",
            "Requirement already satisfied: types-croniter in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.3.2.1)\n",
            "Requirement already satisfied: types-openssl-python in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.1.3)\n",
            "Requirement already satisfied: types-retry in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.9.9)\n",
            "Requirement already satisfied: types-MarkupSafe in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.1.10)\n",
            "Requirement already satisfied: types-decorator in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (5.1.8.1)\n",
            "Requirement already satisfied: types-nmap in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.1.6)\n",
            "Requirement already satisfied: types-certifi in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (2021.10.8.3)\n",
            "Requirement already satisfied: types-Jinja2 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (2.11.9)\n",
            "Requirement already satisfied: types-six in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.16.21.4)\n",
            "Requirement already satisfied: types-pyfarmhash in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.3.1)\n",
            "Requirement already satisfied: types-geoip2 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (3.0.0)\n",
            "Requirement already satisfied: types-typed-ast in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.5.8.3)\n",
            "Requirement already satisfied: types-enum34 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.1.8)\n",
            "Requirement already satisfied: types-annoy in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.17.8.1)\n",
            "Requirement already satisfied: types-first in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (2.0.5)\n",
            "Requirement already satisfied: types-tornado in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (5.1.1)\n",
            "Requirement already satisfied: types-atomicwrites in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.4.5.1)\n",
            "Requirement already satisfied: types-JACK-Client in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.5.10.3)\n",
            "Requirement already satisfied: types-Flask in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.1.6)\n",
            "Requirement already satisfied: types-pyRFC3339 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.1.1.1)\n",
            "Requirement already satisfied: types-python-slugify in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (7.0.0.1)\n",
            "Requirement already satisfied: types-click in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (7.1.8)\n",
            "Requirement already satisfied: types-filelock in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (3.2.7)\n",
            "Requirement already satisfied: types-mock in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (4.0.15.2)\n",
            "Requirement already satisfied: types-futures in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (3.3.8)\n",
            "Requirement already satisfied: types-tzlocal in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (4.2.2.2)\n",
            "Requirement already satisfied: types-pytz in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (2022.7.0.0)\n",
            "Requirement already satisfied: types-pymssql in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (2.1.0)\n",
            "Requirement already satisfied: types-bleach in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (5.0.3.1)\n",
            "Requirement already satisfied: types-cryptography in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (3.3.23.2)\n",
            "Requirement already satisfied: types-freezegun in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (1.1.10)\n",
            "Requirement already satisfied: types-boto in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (2.49.18.3)\n",
            "Requirement already satisfied: types-python-gflags in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (3.1.7.1)\n",
            "Requirement already satisfied: types-Pillow in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (9.3.0.4)\n",
            "Requirement already satisfied: types-click-spinner in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-all) (0.1.13.1)\n",
            "Requirement already satisfied: types-urllib3<1.27 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from types-requests->types-all) (1.26.25.4)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (2.11.0)\n",
            "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.29.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (65.5.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.6)\n",
            "Requirement already satisfied: packaging in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (14.0.6)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.6.3)\n",
            "Requirement already satisfied: numpy>=1.20 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.21.5)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.42.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.28.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.6.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (3.0.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.12)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\salvador\\anaconda3\\envs\\datos\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "id": "eavKvxYZNtwJ",
        "outputId": "6684d820-9fda-4456-a8f3-f92042d4374f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "pip install keras"
      ],
      "metadata": {
        "id": "Wn4AM_uvNtwK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "#Importación de librerías\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "from xgboost import plot_importance\n",
        "from scipy.stats import zscore\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from collections import Counter\n",
        "import unidecode\n",
        "import re\n",
        "from joblib import load, dump\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
        "from keras.metrics import MeanSquaredError\n",
        "from sklearn.metrics import recall_score, accuracy_score, f1_score, precision_score, r2_score\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n",
        "from collections import defaultdict\n",
        "import math\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import joblib\n",
        "#Configuración de Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=UserWarning)\n",
        "\n",
        "#Ejecución con Drive\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    IN_COLAB = True\n",
        "else:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB :\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    properati = pd.read_csv('/content/drive/MyDrive/📔 Organización de Datos (75.06)/TPS/TP2/1d_df_reducido.csv')\n",
        "    properati_descrip = pd.read_csv('/content/drive/MyDrive/📔 Organización de Datos (75.06)/TPS/TP1/properati_argentina_2021_decrip.csv')\n",
        "    stop_words = '/content/drive/MyDrive/📔 Organización de Datos (75.06)/TPS/TP2/stopwords.txt'\n",
        "else:\n",
        "    # properati = pd.read_csv('./1d_df_reducido.csv')\n",
        "    df_train = pd.read_csv('./DATASETS/df_train_tp1.csv')\n",
        "    df_test = pd.read_csv('./DATASETS/df_test_tp1.csv')\n",
        "    properati_descrip = pd.read_csv('properati_argentina_2021_decrip.csv')\n",
        "    stop_words = 'stopwords'"
      ],
      "metadata": {
        "id": "j_sVsWqyNtwL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Funciones auxiliares"
      ],
      "metadata": {
        "collapsed": false,
        "id": "P0D6ms6ENtwM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def metricas_clasificacion(y_test, y_pred):\n",
        "    print(f'Accuracy: {round(accuracy_score(y_test, y_pred),2)}')\n",
        "    print(f'Precision: {round(precision_score(y_test, y_pred, average=\"macro\"),2)}')\n",
        "    print(f'Recall: {round(recall_score(y_test, y_pred, average=\"macro\"),2)}')\n",
        "    print(f'F1 Score: {round(f1_score(y_test, y_pred, average=\"macro\"),2)}')"
      ],
      "metadata": {
        "id": "orY4phqBNtwM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def prediccion_y_metricas_regresion(regressor, x_test, y_test):\n",
        "\n",
        "  y_pred = regressor.predict(x_test)\n",
        "\n",
        "  print(f\"Se obtuvo un Score de {round(regressor.score(x_test, y_test)*100,3)}%\")\n",
        "\n",
        "  mse = metrics.mean_squared_error(\n",
        "        y_true  = y_test,\n",
        "        y_pred  = y_pred,\n",
        "        squared = True\n",
        "       )\n",
        "\n",
        "  print(f\"El error según la métrica 'Mean Square Error' de test es: {mse}\")\n",
        "\n",
        "  rmse = metrics.mean_squared_error(\n",
        "        y_true  = y_test,\n",
        "        y_pred  = y_pred,\n",
        "        squared = False\n",
        "       )\n",
        "\n",
        "  print(f\"El error según la métrica 'Root Mean Square Error' de test es: {rmse}\")\n",
        "\n",
        "  return"
      ],
      "metadata": {
        "id": "rNaCoDhaNtwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_aspects(line, word):\n",
        "    format = r\"\\W*([\\w]+)\"\n",
        "    n = 2\n",
        "    x = re.search(r'{}\\W*{}{}'.format(format*n, word, format*n), line)\n",
        "    if x is not None:\n",
        "        return x.group()\n",
        "    else:\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "CCKsO-A5w7TQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_b_m_a(x):\n",
        "    mx = max(x[0], x[1], x[2])\n",
        "    if mx == x[0]:\n",
        "        return 'bajo'\n",
        "    elif mx == x[1]:\n",
        "        return 'medio'\n",
        "    elif mx == x[2]:\n",
        "        return 'alto'"
      ],
      "metadata": {
        "id": "3suAr0ciwY91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def estandarizar(df, columns):\n",
        "  sscaler = StandardScaler()\n",
        "\n",
        "  for col in columns:\n",
        "    df[col] = sscaler.fit_transform(pd.DataFrame(df[col]))"
      ],
      "metadata": {
        "id": "0LF1eyB9l4nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def limpiar_values_de_aspects(df, aspects, values):\n",
        "    i = 0\n",
        "    for aspect in aspects:\n",
        "        for word in values[i]:\n",
        "            df[aspect] = df[aspect].apply(lambda line: word if word in line else line)\n",
        "        df[aspect] = df[aspect].apply(lambda line: line if len(line.split())<2 else '')\n",
        "        i = i+1"
      ],
      "metadata": {
        "id": "AAEy2PV92DpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, x, y, splits, n):\n",
        "    cv = RepeatedStratifiedKFold(n_splits=splits, n_repeats=n, random_state=1)\n",
        "    scores = cross_val_score(model, x, y, scoring='neg_mean_squared_error', cv=cv, verbose=1, n_jobs=3, error_score='raise')\n",
        "    return scores"
      ],
      "metadata": {
        "id": "tDt5-bPcEn_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "def plot_results(model_scores, name):\n",
        "    \n",
        "    model_names = list(model_scores.keys())\n",
        "    results = [model_scores[model] for model in model_names]\n",
        "    fig = go.Figure()\n",
        "    for model, result in zip(model_names, results):\n",
        "        fig.add_trace(go.Box(\n",
        "            y=result,\n",
        "            name=model,\n",
        "            boxpoints='all',\n",
        "            jitter=0.5,\n",
        "            whiskerwidth=0.2,\n",
        "            marker_size=2,\n",
        "            line_width=1)\n",
        "        )\n",
        "    \n",
        "    fig.update_layout(\n",
        "    title='Performance of Different Models Using 5-Fold Cross-Validation',\n",
        "    paper_bgcolor='rgb(243, 243, 243)',\n",
        "    plot_bgcolor='rgb(243, 243, 243)',\n",
        "    xaxis_title='Model',\n",
        "    yaxis_title='Error Cuadrático Medio',\n",
        "    showlegend=False)\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "NImxsouY4HaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparación de datasets"
      ],
      "metadata": {
        "id": "yG33nESmvkqN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "df_train_x = df_train.drop([\"property_price\", \"tipo_precio_3\"], axis=\"columns\")\n",
        "df_train_y_regresion = df_train[\"property_price\"]\n",
        "df_train_y_clasificacion = df_train[\"tipo_precio_3\"]\n",
        "\n",
        "df_test_x = df_test.drop([\"property_price\", \"tipo_precio_3\"], axis=\"columns\")\n",
        "df_test_y_regresion = df_test[\"property_price\"]\n",
        "df_test_y_clasificacion = df_test[\"tipo_precio_3\"]"
      ],
      "metadata": {
        "id": "Cn2iKXxmNtwQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Procesamiento del Lenguaje Natural"
      ],
      "metadata": {
        "collapsed": false,
        "id": "DajLENWv2DpA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.a Ampliación del dataset\n",
        "___"
      ],
      "metadata": {
        "id": "mmjJ3qskuJyJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hacemos un merge del dataset original y el de descripciones, y quedémonos únicamente con las columnas `id` y `property_description`:"
      ],
      "metadata": {
        "id": "904YC-oLyddb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "df_descrip = pd.merge(df_train_x, properati_descrip, on=\"id\")\n",
        "df_descrip = df_descrip[[\"id\", \"property_description\"]]\n",
        "\n",
        "df_test_descrip = pd.merge(df_test_x, properati_descrip, on=\"id\")\n",
        "df_test_descrip = df_test_descrip[[\"id\", \"property_description\"]]"
      ],
      "metadata": {
        "id": "vRbU2jpk2Do_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "                             id  \\\n0      ahcEMvB66wjPz0SYWZQDBw==   \n1      M0g0l0s6S13X+cZlGkUo8g==   \n2      V/KMMLRRx/Nn+g3m5lrW7A==   \n3      odR0QjYc3xtaYfqNJvbOSQ==   \n4      RqOcPIKYYZDG+CFMq2c1RA==   \n...                         ...   \n18600  g2fBcuyxiq3V0GdPATLFDw==   \n18601  2jfcV70r5M8iASKFbpFEqA==   \n18602  H4X7bNq04pK7U6fCcbxYNg==   \n18603  QWBP5Zp0TBUlFrzP9GO9bA==   \n18604  pKo6hHHPBZJydrHIn5S5Tg==   \n\n                                    property_description  \n0      Corredor Responsable: Juan Carlos Treco - CUCI...  \n1      Corredor Responsable: Micaela Perez / Lucas Fe...  \n2      Corredor Responsable: Gustavo Guastello - C.U....  \n3      PH A ESTRENAR SANCHEZ DE LORIA AL 1500 Y CONST...  \n4      EXCELENTE SEMIPISO 3 AMB C/BALCON LUMINOSO EN ...  \n...                                                  ...  \n18600  Venta DEPARTAMENTO 2 Ambientes Villa Ortuzar. ...  \n18601  Departamento a estrenar monoambiente, luminoso...  \n18602  Corredor Responsable: Daniel Acosta - CUCICBA ...  \n18603  El departamento se ubica en la PB y contiene:<...  \n18604  Departamento tipo PH en el hermoso edificio hi...  \n\n[18605 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>property_description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ahcEMvB66wjPz0SYWZQDBw==</td>\n      <td>Corredor Responsable: Juan Carlos Treco - CUCI...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M0g0l0s6S13X+cZlGkUo8g==</td>\n      <td>Corredor Responsable: Micaela Perez / Lucas Fe...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>V/KMMLRRx/Nn+g3m5lrW7A==</td>\n      <td>Corredor Responsable: Gustavo Guastello - C.U....</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>odR0QjYc3xtaYfqNJvbOSQ==</td>\n      <td>PH A ESTRENAR SANCHEZ DE LORIA AL 1500 Y CONST...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RqOcPIKYYZDG+CFMq2c1RA==</td>\n      <td>EXCELENTE SEMIPISO 3 AMB C/BALCON LUMINOSO EN ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>18600</th>\n      <td>g2fBcuyxiq3V0GdPATLFDw==</td>\n      <td>Venta DEPARTAMENTO 2 Ambientes Villa Ortuzar. ...</td>\n    </tr>\n    <tr>\n      <th>18601</th>\n      <td>2jfcV70r5M8iASKFbpFEqA==</td>\n      <td>Departamento a estrenar monoambiente, luminoso...</td>\n    </tr>\n    <tr>\n      <th>18602</th>\n      <td>H4X7bNq04pK7U6fCcbxYNg==</td>\n      <td>Corredor Responsable: Daniel Acosta - CUCICBA ...</td>\n    </tr>\n    <tr>\n      <th>18603</th>\n      <td>QWBP5Zp0TBUlFrzP9GO9bA==</td>\n      <td>El departamento se ubica en la PB y contiene:&lt;...</td>\n    </tr>\n    <tr>\n      <th>18604</th>\n      <td>pKo6hHHPBZJydrHIn5S5Tg==</td>\n      <td>Departamento tipo PH en el hermoso edificio hi...</td>\n    </tr>\n  </tbody>\n</table>\n<p>18605 rows × 2 columns</p>\n</div>"
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test_descrip"
      ],
      "metadata": {
        "id": "tTYc6ZbPNtwR",
        "outputId": "d8eccc85-fedd-4b37-cacf-45c3024b3da6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Busquemos aspectos de una propiedad utilizando la columna `property_description`."
      ],
      "metadata": {
        "id": "uCEL8YyUxYaa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos cuántos registros nulos existen:"
      ],
      "metadata": {
        "id": "tAEE-G_QzCXj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hay 0 datos nulos.\n"
          ]
        }
      ],
      "source": [
        "print(f\"Hay {df_descrip['property_description'].isna().sum()} datos nulos.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydHTArN62DpA",
        "outputId": "532aec7a-b0bc-4f97-d56d-80ee53135a25"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos cuáles son las 100 palabras más comunes en el campo de descripción de propiedades:"
      ],
      "metadata": {
        "id": "t4hiRECrz3Wa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "[('de', 857976),\n ('y', 507778),\n ('con', 401867),\n ('la', 290195),\n ('en', 278176),\n ('a', 243751),\n ('el', 169952),\n ('del', 153279),\n ('que', 140055),\n ('por', 133635),\n ('al', 125215),\n ('-', 113875),\n ('un', 103716),\n ('las', 90713),\n ('los', 88435),\n ('para', 88190),\n ('se', 63109),\n ('DE', 56457),\n ('son', 56420),\n ('2', 52790),\n ('es', 50384),\n ('una', 48927),\n ('3', 41258),\n ('cocina', 38889),\n ('ambientes', 38848),\n ('valor', 38420),\n ('esta', 38292),\n ('muy', 36893),\n ('x', 36800),\n ('Av.', 36630),\n ('comedor', 35535),\n ('baño', 35476),\n ('Y', 34141),\n ('CON', 33915),\n ('no', 33912),\n ('piso', 33348),\n ('o', 33050),\n ('/', 32253),\n ('tu', 32101),\n ('A', 32063),\n ('hasta', 30269),\n ('balcón', 29805),\n ('inmueble', 28725),\n ('casa', 28655),\n ('No', 28635),\n ('propiedad.', 28070),\n ('30%', 27684),\n ('departamento', 27670),\n ('EN', 27267),\n ('cuadras', 27069),\n ('Corredor', 26991),\n ('préstamo', 26920),\n ('cuota', 26780),\n ('medidas', 26422),\n ('Responsable:', 25970),\n ('living', 25952),\n ('4', 25848),\n ('Lendar', 25571),\n ('querés!', 25421),\n ('podés.', 25362),\n ('Accedé', 25354),\n ('Simulá', 25349),\n ('#', 25248),\n ('ID', 25231),\n ('MLS', 25227),\n ('CUCICBA', 24648),\n ('El', 24541),\n ('edificio', 24305),\n ('dos', 24304),\n ('cuenta', 24241),\n ('personas', 23936),\n ('completo', 23797),\n ('propiedad', 23309),\n ('salida', 23058),\n ('parte', 22277),\n (',', 22138),\n ('pisos', 21621),\n ('encuentra', 21617),\n ('frente', 21612),\n ('Las', 21073),\n ('1', 20964),\n ('amplio', 20885),\n ('Comprá', 20793),\n ('\\\\n\\\\n', 20732),\n ('vista', 19912),\n ('presente', 19511),\n ('dormitorio', 19499),\n ('Ley', 19317),\n ('gran', 19096),\n ('La', 18859),\n ('placard', 18483),\n ('espacio', 18475),\n ('metros', 18400),\n ('m2', 17976),\n ('Los', 17521),\n ('<br>', 17369),\n ('accesible', 17076),\n ('su', 16596),\n ('dormitorios', 16161),\n ('sobre', 16145)]"
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Counter(\" \".join(df_descrip[\"property_description\"]).split()).most_common(100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpAlq6jJ2DpC",
        "outputId": "ba6d7ea0-e0b6-4446-d3e2-550d723373d2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos observar que podríamos optimizar el texto mediante algunas técnicas de reducción y/o transformación. Entre otras:"
      ],
      "metadata": {
        "id": "iwnQ6tgt0MRV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eliminemos la etiqueta `<br>` de html:"
      ],
      "metadata": {
        "id": "qK78Ucya0Ugr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_descrip[\"property_description\"] = df_descrip[\"property_description\"].apply(lambda line: line.replace(\"<br>\", \" \"))\n",
        "df_test_descrip[\"property_description\"] = df_test_descrip[\"property_description\"].apply(lambda line: line.replace(\"<br>\", \" \"))"
      ],
      "metadata": {
        "id": "_o_B51Zk0hGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformemos todas las palabras a minúsculas, de modo que el contador no realice distinciones:"
      ],
      "metadata": {
        "id": "pyNp4Y520yHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_descrip[\"property_description\"] = df_descrip[\"property_description\"].apply(lambda line: line.lower())\n",
        "df_test_descrip[\"property_description\"] = df_test_descrip[\"property_description\"].apply(lambda line: line.lower())\n"
      ],
      "metadata": {
        "id": "VWBmcgfI04Ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quitemos los tíldes de las letras:"
      ],
      "metadata": {
        "id": "WpSPMtks1bZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_descrip[\"property_description\"] = df_descrip[\"property_description\"].apply(lambda line: unidecode.unidecode(line))\n",
        "df_test_descrip[\"property_description\"] = df_test_descrip[\"property_description\"].apply(lambda line: unidecode.unidecode(line))"
      ],
      "metadata": {
        "id": "KWHrTmAG1dGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eliminemos los símbolos:"
      ],
      "metadata": {
        "id": "tpUndCZy1j2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_descrip[\"property_description\"] = df_descrip[\"property_description\"].apply(lambda line: re.sub(r'[^\\w]', ' ', line))\n",
        "df_test_descrip[\"property_description\"] = df_test_descrip[\"property_description\"].apply(lambda line: re.sub(r'[^\\w]', ' ', line))"
      ],
      "metadata": {
        "id": "sWcF2SIJ1lfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eliminemos los espacios múltiples entre palabras:"
      ],
      "metadata": {
        "id": "bdqDlvqN1rL1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "df_descrip[\"property_description\"] = df_descrip[\"property_description\"].apply(lambda line: re.sub(\"\\s\\s+\" , \" \", line))\n",
        "df_test_descrip[\"property_description\"] = df_test_descrip[\"property_description\"].apply(lambda line: re.sub(\"\\s\\s+\" , \" \", line))"
      ],
      "metadata": {
        "id": "uQvajcwC2DpE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizando el contenido del archivo `stop_words.txt`, eliminemos palabras sin significado del datset y colocamos los cambios en uno nuevo:"
      ],
      "metadata": {
        "id": "BzcWZSJY4GPs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "with open(stop_words) as f:\n",
        "    lines = f.read().splitlines()\n",
        "\n",
        "f = lambda x: ' '.join([item for item in x.split() if item not in lines])\n",
        "\n",
        "df_descrip[\"property_description\"] = df_descrip[\"property_description\"].apply(f)\n",
        "df_test_descrip[\"property_description\"] = df_test_descrip[\"property_description\"].apply(f)"
      ],
      "metadata": {
        "id": "FrOeCCBY2DpF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luego de estas transformaciones, veamos cuáles son las palabras más utilizadas:"
      ],
      "metadata": {
        "id": "JYXs-85EVQwx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "[('cocina', 89458),\n ('2', 88203),\n ('bano', 74428),\n ('3', 74274),\n ('ambientes', 71516),\n ('balcon', 71288),\n ('comedor', 68490),\n ('piso', 67830),\n ('living', 63837),\n ('propiedad', 62558),\n ('departamento', 54476),\n ('edificio', 53422),\n ('av', 50583),\n ('1', 50142),\n ('dormitorio', 48859),\n ('completo', 48391),\n ('pisos', 46212),\n ('4', 46043),\n ('frente', 44713),\n ('expensas', 44286),\n ('n', 44023),\n ('excelente', 41314),\n ('corredor', 41145),\n ('medidas', 41046),\n ('x', 40904),\n ('inmueble', 40569),\n ('responsable', 37723),\n ('amplio', 36355),\n ('m2', 34044),\n ('30', 34027),\n ('placard', 33948),\n ('casa', 32676),\n ('dormitorios', 32257),\n ('lavadero', 31877),\n ('c', 31791),\n ('cuadras', 31165),\n ('luminoso', 30549),\n ('cucicba', 30414),\n ('accede', 29382),\n ('terraza', 29328),\n ('ley', 27849),\n ('aire', 27700),\n ('lendar', 27449),\n ('queres', 27416),\n ('prestamo', 27366),\n ('vista', 26980),\n ('venta', 26867),\n ('cuota', 26856),\n ('podes', 26580),\n ('salida', 26111),\n ('ubicacion', 25546),\n ('simula', 25536),\n ('id', 25235),\n ('cochera', 25233),\n ('mls', 25230),\n ('personas', 24976),\n ('espacio', 24793),\n ('5', 24267),\n ('planta', 23607),\n ('zona', 23396),\n ('compra', 23246),\n ('metros', 23075),\n ('independiente', 23073),\n ('inmobiliario', 22866),\n ('patio', 22294),\n ('servicio', 22214),\n ('principal', 21845),\n ('barrio', 21305),\n ('ubicado', 21087),\n ('linea', 20909),\n ('parrilla', 20747),\n ('mesada', 20701),\n ('suite', 20635),\n ('toilette', 20555),\n ('acceso', 20485),\n ('presente', 19926),\n ('servicios', 19773),\n ('accesible', 19275),\n ('subte', 18715),\n ('unidades', 18413),\n ('agua', 18371),\n ('mas', 18246),\n ('acondicionado', 18043),\n ('hall', 17969),\n ('b', 17717),\n ('operacion', 17568),\n ('aviso', 17401),\n ('unidad', 16996),\n ('24', 16901),\n ('comercial', 16525),\n ('madera', 16499),\n ('doble', 16416),\n ('propietario', 16374),\n ('calefaccion', 16297),\n ('calidad', 16139),\n ('entrada', 15982),\n ('discapacidades', 15931),\n ('informacion', 15902),\n ('estacion', 15816),\n ('operaciones', 15668)]"
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Counter(\" \".join(df_descrip[\"property_description\"]).split()).most_common(100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNYcv0DM2DpG",
        "outputId": "eed3ff96-3911-4d2a-a042-969e76b82e01"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seleccionemos los aspectos que nos parecen relevantes, para luego buscar sus posibles valores.\n",
        "\n",
        "Para esto, elegimos: `cocina`, `pisos`, `calefaccion`, `expensas`, `lavadero`, `balcon`, `cochera` y `aire` y limpiamos cualquier tipo de formato restante en el dataset:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "Ai_Odw_x2DpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aspectos = ['cocina', 'pisos', 'calefaccion', 'expensas', 'lavadero', 'balcon', 'cochera', 'aire']"
      ],
      "metadata": {
        "id": "BkHpD1gtB7e_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "for word in aspectos:\n",
        "    df_descrip[word] = df_descrip[\"property_description\"].apply(lambda line: format_aspects(line, word))\n",
        "    df_test_descrip[word] = df_test_descrip[\"property_description\"].apply(lambda line: format_aspects(line, word))"
      ],
      "metadata": {
        "id": "AnaswxtR2DpH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos cuáles son las 15 palabras más comunes para cada uno de los aspectos elegidos:"
      ],
      "metadata": {
        "id": "EDsk7Bjgx116"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cant_val_aspectos = 15"
      ],
      "metadata": {
        "id": "eYdLqsvGyNcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Aspecto `cocina`\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wWJKdB85y1l0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "[('cocina', 62810),\n ('comedor', 19198),\n ('integrada', 11530),\n ('living', 9979),\n ('bano', 8949),\n ('lavadero', 6978),\n ('balcon', 6225),\n ('independiente', 6077),\n ('completo', 5385),\n ('diario', 4992),\n ('muebles', 4829),\n ('separada', 4746),\n ('amplia', 4518),\n ('toilette', 3963),\n ('completa', 3692)]"
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Counter(\" \".join(df_descrip[\"cocina\"]).split()).most_common(cant_val_aspectos)"
      ],
      "metadata": {
        "id": "l-7v9FP82DpH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bea24da-1ae1-4df4-eb9a-5fddb082398b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para `cocina`, los valores podrían ser: \n",
        "- integrada\n",
        "- lavadero\n",
        "- completa"
      ],
      "metadata": {
        "collapsed": false,
        "id": "6ACLlV0F2DpI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Aspecto `pisos`"
      ],
      "metadata": {
        "id": "1XQ4TVyUzSqc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "[('pisos', 31829),\n ('parquet', 6394),\n ('madera', 4426),\n ('porcelanato', 4025),\n ('living', 3671),\n ('edificio', 3624),\n ('comedor', 3155),\n ('unidades', 1821),\n ('cocina', 1754),\n ('departamentos', 1662),\n ('bano', 1576),\n ('2', 1411),\n ('4', 1314),\n ('3', 1241),\n ('ambientes', 1201)]"
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Counter(\" \".join(df_descrip[\"pisos\"]).split()).most_common(cant_val_aspectos)"
      ],
      "metadata": {
        "id": "UQQMsrnL2DpI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a261ec0d-9cd6-4277-98b0-7b18d0b28211"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para `pisos`, los valores podrían ser: \n",
        "- porcelanato\n",
        "- parquet\n",
        "- madera"
      ],
      "metadata": {
        "collapsed": false,
        "id": "l39ZahiN2DpJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Aspecto `calefaccion`"
      ],
      "metadata": {
        "id": "a4pG3YbW1wnt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "[('calefaccion', 15449),\n ('radiante', 4448),\n ('losa', 3916),\n ('central', 3444),\n ('caliente', 2653),\n ('agua', 2257),\n ('radiadores', 2052),\n ('individual', 1921),\n ('aire', 1777),\n ('piso', 1527),\n ('caldera', 1246),\n ('tiro', 1197),\n ('acondicionado', 1097),\n ('servicios', 1056),\n ('ambientes', 798)]"
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Counter(\" \".join(df_descrip[\"calefaccion\"]).split()).most_common(cant_val_aspectos)"
      ],
      "metadata": {
        "id": "RPZApHfA2DpJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67f4d899-74cf-4d93-ea99-c89946b6f262"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para `calefaccion`, los valores podrían ser: \n",
        "- radiadores\n",
        "- radiante\n",
        "- central\n",
        "- individual"
      ],
      "metadata": {
        "collapsed": false,
        "id": "Mt-7dfsl2DpK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Aspecto `expensas`"
      ],
      "metadata": {
        "id": "XfzRZc861ysa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "[('expensas', 35164),\n ('servicios', 6846),\n ('impuestos', 5906),\n ('valores', 5559),\n ('bajas', 4879),\n ('funcionales', 4365),\n ('000', 3296),\n ('abl', 2445),\n ('medidas', 1959),\n ('aysa', 1606),\n ('sujetos', 1542),\n ('propiedad', 1276),\n ('superficies', 1260),\n ('indicados', 1242),\n ('consignadas', 1189),\n ('2021', 1147),\n ('tasas', 1143),\n ('mensuales', 1138),\n ('consignado', 1084),\n ('gastos', 1053),\n ('presente', 1046),\n ('ambientes', 1044),\n ('sujeto', 947),\n ('500', 942),\n ('edificio', 915),\n ('aprox', 867),\n ('4', 836),\n ('incluyen', 829),\n ('2', 819),\n ('3', 806)]"
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Counter(\" \".join(df_descrip[\"expensas\"]).split()).most_common(cant_val_aspectos*2)"
      ],
      "metadata": {
        "id": "iRKPdGhA2DpK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e89ec902-f5d3-45e5-df24-45d796fd889b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para `expensas`, los valores podrían ser: \n",
        "- servicios\n",
        "- impuestos \n",
        "- bajas"
      ],
      "metadata": {
        "collapsed": false,
        "id": "C7EiojY82DpK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Aspecto `lavadero`"
      ],
      "metadata": {
        "id": "ZVVvuLxu11U0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "[('lavadero', 28549),\n ('independiente', 7972),\n ('cocina', 7923),\n ('comedor', 4376),\n ('bano', 4342),\n ('diario', 3175),\n ('servicio', 2922),\n ('dependencia', 2920),\n ('incorporado', 2506),\n ('completo', 2102),\n ('patio', 1882),\n ('separado', 1807),\n ('balcon', 1738),\n ('espacio', 1736),\n ('toilette', 1385)]"
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Counter(\" \".join(df_descrip[\"lavadero\"]).split()).most_common(cant_val_aspectos)"
      ],
      "metadata": {
        "id": "sAzBKC5c2DpK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c811e281-914c-4804-fe87-064ada17a12d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para `lavadero`, los valores podrían ser: \n",
        "- independiente\n",
        "- cocina\n",
        "- comedor"
      ],
      "metadata": {
        "collapsed": false,
        "id": "i8zxU-Co2DpL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Aspecto `balcon`"
      ],
      "metadata": {
        "id": "0opxhwgx122i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "[('balcon', 42917),\n ('salida', 9996),\n ('frente', 9711),\n ('comedor', 8052),\n ('ambientes', 6387),\n ('corrido', 6126),\n ('cocina', 4569),\n ('living', 4207),\n ('vista', 4051),\n ('amplio', 3716),\n ('terraza', 3682),\n ('aterrazado', 3172),\n ('2', 3151),\n ('luminoso', 2855),\n ('3', 2684)]"
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Counter(\" \".join(df_descrip[\"balcon\"]).split()).most_common(cant_val_aspectos)"
      ],
      "metadata": {
        "id": "geCmhGct2DpL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f9103b9-03aa-4035-dd78-c3a1c435e833"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para `balcon`, los valores podrían ser: \n",
        "- frente\n",
        "- amplio \n",
        "- terraza \n",
        "- salida \n",
        "- corrido\n",
        "- luminoso"
      ],
      "metadata": {
        "collapsed": false,
        "id": "GUiM00PQ2DpL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Aspecto `cochera`"
      ],
      "metadata": {
        "id": "W05qxE7f138s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "[('cochera', 17208),\n ('cocheras', 7359),\n ('fija', 4756),\n ('cubierta', 4118),\n ('ambientes', 3484),\n ('baulera', 2863),\n ('2', 2467),\n ('edificio', 2119),\n ('balcon', 1521),\n ('3', 1399),\n ('opcional', 1307),\n ('1', 1132),\n ('fijas', 1080),\n ('terraza', 1007),\n ('dependencia', 979),\n ('posibilidad', 958),\n ('piso', 826),\n ('frente', 780),\n ('bano', 760),\n ('disponibles', 759),\n ('departamento', 759),\n ('4', 753),\n ('servicio', 729),\n ('planta', 701),\n ('parrilla', 699),\n ('espacio', 615),\n ('subsuelo', 598),\n ('amenities', 586),\n ('completo', 553),\n ('patio', 525)]"
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Counter(\" \".join(df_descrip[\"cochera\"]).split()).most_common(cant_val_aspectos*2)"
      ],
      "metadata": {
        "id": "vF7x7sFV2DpL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa1e9494-2db9-48dd-8101-5987d80ccb55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para `cochera`, los valores podrían ser: \n",
        "- fija\n",
        "- cubierta"
      ],
      "metadata": {
        "collapsed": false,
        "id": "_sGYjhjF2DpM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Aspecto `aire`"
      ],
      "metadata": {
        "id": "ehAh9leY2Lfu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "[('aire', 20578),\n ('acondicionado', 14337),\n ('frio', 5985),\n ('aires', 5809),\n ('split', 2204),\n ('ciudad', 2020),\n ('acondicionados', 1961),\n ('luz', 1851),\n ('equipos', 1585),\n ('calefaccion', 1493),\n ('instalacion', 1413),\n ('ambientes', 1411),\n ('living', 1138),\n ('central', 1062),\n ('balcon', 1002)]"
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Counter(\" \".join(df_descrip[\"aire\"]).split()).most_common(cant_val_aspectos)"
      ],
      "metadata": {
        "id": "eQlqeMRa2DpM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa0a82b5-9f5b-4ab4-80b7-f0090e746727"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para `aire`, posibles valores son: \n",
        "- split \n",
        "- central \n",
        "- acondicionado"
      ],
      "metadata": {
        "collapsed": false,
        "id": "9hWHT90P2DpM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Consolidación de valores"
      ],
      "metadata": {
        "id": "fF4R61si2RJI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación creamos la variable `values`, que contiene los posibles valores para cada uno de los aspectos elegidos:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "ZTu9pPYV2DpN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "values_cocina = ['integrada' , 'lavadero' , 'completa']\n",
        "values_pisos = ['porcelanato' , 'parquet' , 'madera']\n",
        "values_calefaccion = ['radiadores' , 'radiante' , 'central' , 'individual']\n",
        "values_expensas = ['serviocios' , 'impuestos' , 'bajas']\n",
        "values_lavadero = ['independiente' , 'cocina' , 'comedor']\n",
        "values_balcon = ['frente' , 'amplio' , 'terraza' , 'salida' , 'corrido' , 'luminoso']\n",
        "values_cochera = ['fija' , 'cubierta']\n",
        "values_aire = ['split' , 'central' , 'acondicionado']"
      ],
      "metadata": {
        "id": "8woiCcO32DpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "values = [values_cocina, values_pisos, values_calefaccion, values_expensas, values_lavadero, values_balcon, values_cochera, values_aire]"
      ],
      "metadata": {
        "id": "CFU_0j0EGUE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En primer lugar, creamos un dataset auxiliar que tenga los IDs y las columnas de los aspectos:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "B9JpAzOi2DpN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "aux_df = df_descrip.copy()\n",
        "aux_df_test = df_test_descrip.copy()\n",
        "\n",
        "aux_df.drop('property_description', inplace=True, axis=1)\n",
        "aux_df_test.drop('property_description', inplace=True, axis=1)"
      ],
      "metadata": {
        "id": "Z617kPUE2DpN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luego creamos una función a la que -pasándole un dataset, los aspectos y el listado de valores posibles- reemplace el contenido de las columnas por los valores correspondientes."
      ],
      "metadata": {
        "collapsed": false,
        "id": "qpHzefm72DpO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modificamos las columnas de los aspectos, para que sólo queden los valores correspondientes:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "8A7lmncH2DpO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "                          id    cocina pisos calefaccion   expensas  \\\n0   mQStJ0NPSYuW7WA/0yOYuA==                                          \n1   Gi/LqlLpBXSMH9vD5kWUcw==                                          \n2   iYU9D39208HZ55k43esCsQ==                    radiante              \n3   u8oPwCg2R/C105SlZ9nlaQ==  lavadero                                \n4   RZ744+VZFnLS5FWxmtTJ7A==                    radiante              \n5   NbzjXoT+aeAnxr2lTv1Whw==                    radiante              \n6   5lBJkaOpRzdbcOFuJ59/4A==  lavadero                                \n7   WUZ/JS1/1oszsRErSr8PJg==                                          \n8   EKIOdcAhuwcww5BfkZ+6ig==                                          \n9   QmnVieT3iXh1oktdzYLRlw==                                          \n10  hwKrPY/jtN9LHTfrBn0icQ==                                          \n11  22U4lOQGJ/V8qegwRwe8lw==                                          \n12  pcjSyDd82IYXeVAPrpXjyw==                                          \n13  GfWpjTvrEdhVibSYOUXiAA==                                          \n14  M5IUi8ASsbZEycYtMbzxdw==                                          \n15  MMvaHE4jydryetM6loC2nw==                                          \n16  8QDiKrZx64C0FxyfLsesHA==                                          \n17  70wNmuUXl6DK0PjTj/6/2A==                                          \n18  0doVMJvCbwNr0TYfUtkMQg==                              impuestos   \n19  zp/cmtmUY2AlxUYMnXBKbw==                                          \n\n         lavadero   balcon cochera           aire  \n0         comedor  terraza                         \n1                                                  \n2                  terraza                         \n3          cocina   salida                         \n4                  terraza                         \n5                  terraza                         \n6          cocina                                  \n7                                                  \n8                                                  \n9                                                  \n10                                                 \n11                                                 \n12                                                 \n13                                                 \n14                                                 \n15                                                 \n16                                                 \n17                                                 \n18                                                 \n19  independiente  terraza          acondicionado  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cocina</th>\n      <th>pisos</th>\n      <th>calefaccion</th>\n      <th>expensas</th>\n      <th>lavadero</th>\n      <th>balcon</th>\n      <th>cochera</th>\n      <th>aire</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>mQStJ0NPSYuW7WA/0yOYuA==</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>comedor</td>\n      <td>terraza</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Gi/LqlLpBXSMH9vD5kWUcw==</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>iYU9D39208HZ55k43esCsQ==</td>\n      <td></td>\n      <td></td>\n      <td>radiante</td>\n      <td></td>\n      <td></td>\n      <td>terraza</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>u8oPwCg2R/C105SlZ9nlaQ==</td>\n      <td>lavadero</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>cocina</td>\n      <td>salida</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RZ744+VZFnLS5FWxmtTJ7A==</td>\n      <td></td>\n      <td></td>\n      <td>radiante</td>\n      <td></td>\n      <td></td>\n      <td>terraza</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>NbzjXoT+aeAnxr2lTv1Whw==</td>\n      <td></td>\n      <td></td>\n      <td>radiante</td>\n      <td></td>\n      <td></td>\n      <td>terraza</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>5lBJkaOpRzdbcOFuJ59/4A==</td>\n      <td>lavadero</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>cocina</td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>WUZ/JS1/1oszsRErSr8PJg==</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>EKIOdcAhuwcww5BfkZ+6ig==</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>QmnVieT3iXh1oktdzYLRlw==</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>hwKrPY/jtN9LHTfrBn0icQ==</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>22U4lOQGJ/V8qegwRwe8lw==</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>pcjSyDd82IYXeVAPrpXjyw==</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>GfWpjTvrEdhVibSYOUXiAA==</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>M5IUi8ASsbZEycYtMbzxdw==</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>MMvaHE4jydryetM6loC2nw==</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>8QDiKrZx64C0FxyfLsesHA==</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>70wNmuUXl6DK0PjTj/6/2A==</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0doVMJvCbwNr0TYfUtkMQg==</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>impuestos</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>zp/cmtmUY2AlxUYMnXBKbw==</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>independiente</td>\n      <td>terraza</td>\n      <td></td>\n      <td>acondicionado</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "limpiar_values_de_aspects(aux_df, aspectos, values)\n",
        "limpiar_values_de_aspects(aux_df_test, aspectos, values)\n",
        "aux_df.head(20)"
      ],
      "metadata": {
        "id": "WXhzGxCl2DpO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "3355d0c0-87e8-4707-b349-e4d9b468bfa9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por último hacemos el merge con el dataset original, teniendo en cuenta los IDs:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "Ia2LxOLq2DpP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "    start_date  end_date    latitud   longitud  property_rooms  \\\n0       737971    737991 -34.576973 -58.406591             7.0   \n1       737867    737868 -34.610046 -58.361382             4.0   \n2       737875    738097 -34.569770 -58.431032             4.0   \n3       738132    738182 -34.579756 -58.406144             3.0   \n4       737875    738097 -34.569770 -58.431032             4.0   \n5       737875    738097 -34.569770 -58.431032             4.0   \n6       738019    738182 -34.647545 -58.497062             5.0   \n7       737829    737871 -34.608300 -58.371200             5.0   \n8       737838    737847 -34.605406 -58.400957             1.0   \n9       737956    738048 -34.592467 -58.445158             1.0   \n10      737999    738001 -34.562379 -58.454491             3.0   \n11      737999    738001 -34.628692 -58.463322             3.0   \n12      737999    738001 -34.562379 -58.454491             3.0   \n13      737999    738001 -34.605478 -58.404722             3.0   \n14      737860    737946 -34.605862 -58.422360             3.0   \n15      737999    738002 -34.593817 -58.404138             3.0   \n16      737999    738001 -34.628692 -58.463322             3.0   \n17      737999    738001 -34.605478 -58.404722             3.0   \n18      737924    737924 -34.633013 -58.527117             2.0   \n19      737910    737918 -34.562379 -58.454491             5.0   \n\n    property_surface_total  place_l4_Agronomía  place_l4_Almagro  \\\n0                    415.0                   0                 0   \n1                    194.0                   0                 0   \n2                    260.0                   0                 0   \n3                    120.0                   0                 0   \n4                    165.0                   0                 0   \n5                    165.0                   0                 0   \n6                    132.0                   0                 0   \n7                    300.0                   0                 0   \n8                    325.0                   0                 0   \n9                    122.0                   0                 0   \n10                    50.0                   0                 0   \n11                    50.0                   0                 0   \n12                    50.0                   0                 0   \n13                    50.0                   0                 0   \n14                    50.0                   0                 1   \n15                    50.0                   0                 0   \n16                    50.0                   0                 0   \n17                    50.0                   0                 0   \n18                   240.0                   0                 0   \n19                   139.0                   0                 0   \n\n    place_l4_Balvanera  place_l4_Barracas  ...  property_type_Departamento  \\\n0                    0                  0  ...                           1   \n1                    0                  0  ...                           1   \n2                    0                  0  ...                           1   \n3                    0                  0  ...                           1   \n4                    0                  0  ...                           1   \n5                    0                  0  ...                           1   \n6                    0                  0  ...                           0   \n7                    0                  0  ...                           0   \n8                    0                  0  ...                           1   \n9                    0                  0  ...                           1   \n10                   0                  0  ...                           0   \n11                   0                  0  ...                           1   \n12                   0                  0  ...                           1   \n13                   0                  0  ...                           1   \n14                   0                  0  ...                           1   \n15                   0                  0  ...                           1   \n16                   0                  0  ...                           0   \n17                   0                  0  ...                           0   \n18                   0                  0  ...                           0   \n19                   0                  0  ...                           1   \n\n    property_type_PH    cocina  pisos  calefaccion   expensas       lavadero  \\\n0                  0                                                 comedor   \n1                  0                                                           \n2                  0                      radiante                             \n3                  0  lavadero                                        cocina   \n4                  0                      radiante                             \n5                  0                      radiante                             \n6                  1  lavadero                                        cocina   \n7                  0                                                           \n8                  0                                                           \n9                  0                                                           \n10                 1                                                           \n11                 0                                                           \n12                 0                                                           \n13                 0                                                           \n14                 0                                                           \n15                 0                                                           \n16                 1                                                           \n17                 1                                                           \n18                 0                                impuestos                  \n19                 0                                           independiente   \n\n     balcon  cochera           aire  \n0   terraza                          \n1                                    \n2   terraza                          \n3    salida                          \n4   terraza                          \n5   terraza                          \n6                                    \n7                                    \n8                                    \n9                                    \n10                                   \n11                                   \n12                                   \n13                                   \n14                                   \n15                                   \n16                                   \n17                                   \n18                                   \n19  terraza           acondicionado  \n\n[20 rows x 77 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>start_date</th>\n      <th>end_date</th>\n      <th>latitud</th>\n      <th>longitud</th>\n      <th>property_rooms</th>\n      <th>property_surface_total</th>\n      <th>place_l4_Agronomía</th>\n      <th>place_l4_Almagro</th>\n      <th>place_l4_Balvanera</th>\n      <th>place_l4_Barracas</th>\n      <th>...</th>\n      <th>property_type_Departamento</th>\n      <th>property_type_PH</th>\n      <th>cocina</th>\n      <th>pisos</th>\n      <th>calefaccion</th>\n      <th>expensas</th>\n      <th>lavadero</th>\n      <th>balcon</th>\n      <th>cochera</th>\n      <th>aire</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>737971</td>\n      <td>737991</td>\n      <td>-34.576973</td>\n      <td>-58.406591</td>\n      <td>7.0</td>\n      <td>415.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>comedor</td>\n      <td>terraza</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>737867</td>\n      <td>737868</td>\n      <td>-34.610046</td>\n      <td>-58.361382</td>\n      <td>4.0</td>\n      <td>194.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>737875</td>\n      <td>738097</td>\n      <td>-34.569770</td>\n      <td>-58.431032</td>\n      <td>4.0</td>\n      <td>260.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>radiante</td>\n      <td></td>\n      <td></td>\n      <td>terraza</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>738132</td>\n      <td>738182</td>\n      <td>-34.579756</td>\n      <td>-58.406144</td>\n      <td>3.0</td>\n      <td>120.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>lavadero</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>cocina</td>\n      <td>salida</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>737875</td>\n      <td>738097</td>\n      <td>-34.569770</td>\n      <td>-58.431032</td>\n      <td>4.0</td>\n      <td>165.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>radiante</td>\n      <td></td>\n      <td></td>\n      <td>terraza</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>737875</td>\n      <td>738097</td>\n      <td>-34.569770</td>\n      <td>-58.431032</td>\n      <td>4.0</td>\n      <td>165.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>radiante</td>\n      <td></td>\n      <td></td>\n      <td>terraza</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>738019</td>\n      <td>738182</td>\n      <td>-34.647545</td>\n      <td>-58.497062</td>\n      <td>5.0</td>\n      <td>132.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>lavadero</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>cocina</td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>737829</td>\n      <td>737871</td>\n      <td>-34.608300</td>\n      <td>-58.371200</td>\n      <td>5.0</td>\n      <td>300.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>737838</td>\n      <td>737847</td>\n      <td>-34.605406</td>\n      <td>-58.400957</td>\n      <td>1.0</td>\n      <td>325.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>737956</td>\n      <td>738048</td>\n      <td>-34.592467</td>\n      <td>-58.445158</td>\n      <td>1.0</td>\n      <td>122.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>737999</td>\n      <td>738001</td>\n      <td>-34.562379</td>\n      <td>-58.454491</td>\n      <td>3.0</td>\n      <td>50.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>737999</td>\n      <td>738001</td>\n      <td>-34.628692</td>\n      <td>-58.463322</td>\n      <td>3.0</td>\n      <td>50.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>737999</td>\n      <td>738001</td>\n      <td>-34.562379</td>\n      <td>-58.454491</td>\n      <td>3.0</td>\n      <td>50.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>737999</td>\n      <td>738001</td>\n      <td>-34.605478</td>\n      <td>-58.404722</td>\n      <td>3.0</td>\n      <td>50.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>737860</td>\n      <td>737946</td>\n      <td>-34.605862</td>\n      <td>-58.422360</td>\n      <td>3.0</td>\n      <td>50.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>737999</td>\n      <td>738002</td>\n      <td>-34.593817</td>\n      <td>-58.404138</td>\n      <td>3.0</td>\n      <td>50.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>737999</td>\n      <td>738001</td>\n      <td>-34.628692</td>\n      <td>-58.463322</td>\n      <td>3.0</td>\n      <td>50.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>737999</td>\n      <td>738001</td>\n      <td>-34.605478</td>\n      <td>-58.404722</td>\n      <td>3.0</td>\n      <td>50.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>737924</td>\n      <td>737924</td>\n      <td>-34.633013</td>\n      <td>-58.527117</td>\n      <td>2.0</td>\n      <td>240.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>impuestos</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>737910</td>\n      <td>737918</td>\n      <td>-34.562379</td>\n      <td>-58.454491</td>\n      <td>5.0</td>\n      <td>139.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>independiente</td>\n      <td>terraza</td>\n      <td></td>\n      <td>acondicionado</td>\n    </tr>\n  </tbody>\n</table>\n<p>20 rows × 77 columns</p>\n</div>"
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df_train_x.copy()\n",
        "df = pd.merge(df,aux_df, on=\"id\")\n",
        "df.drop(\"id\", inplace=True, axis=\"columns\")\n",
        "\n",
        "df_test = df_test_x.copy()\n",
        "df_test = pd.merge(df_test,aux_df_test, on=\"id\")\n",
        "df_test.drop(\"id\", inplace=True, axis=\"columns\")\n",
        "\n",
        "df.head(20)"
      ],
      "metadata": {
        "id": "I2x-X60t2DpP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 914
        },
        "outputId": "9aa74e5a-0b67-4010-a31b-a2f67689e136"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exportación de Datos"
      ],
      "metadata": {
        "id": "rN3FutIEHrf2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exportamos los datasets generados:"
      ],
      "metadata": {
        "id": "xd-CoUsZHtL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if IN_COLAB:\n",
        "  path = '/content/drive/MyDrive/📔 Organización de Datos (75.06)/TPS/TP2/DATASETS/1a_df_descrip.csv'\n",
        "else:\n",
        "  path = 'DATASETS/1a_df_descrip.csv'\n",
        "\n",
        "df_descrip.to_csv(path)"
      ],
      "metadata": {
        "id": "qr1jlB8QH16Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if IN_COLAB:\n",
        "  path = '/content/drive/MyDrive/📔 Organización de Datos (75.06)/TPS/TP2/DATASETS/1a_df_ampliado.csv'\n",
        "else:\n",
        "  path = 'DATASETS/1a_df_ampliado.csv'\n",
        "\n",
        "df.to_csv(path)"
      ],
      "metadata": {
        "id": "QTsLoqr-IHOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.b Modelos\n",
        "___"
      ],
      "metadata": {
        "collapsed": false,
        "id": "fI1Fi95S2DpP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sin optimización de hiperparámetros"
      ],
      "metadata": {
        "id": "ldOrNGnEaE5H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenemos un modelo de XGBoost con los mismos hiperparámetros utilizados en el TP1."
      ],
      "metadata": {
        "id": "a2X0YkeUUL1X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizamos One Hot Encoding para las nuevas variables cualitativas:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "WqUMr9_r2DpQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "   start_date  end_date    latitud   longitud  property_rooms  \\\n0      737971    737991 -34.576973 -58.406591             7.0   \n1      737867    737868 -34.610046 -58.361382             4.0   \n2      737875    738097 -34.569770 -58.431032             4.0   \n3      738132    738182 -34.579756 -58.406144             3.0   \n4      737875    738097 -34.569770 -58.431032             4.0   \n\n   property_surface_total  place_l4_Agronomía  place_l4_Almagro  \\\n0                   415.0                   0                 0   \n1                   194.0                   0                 0   \n2                   260.0                   0                 0   \n3                   120.0                   0                 0   \n4                   165.0                   0                 0   \n\n   place_l4_Balvanera  place_l4_Barracas  ...  balcon_corrido  balcon_frente  \\\n0                   0                  0  ...               0              0   \n1                   0                  0  ...               0              0   \n2                   0                  0  ...               0              0   \n3                   0                  0  ...               0              0   \n4                   0                  0  ...               0              0   \n\n   balcon_luminoso  balcon_salida  balcon_terraza  cochera_cubierta  \\\n0                0              0               1                 0   \n1                0              0               0                 0   \n2                0              0               1                 0   \n3                0              1               0                 0   \n4                0              0               1                 0   \n\n   cochera_fija  aire_acondicionado  aire_central  aire_split  \n0             0                   0             0           0  \n1             0                   0             0           0  \n2             0                   0             0           0  \n3             0                   0             0           0  \n4             0                   0             0           0  \n\n[5 rows x 95 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>start_date</th>\n      <th>end_date</th>\n      <th>latitud</th>\n      <th>longitud</th>\n      <th>property_rooms</th>\n      <th>property_surface_total</th>\n      <th>place_l4_Agronomía</th>\n      <th>place_l4_Almagro</th>\n      <th>place_l4_Balvanera</th>\n      <th>place_l4_Barracas</th>\n      <th>...</th>\n      <th>balcon_corrido</th>\n      <th>balcon_frente</th>\n      <th>balcon_luminoso</th>\n      <th>balcon_salida</th>\n      <th>balcon_terraza</th>\n      <th>cochera_cubierta</th>\n      <th>cochera_fija</th>\n      <th>aire_acondicionado</th>\n      <th>aire_central</th>\n      <th>aire_split</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>737971</td>\n      <td>737991</td>\n      <td>-34.576973</td>\n      <td>-58.406591</td>\n      <td>7.0</td>\n      <td>415.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>737867</td>\n      <td>737868</td>\n      <td>-34.610046</td>\n      <td>-58.361382</td>\n      <td>4.0</td>\n      <td>194.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>737875</td>\n      <td>738097</td>\n      <td>-34.569770</td>\n      <td>-58.431032</td>\n      <td>4.0</td>\n      <td>260.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>738132</td>\n      <td>738182</td>\n      <td>-34.579756</td>\n      <td>-58.406144</td>\n      <td>3.0</td>\n      <td>120.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>737875</td>\n      <td>738097</td>\n      <td>-34.569770</td>\n      <td>-58.431032</td>\n      <td>4.0</td>\n      <td>165.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 95 columns</p>\n</div>"
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_dummies = pd.get_dummies(df, columns=['cocina', 'pisos', 'lavadero', 'calefaccion', 'expensas', 'balcon', 'cochera', 'aire'], drop_first=True)\n",
        "df_test_dummies = pd.get_dummies(df_test, columns=['cocina', 'pisos', 'lavadero', 'calefaccion', 'expensas', 'balcon', 'cochera', 'aire'], drop_first=True)\n",
        "df_dummies.head(5)"
      ],
      "metadata": {
        "id": "5e0r2Yj-2DpQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "9345f93a-6a15-48ed-ebd9-8004cb87637f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "       start_date  end_date    latitud   longitud  property_rooms  \\\n0          737971    737991 -34.576973 -58.406591             7.0   \n1          737867    737868 -34.610046 -58.361382             4.0   \n2          737875    738097 -34.569770 -58.431032             4.0   \n3          738132    738182 -34.579756 -58.406144             3.0   \n4          737875    738097 -34.569770 -58.431032             4.0   \n...           ...       ...        ...        ...             ...   \n74246      737802    737946 -34.572157 -58.494807             3.0   \n74247      737797    737946 -34.583718 -58.484141             4.0   \n74248      737802    737946 -34.572512 -58.478717             5.0   \n74249      737802    737946 -34.572512 -58.478717             5.0   \n74250      737802    737946 -34.572512 -58.478717             5.0   \n\n       property_surface_total  place_l4_Agronomía  place_l4_Almagro  \\\n0                       415.0                   0                 0   \n1                       194.0                   0                 0   \n2                       260.0                   0                 0   \n3                       120.0                   0                 0   \n4                       165.0                   0                 0   \n...                       ...                 ...               ...   \n74246                     1.0                   0                 0   \n74247                     1.0                   0                 0   \n74248                     1.0                   0                 0   \n74249                     1.0                   0                 0   \n74250                     1.0                   0                 0   \n\n       place_l4_Balvanera  place_l4_Barracas  ...  balcon_corrido  \\\n0                       0                  0  ...               0   \n1                       0                  0  ...               0   \n2                       0                  0  ...               0   \n3                       0                  0  ...               0   \n4                       0                  0  ...               0   \n...                   ...                ...  ...             ...   \n74246                   0                  0  ...               0   \n74247                   0                  0  ...               0   \n74248                   0                  0  ...               0   \n74249                   0                  0  ...               0   \n74250                   0                  0  ...               0   \n\n       balcon_frente  balcon_luminoso  balcon_salida  balcon_terraza  \\\n0                  0                0              0               1   \n1                  0                0              0               0   \n2                  0                0              0               1   \n3                  0                0              1               0   \n4                  0                0              0               1   \n...              ...              ...            ...             ...   \n74246              1                0              0               0   \n74247              0                0              0               0   \n74248              0                0              0               0   \n74249              0                0              0               0   \n74250              0                0              0               0   \n\n       cochera_cubierta  cochera_fija  aire_acondicionado  aire_central  \\\n0                     0             0                   0             0   \n1                     0             0                   0             0   \n2                     0             0                   0             0   \n3                     0             0                   0             0   \n4                     0             0                   0             0   \n...                 ...           ...                 ...           ...   \n74246                 1             0                   0             0   \n74247                 0             0                   0             0   \n74248                 0             1                   0             0   \n74249                 0             1                   0             0   \n74250                 0             1                   0             0   \n\n       aire_split  \n0               0  \n1               0  \n2               0  \n3               0  \n4               0  \n...           ...  \n74246           0  \n74247           0  \n74248           0  \n74249           0  \n74250           0  \n\n[74251 rows x 95 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>start_date</th>\n      <th>end_date</th>\n      <th>latitud</th>\n      <th>longitud</th>\n      <th>property_rooms</th>\n      <th>property_surface_total</th>\n      <th>place_l4_Agronomía</th>\n      <th>place_l4_Almagro</th>\n      <th>place_l4_Balvanera</th>\n      <th>place_l4_Barracas</th>\n      <th>...</th>\n      <th>balcon_corrido</th>\n      <th>balcon_frente</th>\n      <th>balcon_luminoso</th>\n      <th>balcon_salida</th>\n      <th>balcon_terraza</th>\n      <th>cochera_cubierta</th>\n      <th>cochera_fija</th>\n      <th>aire_acondicionado</th>\n      <th>aire_central</th>\n      <th>aire_split</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>737971</td>\n      <td>737991</td>\n      <td>-34.576973</td>\n      <td>-58.406591</td>\n      <td>7.0</td>\n      <td>415.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>737867</td>\n      <td>737868</td>\n      <td>-34.610046</td>\n      <td>-58.361382</td>\n      <td>4.0</td>\n      <td>194.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>737875</td>\n      <td>738097</td>\n      <td>-34.569770</td>\n      <td>-58.431032</td>\n      <td>4.0</td>\n      <td>260.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>738132</td>\n      <td>738182</td>\n      <td>-34.579756</td>\n      <td>-58.406144</td>\n      <td>3.0</td>\n      <td>120.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>737875</td>\n      <td>738097</td>\n      <td>-34.569770</td>\n      <td>-58.431032</td>\n      <td>4.0</td>\n      <td>165.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>74246</th>\n      <td>737802</td>\n      <td>737946</td>\n      <td>-34.572157</td>\n      <td>-58.494807</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>74247</th>\n      <td>737797</td>\n      <td>737946</td>\n      <td>-34.583718</td>\n      <td>-58.484141</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>74248</th>\n      <td>737802</td>\n      <td>737946</td>\n      <td>-34.572512</td>\n      <td>-58.478717</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>74249</th>\n      <td>737802</td>\n      <td>737946</td>\n      <td>-34.572512</td>\n      <td>-58.478717</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>74250</th>\n      <td>737802</td>\n      <td>737946</td>\n      <td>-34.572512</td>\n      <td>-58.478717</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>74251 rows × 95 columns</p>\n</div>"
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_dummies"
      ],
      "metadata": {
        "id": "TkUoplwRNtwf",
        "outputId": "b7b42a93-699c-467b-ae58-2668f8e9eab2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamos el modelo:"
      ],
      "metadata": {
        "id": "I6cp1CI3ZKLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_dummies"
      ],
      "metadata": {
        "id": "kQ5AadFSfxhE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "044f7dba-5555-4d62-b84e-494ca9febd99"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "       start_date  end_date    latitud   longitud  property_rooms  \\\n0          738042    738059 -34.629398 -58.425852             2.0   \n1          738042    738052 -34.620748 -58.412004             3.0   \n2          738042    738059 -34.626595 -58.420019             4.0   \n3          738042    738182 -34.627566 -58.411937             4.0   \n4          738042    738043 -34.625298 -58.459998             3.0   \n...           ...       ...        ...        ...             ...   \n18600      737795    738416 -34.585935 -58.475726             2.0   \n18601      737795    737965 -34.571806 -58.479139             1.0   \n18602      737795    737798 -34.572312 -58.480049             3.0   \n18603      737795    738416 -34.629440 -58.442729             2.0   \n18604      737795    738098 -34.636285 -58.400321             3.0   \n\n       property_surface_total  place_l4_Agronomía  place_l4_Almagro  \\\n0                        62.0                   0                 0   \n1                        59.0                   0                 0   \n2                       111.0                   0                 0   \n3                       100.0                   0                 0   \n4                        57.0                   0                 0   \n...                       ...                 ...               ...   \n18600                    44.0                   0                 0   \n18601                    38.0                   0                 0   \n18602                    69.0                   0                 0   \n18603                    63.0                   0                 0   \n18604                    66.0                   0                 0   \n\n       place_l4_Balvanera  place_l4_Barracas  ...  balcon_corrido  \\\n0                       0                  0  ...               0   \n1                       0                  0  ...               0   \n2                       0                  0  ...               0   \n3                       0                  0  ...               0   \n4                       0                  0  ...               0   \n...                   ...                ...  ...             ...   \n18600                   0                  0  ...               0   \n18601                   0                  0  ...               0   \n18602                   0                  0  ...               0   \n18603                   0                  0  ...               0   \n18604                   0                  0  ...               0   \n\n       balcon_frente  balcon_luminoso  balcon_salida  balcon_terraza  \\\n0                  1                0              0               0   \n1                  0                0              1               0   \n2                  0                0              0               0   \n3                  0                0              0               0   \n4                  0                1              0               0   \n...              ...              ...            ...             ...   \n18600              1                0              0               0   \n18601              0                0              0               0   \n18602              1                0              0               0   \n18603              0                0              0               0   \n18604              0                0              0               0   \n\n       cochera_cubierta  cochera_fija  aire_acondicionado  aire_central  \\\n0                     0             0                   1             0   \n1                     0             1                   0             0   \n2                     0             0                   0             0   \n3                     0             0                   0             0   \n4                     0             0                   0             0   \n...                 ...           ...                 ...           ...   \n18600                 0             0                   0             0   \n18601                 0             0                   1             0   \n18602                 0             0                   1             0   \n18603                 0             0                   0             0   \n18604                 0             0                   1             0   \n\n       aire_split  \n0               0  \n1               0  \n2               0  \n3               0  \n4               0  \n...           ...  \n18600           0  \n18601           0  \n18602           0  \n18603           0  \n18604           0  \n\n[18605 rows x 95 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>start_date</th>\n      <th>end_date</th>\n      <th>latitud</th>\n      <th>longitud</th>\n      <th>property_rooms</th>\n      <th>property_surface_total</th>\n      <th>place_l4_Agronomía</th>\n      <th>place_l4_Almagro</th>\n      <th>place_l4_Balvanera</th>\n      <th>place_l4_Barracas</th>\n      <th>...</th>\n      <th>balcon_corrido</th>\n      <th>balcon_frente</th>\n      <th>balcon_luminoso</th>\n      <th>balcon_salida</th>\n      <th>balcon_terraza</th>\n      <th>cochera_cubierta</th>\n      <th>cochera_fija</th>\n      <th>aire_acondicionado</th>\n      <th>aire_central</th>\n      <th>aire_split</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>738042</td>\n      <td>738059</td>\n      <td>-34.629398</td>\n      <td>-58.425852</td>\n      <td>2.0</td>\n      <td>62.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>738042</td>\n      <td>738052</td>\n      <td>-34.620748</td>\n      <td>-58.412004</td>\n      <td>3.0</td>\n      <td>59.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>738042</td>\n      <td>738059</td>\n      <td>-34.626595</td>\n      <td>-58.420019</td>\n      <td>4.0</td>\n      <td>111.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>738042</td>\n      <td>738182</td>\n      <td>-34.627566</td>\n      <td>-58.411937</td>\n      <td>4.0</td>\n      <td>100.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>738042</td>\n      <td>738043</td>\n      <td>-34.625298</td>\n      <td>-58.459998</td>\n      <td>3.0</td>\n      <td>57.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>18600</th>\n      <td>737795</td>\n      <td>738416</td>\n      <td>-34.585935</td>\n      <td>-58.475726</td>\n      <td>2.0</td>\n      <td>44.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18601</th>\n      <td>737795</td>\n      <td>737965</td>\n      <td>-34.571806</td>\n      <td>-58.479139</td>\n      <td>1.0</td>\n      <td>38.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18602</th>\n      <td>737795</td>\n      <td>737798</td>\n      <td>-34.572312</td>\n      <td>-58.480049</td>\n      <td>3.0</td>\n      <td>69.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18603</th>\n      <td>737795</td>\n      <td>738416</td>\n      <td>-34.629440</td>\n      <td>-58.442729</td>\n      <td>2.0</td>\n      <td>63.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18604</th>\n      <td>737795</td>\n      <td>738098</td>\n      <td>-34.636285</td>\n      <td>-58.400321</td>\n      <td>3.0</td>\n      <td>66.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>18605 rows × 95 columns</p>\n</div>"
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=0.3, enable_categorical=False,\n             gamma=0.1, gpu_id=-1, importance_type=None,\n             interaction_constraints='', learning_rate=0.3, max_delta_step=0,\n             max_depth=6, min_child_weight=5, missing=nan,\n             monotone_constraints='()', n_estimators=100, n_jobs=4,\n             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n             validate_parameters=1, verbosity=None)",
            "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=0.3, enable_categorical=False,\n             gamma=0.1, gpu_id=-1, importance_type=None,\n             interaction_constraints=&#x27;&#x27;, learning_rate=0.3, max_delta_step=0,\n             max_depth=6, min_child_weight=5, missing=nan,\n             monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=4,\n             num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0,\n             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=&#x27;exact&#x27;,\n             validate_parameters=1, verbosity=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=0.3, enable_categorical=False,\n             gamma=0.1, gpu_id=-1, importance_type=None,\n             interaction_constraints=&#x27;&#x27;, learning_rate=0.3, max_delta_step=0,\n             max_depth=6, min_child_weight=5, missing=nan,\n             monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=4,\n             num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0,\n             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=&#x27;exact&#x27;,\n             validate_parameters=1, verbosity=None)</pre></div></div></div></div></div>"
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "XGB_Regressor = XGBRegressor(min_child_weight = 5, max_depth = 6, learning_rate = 0.3, gamma = 0.1, colsample_bytree = 0.3)\n",
        "XGB_Regressor.fit(df_dummies, df_train_y_regresion)"
      ],
      "metadata": {
        "id": "wHNC3OGoNtwg",
        "outputId": "6b9a9ea4-7ca9-4bc5-9dff-4f7a3bc0bb8b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hagamos las predicciones y veamos cómo resultaron las métricas del modelo:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "EYC5dWmONtwg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Se obtuvo un Score de 58.018%\n",
            "El error según la métrica 'Mean Square Error' de test es: 53023059874.91771\n",
            "El error según la métrica 'Root Mean Square Error' de test es: 230267.3660658794\n"
          ]
        }
      ],
      "source": [
        "prediccion_y_metricas_regresion(XGB_Regressor,df_test_dummies, df_test_y_regresion)"
      ],
      "metadata": {
        "id": "zB9xby40Ntwg",
        "outputId": "33c60bd8-e043-4fea-eab9-e9938fe359f9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Importancia de Features"
      ],
      "metadata": {
        "id": "g6pT4X0QPDgc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estudiemos cuáles son los atributos más importantes para los aspectos elegidos:"
      ],
      "metadata": {
        "id": "d9qHlaL8PL3g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Apecto cocina"
      ],
      "metadata": {
        "id": "JxUdt56_CmMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aspecto_id = list()\n",
        "\n",
        "for aspecto in list(filter(lambda x: x.startswith('cocina_'), df_dummies.columns.tolist())):\n",
        "  aspecto_id.append(df_dummies.columns.get_loc(aspecto))"
      ],
      "metadata": {
        "id": "hFJOpgj-CvbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(df_test_dummies.columns[aspecto_id], XGB_Regressor.feature_importances_[aspecto_id])\n",
        "plt.xlabel(\"Importancia de Atributos\")\n",
        "plt.ylabel(\"Aspecto cocina\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "w39dV0_l-Ckp",
        "outputId": "182c1da8-ac1d-417a-cbf1-6f501575c80d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Aspecto cocina')"
            ]
          },
          "metadata": {},
          "execution_count": 141
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAccAAAEGCAYAAAAQSF6jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAdmklEQVR4nO3debQmVXnv8e+vGwRRBoGOogZbCEhAEbDBiGiAeLlGME6MwQE1IRKj6M2ESy9xuEaU64QDXnAxiKgIilGMI5MoatNIQzcsCIioIGpQQcBIpHnuH7WPvF2c0+dt6Pe85zTfz1q1TtV+d+39VPXpfnrvqrcqVYUkSbrXvHEHIEnSbGNylCSpx+QoSVKPyVGSpB6ToyRJPeuMOwCtGZtvvnktXLhw3GFI0pxy6aWX3lJVC/rlJse1xMKFC1myZMm4w5CkOSXJDycrd1pVkqQek6MkST0mR0mSekyOkiT1mBwlSeoxOUqS1GNylCSpx+QoSVKPDwFYSyy76TYWHvXFcYchSWvMDcfsO7a+HTlKktRjcpQkqcfkKElSj8lRkqQek6MkST0mR0mSekyOkiT1mBwlSeoxOUqS1GNylCSpx+QoSVKPyVGSpB6ToyRJPSZHSZJ6TI6SJPWYHCVJ6jE5SpLUY3KUJKnH5ChJUo/JUZKkHpOjJEk9JkdJknpMjpIk9ZgcJUnqMTlKktQz55JjkovXcHunJNl/TbbZa39hkuWjal+StObNueRYVbuPO4ZRSrLOuGOQpAe7GU+OSV6a5Ioklyc5rY2szmtl5ybZstV7ZJKzW73Lk+zeyu9oP/dMckGSs5JcneT0JGmfHZ3kkiTLk5wwUT5EbPfZL8l2SRYP1FmYZNmq+knylIm4gVcP7Ds/ybFtnyuS/M3AsVyU5PPAVUnWT3JykmVJLkuy1xTxHp5kSZIlK35z2+r/YUiSJjWjyTHJDsCbgL2r6snAkcAHgFOrakfgdOC4Vv044MJWbxfgykma3Bl4HbA9sBXw9Fb+warataqeCDwU2G/IEO+zX1VdDTwkyeNbnYOAM6bp52TgNS32Qa8EbquqXYFdgb8eaHcX4Miq2pYuoVZVPQk4BDg1yfr9YKvqhKpaVFWL5m+w8ZCHKEmazkyPHPcGzqyqWwCq6pfA04BPtM9PA/YYqHt8q7eiqiYbGi2uqhur6h5gKbCwle+V5LtthLc3sMOQ8U2136fpkiKsnBzvUz/JJsAmVfWNgWOasA/w0iRLge8CmwHbDBzLD9r6HsDH27FfDfwQ2HbIY5AkPUBz/frWXQPrK4B12gjrw8CiqvpxkjcD9xl19U2z3xnAmUk+Szeiu/Z+9hO6EeVXen3vCdw5XYySpJkx0yPH84ADkmwGkGRT4GLg4Pb5ocBFbf1c4IhWb36SYecNJxLULUkeDgx7J+qU+1XV9+mS7//m3lHjpPWr6lbg1iQTI+BDB/r4CnBEknXbcW2b5GGTxHLRxH5JtgW2BK4Z8jgkSQ/QjI4cq+rKJG8HLkyyArgMeA1wcpJ/BP4TeHmrfiRwQpJX0iWmI4BvD9HHrUlOBJYDPwUuGTK26fY7AzgWePwQ9V8OnJSkgK8OlH+Ubur3e+3mnf8Enj9JOB8Gjm/TtXcDh1XVXZPUkySNQKpq3DFoDVhvi21qi5e9b9xhSNIac8Mx+468jySXVtWifvmc+56jJEmjNtdvyBlakg9x71c9Jry/qk4eRzySpNnrQZMcq+rV09eSJMlpVUmS7sPkKElSj8lRkqQek6MkST0mR0mSekyOkiT1mBwlSeoxOUqS1GNylCSpx+QoSVKPyVGSpB6ToyRJPSZHSZJ6TI6SJPWYHCVJ6jE5SpLUY3KUJKnH5ChJUo/JUZKknnXGHYDWjCc9ZmOWHLPvuMOQpLWCI0dJknpMjpIk9ZgcJUnqMTlKktRjcpQkqcfkKElSz1Bf5UiyL7ADsP5EWVW9dVRBSZI0TtOOHJN8BDgIeA0Q4ADgcSOOS5KksRlmWnX3qnop8KuqegvwNGDb0YYlSdL4DJMc/6v9/E2SRwO/A7YYXUiSJI3XMNccz0myCXAs8D2ggI+ONCpJksZo2uRYVW9rq59Jcg6wflXdNtqwJEkan2HvVt0dWDhRPwlV9bERxiVJ0thMmxyTnAZsDSwFVrTiAkyOs8iym25j4VFfHHcYkjSjbhjR24iGGTkuAravqhpJBJIkzTLD3K26HHjUqAORJGm2GGbkuDlwVZLFwF0ThVX1FyOLSpKkMRomOb551EFIkjSbDPNVjgtnIhBJkmaLKZNjkm9W1R5Jbqe7O/X3HwFVVRuNPDpJksZgyuRYVXu0nxvOXDiSJI3fMG/l+JMkGw5sb5jkqaMNS5Kk8RnmqxzHA3cMbN/ZyiRJWisNkxwz+ACAqrqHIR87J0nSXDRMcrw+yWuTrNuWI4HrRx2YJEnjMkxyfBWwO3BTW54KHD7KoCRJGqdhvuf4c+DgGYhFkqRZYZi7VR+b5OwkP2/LZ5I8diaCkyRpHIaZVj0Z+Dzw6LZ8oZVJkrRWGiY5Lqiqk6vq7racAiwYcVySJI3NMMnxF0lenGR+W14M/GLUgUmSNC7DJMdXAAcCPwVuBvYHXj7KoCRJGqdh7lb9IeC7GyVJDxrD3K16apJNBrYfkeSk0YYlSdL4DDOtumNV3TqxUVW/AnYeXUiSJI3XMMlxXpJHTGwk2RSfrSpJWosNk+TeDXw7yZlt+wDg7aMLSZKk8RrmhpyPJVkC7N2KXlhVV402LEmSxmeo6dGWDE2IkqQHhWGuOY5NkovXcHtvTfKsaersmWT3NdnvMFq/58x0v5Kk+5rVN9ZU1RpNUlV19BDV9gTuAB5wYk4SupdF3/NA25IkzZyhRo5JHplkv7b8wbCNJ3lpkiuSXJ7ktCQLk5zXys5NsuVA+2e3epdPjNyS3NF+7pnkgiRnJbk6yekt8ZDk6CSXJFme5ISJ8iniOSXJ/m39hiRvSfK9JMuSbJdkId37K1+fZGmSZyRZ0N5Ecklbnt72X5Dka0muTPLRJD9Msnk7xmuSfAxYDvxhkuOTLGl13zIQz7Pb8XwPeOFA+W5Jvp3ksiQXJ3nCFMdzeGt3yYrf3DbsH4skaRrDPATgQGAx3V2qBwLfnUgw0+y3A/AmYO+qejJwJPAB4NSq2hE4HTiuVT8OuLDV2wW4cpImdwZeB2wPbAU8vZV/sKp2raonAg8F9psutgG3VNUuwPHAP1TVDcBHgPdW1U5VdRHw/ra9K/Ai4KNt338BzquqHYCzgC0H2t0G+HBV7dCeMPTGqloE7Aj8aZIdk6wPnAg8F3gK8KiB/a8GnlFVOwNHA/86WfBVdUJVLaqqRfM32Hg1DluStCrDTKu+Edi1vfSYJAuAr9MlhFXZGzizqm4BqKpfJnka946QTgPeNVD3pa3eCmCyYdDiqrqxxbAUWAh8E9gryT8BGwCb0iXWLwxxXACfbT8vHYir71nA9gMD0o2SPBzYA3hBi/nLSX41sM8Pq+o7A9sHJjmc7nxvQZfg5wE/qKpr2zF9HDi81d8YODXJNkAB6w55PJKkNWCY5DhvIjE2v2A8N/LcNbC+Alinjb4+DCyqqh8neTOw/v1ocwVTn4t5wJ9U1W8HC1cxewtw50C9xwP/QPcfjF8lOWWIGN8GnF9VL2hTvRdMU1+StAYNk+S+nOQrSQ5LchjwReBLQ+x3HnBAks3g90/WuRg4uH1+KHBRWz8XOKLVm59k2DnCiSRzSxvNTTvdO4TbgQ0Htr8KvGZiI8lObfVbdNPMJNkHeAST24guWd6W5JHAn7fyq4GFSbZu24cM7LMxcFNbP+x+HYUk6X6bNjlW1T8C/4/uetmOwAlV9U9D7Hcl3ZN0LkxyOfAeuiTz8iRXAC+huw5J+7lXkmV0U5zbDxN8e+briXQ3vnwFuGSY/abxBeAFEzfkAK8FFrWbiK6iu2EH4C3APkmW012P/SldYu3HeDlwGV0y/ARdUqWNRA8HvthuyBkcnb8LeEeSy5jldxRL0tooVbXqCsk7q+qfpyt7sEmyHrCiqu5u11KPr6qdpttvVNbbYpva4mXvG1f3kjQWNxyz7wPaP8ml7YbJlQwzrfo/Jin780nKHmy2BC5po+LjgL8eczySpDVkyim7JEcAfwts3aZBJ2zIGviC/Cgl+RD3ftVjwvur6uQ11Ue7y9RXd0nSWmhV17M+QXfjzTuAowbKb6+qX440qgeoql497hgkSXPXlNOqVXVb+1L8+4FfVtUP2xfa707y1JkKUJKkmTbMNcfj6Z41OuGOViZJ0lppmOSYGriltT1E268XSJLWWsMkx+uTvDbJum05Erh+1IFJkjQuwyTHVwG70z2x5Ubgqdz7DFBJktY6006PtueqHjxdPUmS1hbDvLJq2/buxeVte8ckbxp9aJIkjccw06onAm8AfgdQVVfgSFKStBYbJjluUFWLe2V3jyIYSZJmg2GS4y3ttUoFkGR/4OaRRiVJ0hgN833FVwMnANsluQn4Ad27GCVJWisNc7fq9cCzkjwMmFdV93lnoSRJa5Nh7lbdLMlxwEXABUnen2Sz0YcmSdJ4DHPN8VPAfwIvAvZv62eMMihJksZpmGuOW1TV2wa2/0+Sg0YVkCRJ4zbMyPGrSQ5OMq8tBwJfGXVgkiSNyzDJ8a/pXnx8F/DfdNOsf5Pk9iS/HmVwkiSNwzB3q244E4FIkjRbTJsckzwdWFpVdyZ5MbAL8L6q+tHIo9PQnvSYjVlyzL7jDkOS1grDTKseD/wmyZOBvwe+D5w20qgkSRqjYZLj3VVVwPOAD1bVhwCnWiVJa61hvspxe5I3AC8GnplkHrDuaMOSJGl8hhk5HkR3p+orq+qnwGOBY0calSRJYzRtcqyqn1bVe6rqolb0OOCpow1LkqTxGWZalSQ7A38JHED3Vo7PjDIoSZLGacrkmGRb4JC23EL3PNVU1V4zFJskSWOxqpHj1XRv4tivqq4DSPL6GYlKkqQxWtU1xxcCNwPnJzkxyZ8BmZmwJEkanymTY1V9rqoOBrYDzgdeB/xBkuOT7DNTAUqSNNOGuVv1zqr6RFU9l+5rHJcB/zzyyCRJGpNhvuf4e1X1q6o6oar+bFQBSZI0bquVHCVJejAY6nuOmv2W3XQbC4/64rjDGKkbfOuIpBniyFGSpB6ToyRJPSZHSZJ6TI6SJPWYHCVJ6jE5SpLUY3KUJKnH5ChJUo/JUZKkHpOjJEk9JkdJknpMjpIk9ZgcJUnqMTlKktRjcpQkqcfkKElSj8lRkqQek6MkST0mR0mSekyOkiT1mBwlSeoxOUqS1GNylCSpx+QoSVKPyVGSpJ45kRyTXDzuGO6vJHsmOWeaOjslec5MxSRJWrU5kRyravdxxzBiOwEmR0maJWYkOSZ5aZIrklye5LQkC5Oc18rOTbJlq/fIJGe3epcn2b2V39F+7pnkgiRnJbk6yelJ0j47OsklSZYnOWGifIp4/ijJ11sf30uydTrHtv2XJTlooM8Lk/xbkuuTHJPk0CSLW72tW71TknwkyZIk/5Fkv0n6fViSk9q+lyV5XpKHAG8FDkqyNMlBSXZL8u1W5+IkT1jTfyaSpKmtM+oOkuwAvAnYvapuSbIpcCpwalWdmuQVwHHA89vPC6vqBUnmAw+fpMmdgR2AnwDfAp4OfBP4YFW9tfV5GrAf8IUpwjodOKaqzk6yPt1/El5IN4J7MrA5cEmSb7T6Twb+GPglcD3w0araLcmRwGuA17V6C4HdgK2B85P8Ua/fNwLnVdUrkmwCLAa+DhwNLKqqv2vxbwQ8o6ruTvIs4F+BF01ybg8HDgeYv9GCKQ5VkrS6ZmLkuDdwZlXdAlBVvwSeBnyifX4asMdA3eNbvRVVddsk7S2uqhur6h5gKV1CAtgryXeTLGvt7DBZMEk2BB5TVWe3fn5bVb9pMXyy9fsz4EJg17bbJVV1c1XdBXwf+GorXzbQP8Cnq+qeqrqWLolu1+t+H+CoJEuBC4D1gS0nCXNj4Mwky4H3TnUsVXVCVS2qqkXzN9h4siqSpPth5CPHEbhrYH0FsE4b/X2YbvT14yRvpks8o+jznoHte1j5HFZvv/52gBdV1TUrFSZP7dV7G3B+G0EvpEukkqQZMhMjx/OAA5JsBtCmVS8GDm6fHwpc1NbPBY5o9eYnGXY4NJEIb0nycGD/qSpW1e3AjUme3/pZL8kGLYaDWr8LgGfSTXuujgOSzGvXIbcCrul9/hXgNQPXSXdu5bcDGw7U2xi4qa0ftpoxSJIeoJEnx6q6Eng7cGGSy4H30F2ne3mSK4CXAEe26kfSTY8uAy4Fth+yj1uBE4HldAnokml2eQnw2tb/xcCjgLOBK4DL6RL6P1XVT4c9zuZHdAn1S8Crquq3vc/fBqwLXJHkyrYNcD6w/cQNOcC7gHckuYy5ObqXpDktVf2ZP90fSU4Bzqmqs8bR/3pbbFNbvOx94+h6xtxwzL7jDkHSWibJpVW1qF8+J77nKEnSTFqrp+ySfIjuqx6D3l9VJ6/pvqrqsDXdpiRpPNbq5FhVrx53DJKkucdpVUmSekyOkiT1mBwlSeoxOUqS1GNylCSpx+QoSVKPyVGSpB6ToyRJPSZHSZJ6TI6SJPWYHCVJ6jE5SpLUY3KUJKnH5ChJUo/JUZKkHpOjJEk9JkdJknpMjpIk9ZgcJUnqWWfcAWjNeNJjNmbJMfuOOwxJWis4cpQkqcfkKElSj8lRkqQek6MkST0mR0mSekyOkiT1mBwlSeoxOUqS1GNylCSpJ1U17hi0BiS5Hbhm3HGsps2BW8YdxGqYa/GCMc+EuRYvGPOgx1XVgn6hj49be1xTVYvGHcTqSLJkLsU81+IFY54Jcy1eMOZhOK0qSVKPyVGSpB6T49rjhHEHcD/MtZjnWrxgzDNhrsULxjwtb8iRJKnHkaMkST0mR0mSekyOY5Tk2UmuSXJdkqMm+Xy9JGe0z7+bZOHAZ29o5dck+Z/TtZnk8a2N61qbD5muj1kQ8+mtfHmSk5Ks28r3THJbkqVtOXoWxXxKkh8MxLZTK0+S41r9K5LsMkvivWgg1p8k+dwsOscnJfl5kuW9tjZN8rUk17afj1jdczyGmI9NcnWL6+wkm7TyhUn+a+A8f2SWxPvmJDcNxPWc6dqaBTGfMRDvDUmWtvKhz/FKqsplDAswH/g+sBXwEOByYPtenb8FPtLWDwbOaOvbt/rrAY9v7cxfVZvAp4GD2/pHgCNW1ccsifk5QNryyYGY9wTOmaXn+RRg/0nieA7wpXYsfwJ8dzbE22v3M8BLZ8M5bp89E9gFWN5r613AUW39KOCdq3OOxxTzPsA6bf2dAzEv7NedJfG+GfiHSeKYsq1xx9xr993A0atzjvuLI8fx2Q24rqqur6r/Bj4FPK9X53nAqW39LODPkqSVf6qq7qqqHwDXtfYmbbPts3drg9bm86fpY6wxA1TVv1cDLAYeO0VcqzKjMa/C84CPtcP5DrBJki1mS7xJNqL7HfncNMcxmVHETFV9A/jlJP0NttX/XR7mHM94zFX11aq6u21+h9X/XZ7pczyVKduaLTG3/Q+k+w/1/WZyHJ/HAD8e2L6xlU1ap/3Fug3YbBX7TlW+GXDrwF/Owb6m6mPcMf9euunUlwBfHih+WpLLk3wpyQ5TxDuumN/eps/em2S91YhjXPFCl2DOrapfD5SN8xyvyiOr6ua2/lPgkasRx7hiHvQKuhHuhMcnuSzJhUmeMYvi/bv2e3xS2tT1arY1rnP8DOBnVXXtQNkw53glJkfNBR8GvlFVF7Xt79E9D/HJwAe4f6OdUXkDsB2wK7Ap8M/jDWdoh7Dy/7Rn8zn+vTarMGe+j5bkjcDdwOmt6GZgy6raGfhfwCfaKH7cjge2Bnaii/Hd4w1ntfR/l+/XOTY5js9NwB8ObD+2lU1aJ8k6wMbAL1ax71Tlv6CbYlqnV76qPsYdM62NfwEW0P1SA1BVv66qO9r6vwPrJtl8NsRcVTe3ab27gJO5d8ppmDhmPN7WxuYtzi9OlM2Cc7wqP5uYLm0/f74acYwrZpIcBuwHHNqSOm3a8Bdt/VK6a2vbjjveqvpZVa2oqnuAE1n93+MZj3mgjRcCZwwcy7DneGWre5HSZc0sdA99v57uYvPExeodenVezcoXqz/d1ndg5YvV19Nd/J6yTeBMVr4h529X1ccsifmvgIuBh/b6eBT3PsBiN+BHE9uzIOYt2s8A7wOOadv7svLNIotnQ7xtv1cBp86mczyw30Lue7PIsax8Q867VuccjynmZwNXAQt65Qu490aTregSwKazIN4tBtZfT3f9b9q2xhnzwHm+8P6c4/u0NV0Fl9EtdHfX/Qfd/2Te2MreCvxFW1+fLqldR3dDylYD+76x7XcN8OeranPgl2Jxa+tMYL3p+pgFMd/dypa2ZeLus78Drmx/eb4D7D6LYj4PWAYsBz4OPLyVB/hQq78MWDQb4m2fXQA8u1c2G87xJ+mmxH5Hd83pla18M+Bc4Frg67R/6FbnHI8h5uvorqFN/C5PJIQXtfO8lG4q+7mzJN7T2jm8Avg8KyfLSdsad8zts1OAV/ViGPocDy4+Pk6SpB6vOUqS1GNylCSpx+QoSVKPyVGSpB6ToyRJPSZHaQYluWOG+1uY5C9H0O6iJMc9gP1PSbL//dhvaZJP9cpel2SDVezz0STbt/XVOv9Jdhp8I4UePEyO0lqqPS1kIbDGk2NVLamq167pdlclyR/TPdTgGUkeNvDR64BJk2OS+VX1V1V11f3sdie67+rpQcbkKI1BuvclXpjk35Jcn+SYJIcmWZxkWZKtW71TknwkyZIk/5Fkv1a+fpKTW93LkuzVyg9L8vkk59F9Uf4YumSyNMnr20jyoiTfa8vuA/FckOSsdO8dPH3i7SxJdk1ycXsI+eIkG7b657TPd0vy7RbHxUmeMMnxJskH072b7+vAHwx89pR2Li5N8pVM/SaNQ+i+nP5V2tsdkrwWeDRwfpLzW9kdSd6d5HK6h6dfkGTRQH/vTXJlknOTLGhlv6+TZPN07wN8CN0X1g9q5++gdO+S/Fy6B3J/J8mObZ8/zb3vC7wsyYar/Uuh2WWYJwW4uLismQW4o/3cE7gV2ILuEVk3AW9pnx0JvK+tn0L3NpJ5wDZ0TwRZH/h74KRWZzu6x7utDxzW6mw60M85A/1vAKzf1rcBlgzUu43uGZbzgG8De9A99ut6YNdWbyO6x4L9vt2Jsrb+LOAzkxz3C4Gv0Y38Ht2OfX9gXbpHBC5o9Q6aOK5J2rgG2JLu3YhfGCi/Adh8YLuAAwe2L6A9Lad9dmhbPxr44CR1NgduaOuHTdRp2x8A/qWt7w0sbetfAJ7e1h8+cT5c5u4y8SBqSTPvkmqvXkryfboREXSP7dproN6nq3sA9LVJrqdLhnvQ/UNNVV2d5Ifc+zDlr1XVVO+7Wxf4YJKdgBWs/ADmxVV1Y4tnKd2U7G3AzVV1Sevr1+3zwTY3Bk5Nsg1d8ll3kn6fCXyyqlYAP2kjW4AnAE8EvtbanE/3aLCVtFHdLVX1oyQ3AScl2XSK41xB9+LmydzDvQ+l/jjw2SnqTWUPuseRUVXnJdks3RsevgW8J8npwGcnzqPmLqdVpfG5a2D9noHte2Cl/7j2n/E43TMf71zFZ68HfgY8GVhENzKcLJ4VvRhW5W3A+VX1ROC5dCPYYQW4sqp2asuTqmqfSeodAmyX5Aa6521uREtSk/htS8LDmDiXd3Pvv4erE3/XSNUxdA/KfyjwrSTbrW4bml1MjtLsd0CSee065FZ004sXAYcCJNmWbrrxmkn2vR0YvP61Md1I8B66F0jPn6bva4Atkuza+tow9776bLDNidcJHTZFO9+gu3Y3v11TnBgZXwMsSPK01v666b1YOck8uje7P6mqFlbVQrprjodMcYyrMo9uOhe6G5W+2dZvAJ7S1gfvou23PXje96Qbzf46ydZVtayq3glcQje61xxmcpRmvx/RvbHgS3RvHPgt3Qug5yVZRjdNeFh175DsuwJY0W6meX3b72XtZpXtWPUok6r6b7rrgB9o+3yN+46s3gW8I8llTD3aPJvuLRpXAR+ju6Y50f7+wDtb+0uB3Xv7PgO4qap+MlD2DWD7lmhPAL48cUPONO4EdkuynO6a4Vtb+f8FjmjHMPjeyvNbP0uTHAS8GXhKkivobnZ6Wav3uiTLW/nv6P6sNIf5Vg5pFktyCt2NL2eNOxbpwcSRoyRJPY4cJUnqceQoSVKPyVGSpB6ToyRJPSZHSZJ6TI6SJPX8fxEyMjTBdb3mAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos que, para el aspecto `cocina` el atributo más importante es: *integrada*."
      ],
      "metadata": {
        "id": "PuNCYrZDFk9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Apecto pisos"
      ],
      "metadata": {
        "id": "0gp2RXuNF1Y0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aspecto_id = list()\n",
        "\n",
        "for aspecto in list(filter(lambda x: x.startswith('pisos_'), df_dummies.columns.tolist())):\n",
        "  aspecto_id.append(df_dummies.columns.get_loc(aspecto))"
      ],
      "metadata": {
        "id": "a60CG-0uF1Y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(df_test_dummies.columns[aspecto_id], XGB_Regressor.feature_importances_[aspecto_id])\n",
        "plt.xlabel(\"Importancia de Atributos\")\n",
        "plt.ylabel(\"Aspecto pisos\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "3c3062b4-f2b8-4d02-b6b7-1950aa6fe706",
        "id": "_FM-HjZ_F1Y1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Aspecto pisos')"
            ]
          },
          "metadata": {},
          "execution_count": 143
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos que, para el aspecto `pisos` el atributo más importante es: *madera*."
      ],
      "metadata": {
        "id": "L57GIYX3F1Y1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Apecto calefaccion"
      ],
      "metadata": {
        "id": "BrjRtFeDF1f_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aspecto_id = list()\n",
        "\n",
        "for aspecto in list(filter(lambda x: x.startswith('calefaccion_'), df_dummies.columns.tolist())):\n",
        "  aspecto_id.append(df_dummies.columns.get_loc(aspecto))"
      ],
      "metadata": {
        "id": "Y8KTh8TbF1f_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(df_test_dummies.columns[aspecto_id], XGB_Regressor.feature_importances_[aspecto_id])\n",
        "plt.xlabel(\"Importancia de Atributos\")\n",
        "plt.ylabel(\"Aspecto calefaccion\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "675bb0df-8e1e-466a-b41d-617af438d344",
        "id": "viDay3L0F1f_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Aspecto calefaccion')"
            ]
          },
          "metadata": {},
          "execution_count": 145
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos que, para el aspecto `calefaccion` el atributo más importante es: *radiante*."
      ],
      "metadata": {
        "id": "R_qiJLXlF1f_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Apecto expensas"
      ],
      "metadata": {
        "id": "au9YA6i5F1nQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aspecto_id = list()\n",
        "\n",
        "for aspecto in list(filter(lambda x: x.startswith('expensas_'), df_dummies.columns.tolist())):\n",
        "  aspecto_id.append(df_dummies.columns.get_loc(aspecto))"
      ],
      "metadata": {
        "id": "fhmbuqxXF1nQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(df_test_dummies.columns[aspecto_id], XGB_Regressor.feature_importances_[aspecto_id])\n",
        "plt.xlabel(\"Importancia de Atributos\")\n",
        "plt.ylabel(\"Aspecto expensas\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "e6807ea0-d5a3-4eb3-f545-a4c87dad71f0",
        "id": "pQQ45SIGF1nQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Aspecto expensas')"
            ]
          },
          "metadata": {},
          "execution_count": 147
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos que, para el aspecto `expensas` el atributo más importante es: *impuestos*."
      ],
      "metadata": {
        "id": "ros9MjIbF1nQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Apecto lavadero"
      ],
      "metadata": {
        "id": "Ffp8z3zFF1v9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aspecto_id = list()\n",
        "\n",
        "for aspecto in list(filter(lambda x: x.startswith('lavadero_'), df_dummies.columns.tolist())):\n",
        "  aspecto_id.append(df_dummies.columns.get_loc(aspecto))"
      ],
      "metadata": {
        "id": "94D5gjIlF1v-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(df_test_dummies.columns[aspecto_id], XGB_Regressor.feature_importances_[aspecto_id])\n",
        "plt.xlabel(\"Importancia de Atributos\")\n",
        "plt.ylabel(\"Aspecto lavadero\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "9782146c-88e7-40c8-baf0-76353ded8201",
        "id": "qXPXi_G-F1v-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Aspecto lavadero')"
            ]
          },
          "metadata": {},
          "execution_count": 149
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos que, para el aspecto `lavadero` el atributo más importante es: *cocina*."
      ],
      "metadata": {
        "id": "zL_Pku0UF1v-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Apecto balcon"
      ],
      "metadata": {
        "id": "l7d1vOTrF14k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aspecto_id = list()\n",
        "\n",
        "for aspecto in list(filter(lambda x: x.startswith('balcon_'), df_dummies.columns.tolist())):\n",
        "  aspecto_id.append(df_dummies.columns.get_loc(aspecto))"
      ],
      "metadata": {
        "id": "ClYZPx6HF14k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(df_test_dummies.columns[aspecto_id], XGB_Regressor.feature_importances_[aspecto_id])\n",
        "plt.xlabel(\"Importancia de Atributos\")\n",
        "plt.ylabel(\"Aspecto balcon\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "b13c7706-5b77-426d-f245-02c2eba0684d",
        "id": "FR-4iEUQF14l"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Aspecto balcon')"
            ]
          },
          "metadata": {},
          "execution_count": 151
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos que, para el aspecto `balcon` el atributo más importante es: *terraza*."
      ],
      "metadata": {
        "id": "2vfjBfJCF14l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Apecto cochera"
      ],
      "metadata": {
        "id": "87MN8BlTF2AL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aspecto_id = list()\n",
        "\n",
        "for aspecto in list(filter(lambda x: x.startswith('cochera_'), df_dummies.columns.tolist())):\n",
        "  aspecto_id.append(df_dummies.columns.get_loc(aspecto))"
      ],
      "metadata": {
        "id": "8BULr6T8F2AM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(df_test_dummies.columns[aspecto_id], XGB_Regressor.feature_importances_[aspecto_id])\n",
        "plt.xlabel(\"Importancia de Atributos\")\n",
        "plt.ylabel(\"Aspecto cochera\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "93464196-a962-4776-86f2-92782c6fdde2",
        "id": "SxJzCW3yF2AM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Aspecto cochera')"
            ]
          },
          "metadata": {},
          "execution_count": 153
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos que, para el aspecto `cochera` el atributo más importante es: *fija*."
      ],
      "metadata": {
        "id": "Bies0n61F2AM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Apecto aire"
      ],
      "metadata": {
        "id": "UIepC0DvF2Hl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aspecto_id = list()\n",
        "\n",
        "for aspecto in list(filter(lambda x: x.startswith('aire_'), df_dummies.columns.tolist())):\n",
        "  aspecto_id.append(df_dummies.columns.get_loc(aspecto))"
      ],
      "metadata": {
        "id": "j60DBX4RF2Hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(df_test_dummies.columns[aspecto_id], XGB_Regressor.feature_importances_[aspecto_id])\n",
        "plt.xlabel(\"Importancia de Atributos\")\n",
        "plt.ylabel(\"Aspecto aire\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "70d85d03-fffc-469c-b73b-02c501bb184f",
        "id": "QATA7-k9F2Hl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Aspecto aire')"
            ]
          },
          "metadata": {},
          "execution_count": 155
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos que, para el aspecto `aire` el atributo más importante es: *split*."
      ],
      "metadata": {
        "id": "7_dKSoWuF2Hm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Con optimización de hiperparámetros"
      ],
      "metadata": {
        "id": "CkJCoGXnaN1y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos cómo se comporta el score con la optimización de hiperparámetros:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "Su2wKojB2DpR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n                   estimator=XGBRegressor(base_score=None, booster=None,\n                                          colsample_bylevel=None,\n                                          colsample_bynode=None,\n                                          colsample_bytree=None,\n                                          enable_categorical=False, gamma=None,\n                                          gpu_id=None, importance_type=None,\n                                          interaction_constraints=None,\n                                          learning_rate=None,\n                                          max_delta_step=None, max_depth=No...\n                                          predictor=None, random_state=None,\n                                          reg_alpha=None, reg_lambda=None,\n                                          scale_pos_weight=None, subsample=None,\n                                          tree_method=None,\n                                          validate_parameters=None,\n                                          verbosity=None),\n                   n_iter=5,\n                   param_distributions={'colsample_bytree': [0.3, 0.4, 0.5, 0.7,\n                                                             0.8],\n                                        'gamma': [0.1, 0.2, 0.3, 0.4, 0.5],\n                                        'learning_rate': [0.2, 0.25, 0.3],\n                                        'max_depth': [4, 5, 6, 8, 10],\n                                        'min_child_weight': [1, 3, 5, 7, 9]},\n                   scoring=make_scorer(r2_score))",
            "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n                   estimator=XGBRegressor(base_score=None, booster=None,\n                                          colsample_bylevel=None,\n                                          colsample_bynode=None,\n                                          colsample_bytree=None,\n                                          enable_categorical=False, gamma=None,\n                                          gpu_id=None, importance_type=None,\n                                          interaction_constraints=None,\n                                          learning_rate=None,\n                                          max_delta_step=None, max_depth=No...\n                                          predictor=None, random_state=None,\n                                          reg_alpha=None, reg_lambda=None,\n                                          scale_pos_weight=None, subsample=None,\n                                          tree_method=None,\n                                          validate_parameters=None,\n                                          verbosity=None),\n                   n_iter=5,\n                   param_distributions={&#x27;colsample_bytree&#x27;: [0.3, 0.4, 0.5, 0.7,\n                                                             0.8],\n                                        &#x27;gamma&#x27;: [0.1, 0.2, 0.3, 0.4, 0.5],\n                                        &#x27;learning_rate&#x27;: [0.2, 0.25, 0.3],\n                                        &#x27;max_depth&#x27;: [4, 5, 6, 8, 10],\n                                        &#x27;min_child_weight&#x27;: [1, 3, 5, 7, 9]},\n                   scoring=make_scorer(r2_score))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n                   estimator=XGBRegressor(base_score=None, booster=None,\n                                          colsample_bylevel=None,\n                                          colsample_bynode=None,\n                                          colsample_bytree=None,\n                                          enable_categorical=False, gamma=None,\n                                          gpu_id=None, importance_type=None,\n                                          interaction_constraints=None,\n                                          learning_rate=None,\n                                          max_delta_step=None, max_depth=No...\n                                          predictor=None, random_state=None,\n                                          reg_alpha=None, reg_lambda=None,\n                                          scale_pos_weight=None, subsample=None,\n                                          tree_method=None,\n                                          validate_parameters=None,\n                                          verbosity=None),\n                   n_iter=5,\n                   param_distributions={&#x27;colsample_bytree&#x27;: [0.3, 0.4, 0.5, 0.7,\n                                                             0.8],\n                                        &#x27;gamma&#x27;: [0.1, 0.2, 0.3, 0.4, 0.5],\n                                        &#x27;learning_rate&#x27;: [0.2, 0.25, 0.3],\n                                        &#x27;max_depth&#x27;: [4, 5, 6, 8, 10],\n                                        &#x27;min_child_weight&#x27;: [1, 3, 5, 7, 9]},\n                   scoring=make_scorer(r2_score))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n             colsample_bynode=None, colsample_bytree=None,\n             enable_categorical=False, gamma=None, gpu_id=None,\n             importance_type=None, interaction_constraints=None,\n             learning_rate=None, max_delta_step=None, max_depth=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n             predictor=None, random_state=None, reg_alpha=None, reg_lambda=None,\n             scale_pos_weight=None, subsample=None, tree_method=None,\n             validate_parameters=None, verbosity=None)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n             colsample_bynode=None, colsample_bytree=None,\n             enable_categorical=False, gamma=None, gpu_id=None,\n             importance_type=None, interaction_constraints=None,\n             learning_rate=None, max_delta_step=None, max_depth=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n             predictor=None, random_state=None, reg_alpha=None, reg_lambda=None,\n             scale_pos_weight=None, subsample=None, tree_method=None,\n             validate_parameters=None, verbosity=None)</pre></div></div></div></div></div></div></div></div></div></div>"
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "params_grid = {'learning_rate': [0.20, 0.25, 0.30],\n",
        "               'max_depth': [4, 5, 6, 8, 10],\n",
        "               'min_child_weight': [1, 3, 5, 7, 9],\n",
        "               'gamma': [0.1, 0.2 , 0.3, 0.4, 0.5],\n",
        "               'colsample_bytree' : [0.3, 0.4, 0.5, 0.7, 0.8]}\n",
        "\n",
        "randomCV = RandomizedSearchCV(estimator = XGBRegressor(),\n",
        "                              param_distributions = params_grid,\n",
        "                              scoring = make_scorer(r2_score),\n",
        "                              cv = StratifiedKFold(n_splits = 5),\n",
        "                              n_iter = 5)\n",
        "\n",
        "randomCV.fit(df_dummies, df_train_y_regresion)"
      ],
      "metadata": {
        "id": "7RTpJeq92DpS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c628a9ba-c22a-41d7-fe70-c2cac713f798"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "{'min_child_weight': 3,\n 'max_depth': 10,\n 'learning_rate': 0.25,\n 'gamma': 0.1,\n 'colsample_bytree': 0.4}"
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "randomCV.best_params_"
      ],
      "metadata": {
        "id": "BjxPIZ2wNtwh",
        "outputId": "28aa4ec1-74d9-4708-f3a9-3d48710c8b4b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Se obtuvo un Score de 58.795%\n",
            "El error según la métrica 'Mean Square Error' de test es: 52042540459.91041\n",
            "El error según la métrica 'Root Mean Square Error' de test es: 228128.34207943213\n"
          ]
        }
      ],
      "source": [
        "prediccion_y_metricas_regresion(randomCV.best_estimator_,df_test_dummies, df_test_y_regresion)"
      ],
      "metadata": {
        "id": "xlm81NqHNtwi",
        "outputId": "0e987eb4-61ea-407f-9991-a690c208a22c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observamos que, si bien las métricas mejoraron, las diferencias al optimizar los parámetros no fueron muy significativas."
      ],
      "metadata": {
        "collapsed": false,
        "id": "h1gb490iNtwi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Importancia de Features"
      ],
      "metadata": {
        "id": "DLI9IK9AP7_n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora veamos cómo se comporta la importancia de atributos con la optimización realizada:"
      ],
      "metadata": {
        "id": "CU0TWzd-QFp6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Apecto cocina"
      ],
      "metadata": {
        "id": "GKe7Aux4HVBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aspecto_id = list()\n",
        "\n",
        "for aspecto in list(filter(lambda x: x.startswith('cocina_'), df_dummies.columns.tolist())):\n",
        "  aspecto_id.append(df_dummies.columns.get_loc(aspecto))"
      ],
      "metadata": {
        "id": "4r-iB4_mHVBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(df_test_dummies.columns[aspecto_id], XGB_Regressor.feature_importances_[aspecto_id])\n",
        "plt.xlabel(\"Importancia de Atributos\")\n",
        "plt.ylabel(\"Aspecto cocina\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "5dc827b5-aaaf-404e-c335-2ceb277f8650",
        "id": "CZPbODvdHVBW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Aspecto cocina')"
            ]
          },
          "metadata": {},
          "execution_count": 177
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nuevamente el atributo más importante es: *integrada*."
      ],
      "metadata": {
        "id": "6vbZ15zrHVBW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Apecto pisos"
      ],
      "metadata": {
        "id": "4HxehiLvHVBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aspecto_id = list()\n",
        "\n",
        "for aspecto in list(filter(lambda x: x.startswith('pisos_'), df_dummies.columns.tolist())):\n",
        "  aspecto_id.append(df_dummies.columns.get_loc(aspecto))"
      ],
      "metadata": {
        "id": "JP0NJAFYHVBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(df_test_dummies.columns[aspecto_id], XGB_Regressor.feature_importances_[aspecto_id])\n",
        "plt.xlabel(\"Importancia de Atributos\")\n",
        "plt.ylabel(\"Aspecto pisos\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "e87cdc42-525e-45a0-dd92-b6321f5d9af8",
        "id": "2pTO8xr3HVBX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Aspecto pisos')"
            ]
          },
          "metadata": {},
          "execution_count": 179
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nuevamente el atributo más importante es: *madera*."
      ],
      "metadata": {
        "id": "KFLUIBQ0HVBX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Apecto calefaccion"
      ],
      "metadata": {
        "id": "tAw_txwJHVBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aspecto_id = list()\n",
        "\n",
        "for aspecto in list(filter(lambda x: x.startswith('calefaccion_'), df_dummies.columns.tolist())):\n",
        "  aspecto_id.append(df_dummies.columns.get_loc(aspecto))"
      ],
      "metadata": {
        "id": "2PX--BYCHVBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(df_test_dummies.columns[aspecto_id], XGB_Regressor.feature_importances_[aspecto_id])\n",
        "plt.xlabel(\"Importancia de Atributos\")\n",
        "plt.ylabel(\"Aspecto calefaccion\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "ed278fbf-116c-4ba9-cbaa-056ce3eaa13f",
        "id": "5KS3ThqJHVBX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Aspecto calefaccion')"
            ]
          },
          "metadata": {},
          "execution_count": 181
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nuevamente el atributo más importante es: *radiante*."
      ],
      "metadata": {
        "id": "Qj49TSjPHVBX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Apecto expensas"
      ],
      "metadata": {
        "id": "vBAV1ck_HVBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aspecto_id = list()\n",
        "\n",
        "for aspecto in list(filter(lambda x: x.startswith('expensas_'), df_dummies.columns.tolist())):\n",
        "  aspecto_id.append(df_dummies.columns.get_loc(aspecto))"
      ],
      "metadata": {
        "id": "ldqc6v0BHVBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(df_test_dummies.columns[aspecto_id], XGB_Regressor.feature_importances_[aspecto_id])\n",
        "plt.xlabel(\"Importancia de Atributos\")\n",
        "plt.ylabel(\"Aspecto expensas\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "c9d2f8f3-824c-4160-beb6-26bac0d8b92d",
        "id": "dquLtB6MHVBY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Aspecto expensas')"
            ]
          },
          "metadata": {},
          "execution_count": 183
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdoAAAEGCAYAAADCGFT7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAa/klEQVR4nO3de9QddX3v8fcnyE1AzkHQhXgJIooISgFBBRXUWisIFcFIsQvW0mO1niq21MspxUttBT21tlJB6rHYiogoeOOIIkJBQEMigQAFVIwekZZiKxep3PI9f8wvshOe5Nlofs+TZ+f9WmuvPXv2b2a+v72TfPKbmT2TqkKSJPUxb7YLkCRpkhm0kiR1ZNBKktSRQStJUkcGrSRJHT1stgvQumXrrbeu+fPnz3YZkjSnLF68+Naq2maq9wxarWT+/PksWrRotsuQpDklyQ9X9567jiVJ6siglSSpI4NWkqSODFpJkjoyaCVJ6siglSSpI4NWkqSODFpJkjryghVaydKbbmP+28+Z7TIkaUYtO/6Abut2RCtJUkcGrSRJHRm0kiR1ZNBKktSRQStJUkcGrSRJHRm0kiR1ZNBKktSRQStJUkcGrSRJHRm0kiR1ZNBKktSRQStJUkcGrSRJHRm0kiR1ZNBKktSRQStJUkcGrSRJHRm0kiR1ZNBKktSRQStJUkcGrSRJHRm0kiR1ZNBKktSRQStJUkcGrSRJHRm0kiR1ZNBKktSRQStJUkcGrSRJHRm0kiR1ZNBKktSRQStJUkcGrSRJHRm0kiR1ZNBKktSRQStJUkcGrSRJHRm0kiR1ZNBKktSRQStJUkcG7ZiSfCzJzrNdxwpJdkvy0tmuQ5K0ZgbtmKrqtVV17WzXMWI3wKCVpHVc16BN8uokC5MsSfLRJHsnuSrJJkk2S3JNkl2S7JfkoiTnJLk+yclJ5rV1vDjJZUm+k+TMJJu3+cuSvLvNX5pkpzb/+W17S5JckWSLJJsnOX+k7cGt7WZtm1cmuTrJgjX05cIke7bpO5N8oNX/9SR7tfdvTHJQa3NUki+0+d9N8s42f36Sq0fWe0ySd7XpHZKcm2RxkotH+nRYq+/K9jltBLwHWND6uSDJVkk+3z7fbyV5+uo+jyn69roki5Isuv+u237t712S9IBuQZvkqcACYJ+q2g24H3gK8EXgvcD7gU9W1YrQ2Qv4Q2BnYAfgkCRbA8cCL6qq3YFFwB+NbObWNv8k4Jg27xjgjW2bzwX+C/gF8PLWdn/gr5IEeAnwk6p6RlXtApw7Zvc2A75RVU8D7mj9+U3g5QwBuMJewCuApwOHrQjqNTgF+MOq2qP14yNt/nHAb1XVM4CDquqeNu+Mqtqtqs4A3g1cUVVPB/4X8I9r+DxWUlWnVNWeVbXnBg/fcsyPQJI0jod1XPcLgT2Ay4dMY1PgFoYgupwh/N400n5hVd0IkOR0YN/WZmfgkraOjYDLRpY5qz0vBg5p05cAH0xyGnBWVf04yYbAXyZ5HrAc2A54NLCUIXRPAL5cVReP2bd7eCCUlwJ3V9W9SZYC80fanVdVP219Oqv16fNTrbCN1J8DnNn6CrDxSJ9OTfKZkT6val+GUKeqvpHkkUkeMdXnMWYfJUlrQc+gDfCJqnrHSjOTbYHNgQ2BTYCft7dqleWrreO8qjp8Ndu4uz3fT+tLVR2f5ByG45eXJPkt4FnANsAeLRCXAZtU1Q1Jdm9t35vk/Kp6z4O28mD3VtWKepevqKOqlicZ/Uyn6tN9rLwnYZP2PA/4WRt5rrxQ1euT7A0cACxOsscYNa5Y9kGfR1VdN+7ykqRfT89jtOcDhyZ5FEA7hvgE4KPAnwGnASeMtN8ryfbt2OwC4JvAt4B9kjyprWOzJE9e00aT7FBVS6vqBIaR807AlsAtLWT3B57Q2j4GuKuqPgl8ANh9bXW++c3W702B32EYXf4b8Kg24twYOBCgqm4HfpDksFZbkjxjpE/frqrjgH8HHsewy3r0eOvFwBGt/X4Mu9VvX83nIUmaId1GtFV1bZJjga+18LwX+ALDaPBTSTYALk3yAoZR4eXAicCTgAuAs9sI8Sjg9BZKMByzvWENmz66hely4BrgKwyB9KW2a3cRsGJEtyvwgSTLW31vWEvdX2Eh8DngsQzHoxcBJHlPe++mkVpgCMqT2ue2IfBp4MpW444MI/zz27wfAW9PsgR4H/Au4ONJrgLuAo5s65zq85AkzZA8sAd0FosYRmDHVNWBs13L2tL+g7BnVf3P2a7lodh42x1r2yM/NNtlSNKMWnb8Ab/W8kkWV9WUJ7z6O1pJkjrqeTLU2KrqQuDCWS4DgCRnA9uvMvttVfXVh7KeqjoVOHUtlSVJmqPWiaBdl1TVy2e7BknS5HDXsSRJHRm0kiR1NG3QtuvsbtGmj01yVrvIgyRJmsY4I9o/q6o7kuwLvAj4PwzXFpYkSdMYJ2jvb88HAKdU1TkM1xyWJEnTGCdob0ryUYbLIv7fdoUmj+1KkjSGcQLzlcBXGW7T9jNgK+BPulYlSdKEmDZoq+quqjoLuC3J4xmuwevdXyRJGsM4Zx0flOS7wA+Af27PXphekqQxjLPr+M8Z7ud6Q1Vtz3Dm8be6ViVJ0oQYJ2jvraqfAvOSzKuqC4Ap71AgSZJWNs61jn+WZHPgIuC0JLcAP+9bliRJk2GcEe3BDDcSfwtwLvB94GU9i5IkaVKM/XvYqroPuAxYBtzeqyBJkibJOEF7EbBJku2ArwG/h/dZlSRpLOMEbarqLuAQ4CNVdRjwtL5lSZI0GcYK2iTPBo4AzmnzNuhXkiRJk2OcoH0z8A7g7Kq6JskTgQv6liVJ0mSY9uc9VXURw3HaFa9vBN7UsyhJkibFtEGb5MnAMcD80fZV9YJ+ZUmSNBnGuWDFmcDJwMd44N60kiRpDOME7X1VdVL3SiRJmkDjnAz1pSR/kGTbJFuteHSvTJKkCTDOiPbI9jx6s/cCnrj2y5EkabKMc9bx9jNRiCRJk2icG78/PMmxSU5pr3dMcmD/0iRJmvvGOUb7D8A9wHPa65uA93arSJKkCTJO0O5QVe8H7gVo1z1O16okSZoQ4wTtPUk2ZTgBiiQ7AHd3rUqSpAkxzlnH72S44fvjkpwG7AMc1bMoSZImxThnHZ+X5DvAsxh2Gb+5qm7tXpkkSRNgnBEtwPOBfRl2H28InN2tIkmSJsg4P+/5CPB6YClwNfD7Sf6ud2GSJE2CcUa0LwCeWlUrTob6BHBN16okSZoQ4wTt94DHAz9srx/X5mkC7brdliw6/oDZLkOSJsY4QbsF8C9JFjIco90LWJTkiwBVdVDH+iRJmtPGCdrjulchSdKEGido/72qrh2dkWS/qrqwT0mSJE2Oca4M9Zkkb81g0yQfBt7XuzBJkibBOEG7N8PJUJcClwM/Ybg6lCRJmsY4QXsv8F/ApsAmwA+qannXqiRJmhDjBO3lDEH7TOC5wOFJzuxalSRJE2Kck6FeU1WL2vTNwMFJfq9jTZIkTYxxRrSLk7w6yXEASR4PXN+3LEmSJsM4QfsR4NnA4e31HYDXOpYkaQzj7Dreu6p2T3IFQFX9Z5KNOtclSdJEGOus4yQbMFx+kSTbAJ51LEnSGMYJ2r9luP/so5L8BfBN4C+7ViVJ0oSYdtdxVZ2WZDHwQiDA71TVv3SvTJKkCTDOMVqq6jrgus61SJI0ccbZdSxJkn5FBq0kSR2Ntes4yaMZLsEIsLCqbulXkiRJk2PaEW2SVwILgcOAVwLfTnJo78IkSZoE44xo/xR45opRbPsd7deBz/YsTJKkSTDOMdp5q+wq/umYy0mStN4bZ0R7bpKvAqe31wuAr/QrSbNp6U23Mf/t58x2GVqHLTv+gNkuQZpTxrlgxZ8kOQTYt806parO7luWJEmTYdqgTXJCVb0NOGuKeZIkaQ3GOdb6m1PM++21XYgkSZNotSPaJG8A/gDYIclVI29tAVzauzBJkibBmnYdf4rhpKf3AW8fmX9HVf1H16okSZoQq911XFW3VdUy4G+A/6iqH1bVD4H7kuw9UwVKkjSXjXOM9iTgzpHXd7Z5kiRpGuMEbaqqVryoquWMeY1kSZLWd+ME7Y1J3pRkw/Z4M3Bj78IkSZoE4wTt64HnADcBPwb2Bl7XsyhJkibFOFeGugV41QzUIknSxBnnNnlPTnJ+kqvb66cnObZ/aZIkzX3j7Dr+e+AdwL0AVXUVjnAlSRrLOEH78KpauMq8+3oUI0nSpBknaG9NsgNQAEkOBW7uWpUkSRNinN/DvhE4BdgpyU3AD4AjulYlSdKEGOes4xuBFyXZDJhXVXf0L0uSpMkwzlnHj0zyt8DFwIVJ/ibJI/uXJknS3DfOMdpPA/8OvAI4tE2f0bMoSZImxTjHaLetqj8fef3eJAt6FSRJ0iQZZ0T7tSSvSjKvPV4JfLV3YZIkTYJxgvZ/MNwE/m7gHoZdyb+f5I4kt/csTpKkuW6cs463mIlCJEmaROOcdbxP+2kPSV6d5INJHt+/NEmS5r5xdh2fBNyV5BnAHwPfB/6pa1WSJE2IcYL2vqoq4GDgxKr6O8DdyZIkjWGcn/fckeQdwKuB5yWZB2zYtyxJkibDOCPaBQxnHL+mqv4VeCzwga5VSZI0IaYN2qr616r6YFVd3GY9Adi7b1mSJE2GcXYdk+Q3gN8FDmO4e8/nehYlSdKkWG3QJnkycHh73MpwfeNU1f4zVJskSXPemka01zHcsefAqvoeQJK3zEhVkiRNiDUdoz0EuBm4IMnfJ3khkJkpS5KkybDaoK2qz1fVq4CdgAuAo4FHJTkpyYtnqkBJkuaycc46/nlVfaqqXsbw054rgLd1r0ySpAkwzu9of6mq/rOqTqmqF/YqSJKkSfKQglaSJD00Bq0kSR0ZtJIkdWTQSpLUkUErSVJHBu06JMmyJFs/hPYHJXl7z5okSb+esW4qoHVTVX0R+OJs1yFJWr05P6JN8uokC5MsSfLRJHsnuSrJJkk2S3JNkl2S7JfkoiTnJLk+ycntJvYkeXGSy5J8J8mZSTZv85cleXebvzTJTm3+89v2liS5IskWSTZPcv5I24Nb283aNq9McnWSBdN06a1t+YVJntTW8bIk327b+nqSR7f5RyU5cZo2D6p1is/wdUkWJVl0/123raVvRpIEczxokzyV4cb0+1TVbsD9wFMYRnnvBd4PfLKqrm6L7AX8IbAzsANwSNtVeyzwoqraHVgE/NHIZm5t808CjmnzjgHe2Lb5XOC/gF8AL29t9wf+KkmAlwA/qapnVNUuwLnTdOu2qtoVOBH4UJv3TeBZVfUbwKeBt06x3OraTFXrStpFSPasqj03ePiW05QnSXoo5vqu4xcCewCXD5nGpsAtwHuAyxnC700j7RdW1Y0ASU4H9m1tdgYuaevYCLhsZJmz2vNihhstAFwCfDDJacBZVfXjJBsCf5nkecByYDvg0cBShtA9AfhyVV08TZ9OH3n+6zb9WOCMJNu2+n4wxXKra/OgWqfZviRpLZrTI1qGuwl9oqp2a4+nVNW7gEcCmwNbAJuMtK9Vlq+2jvNG1rFzVb1mpM3d7fl+2n9Mqup44LUMwX5J26V8BLANsEcbPf4bsElV3QDszhC4701y3DR9qimmPwyc2Ea6v79Kn1hTm9XUKkmaIXM9aM8HDk3yKIAkWyV5AvBR4M+A04ATRtrvlWT7dmx2AcPu1m8B+4wcD92s3fR+tZLsUFVLq+oEhpHzTsCWwC1VdW+S/YEntLaPAe6qqk8CH2AI3TVZMPK8YmS9JXBTmz5yNctN2WY1tUqSZsic3nVcVdcmORb4WgvPe4EvAPdW1aeSbABcmuQFDLtzL2c49vkkhlv/nV1Vy5McBZyeZOO26mOBG9aw6aNbmC4HrgG+wjB6/lKSpQzHea9rbXcFPpBkeavvDdN0678nuYphJH14m/cu4Mwk/wl8A9h+9GOYps1UtUqSZkiqVt2bOpmS7AccU1UHznYta0uSPwYeUVXvXFvr3HjbHWvbIz80fUOtt5Ydf8BslyCtc5Isrqo9p3pvTo9o12dJXg8cxQMnaEmS1kHrTdBW1YXAhbNcBgBJzmbl3b8Ab6uqr467jqo6GTh5rRYmSVrr1pugXZdU1ctnuwZJ0syY62cdS5K0TjNoJUnqyKCVJKkjg1aSpI4MWkmSOjJoJUnqyKCVJKkjg1aSpI4MWkmSOjJoJUnqyKCVJKkjg1aSpI4MWkmSOjJoJUnqyKCVJKkjg1aSpI4MWkmSOjJoJUnqyKCVJKkjg1aSpI4MWkmSOjJoJUnqyKCVJKkjg1aSpI4MWkmSOjJoJUnqyKCVJKkjg1aSpI4MWkmSOjJoJUnqyKCVJKkjg1aSpI4MWkmSOjJoJUnq6GGzXYDWLbtutyWLjj9gtsuQpInhiFaSpI4MWkmSOjJoJUnqyKCVJKkjg1aSpI4MWkmSOjJoJUnqyKCVJKkjg1aSpI5SVbNdg9YhSe4Arp/tOjrbGrh1tovoaNL7B/ZxUkxSH59QVdtM9YaXYNSqrq+qPWe7iJ6SLJrkPk56/8A+Tor1oY/grmNJkroyaCVJ6sig1apOme0CZsCk93HS+wf2cVKsD330ZChJknpyRCtJUkcGrSRJHRm0Ey7JS5Jcn+R7Sd4+xfsbJzmjvf/tJPNH3ntHm399kt8ad50zqVP/Pp7kliRXz0wv1mxt9zHJ45JckOTaJNckefPM9WZqHfq4SZKFSa5sfXz3zPXmwXr8OW3vbZDkiiRf7t+LNev0d3FZkqVJliRZNDM96aCqfEzoA9gA+D7wRGAj4Epg51Xa/AFwcpt+FXBGm965td8Y2L6tZ4Nx1jmX+9feex6wO3D1hH6H2wK7tzZbADfM1nfYsY8BNm9tNgS+DTxrUvo3stwfAZ8Cvjxpf07be8uArWezb2vj4Yh2su0FfK+qbqyqe4BPAwev0uZg4BNt+rPAC5Okzf90Vd1dVT8AvtfWN846Z0qP/lFVFwH/MRMdGMNa72NV3VxV3wGoqjuAfwG2m4G+rE6PPlZV3dnab9ges3XmZ5c/p0keCxwAfGwG+jCdLn2cFAbtZNsO+H8jr3/Mg/9B/WWbqroPuA145BqWHWedM6VH/9Y1XfvYdt/9BsOIb7Z06WPbrboEuAU4r6pmq4+9vsMPAW8Flq/9kh+yXn0s4GtJFid5XYe6Z4RBK62nkmwOfA44uqpun+161raqur+qdgMeC+yVZJfZrmltSXIgcEtVLZ7tWjrbt6p2B34beGOS5812Qb8Kg3ay3QQ8buT1Y9u8KdskeRiwJfDTNSw7zjpnSo/+rWu69DHJhgwhe1pVndWl8vF1/R6r6mfABcBL1mrV4+vRv32Ag5IsY9hN+4Ikn+xR/Ji6fIdVteL5FuBs5uou5dk+SOyj34PhphE3MpxgsOIEhaet0uaNrHyCwmfa9NNY+QSFGxlOeJh2nXO5fyPLzWfdOBmqx3cY4B+BD812/zr2cRvgv7U2mwIXAwdOSv9WWXY/Zv9kqB7f4WbAFq3NZsClwEtm+8/rr/T5zHYBPjp/wfBShrNKvw/8aZv3HuCgNr0JcCbDCQgLgSeOLPunbbnrgd9e0zonrH+nAzcD9zIcL3rNJPUR2Jfh2NdVwJL2eOmE9fHpwBWtj1cDx01S/1ZZ937MctB2+g6fyBDAVwLXzPa/Nb/Ow0swSpLUkcdoJUnqyKCVJKkjg1aSpI4MWkmSOjJoJUnqyKCV5qgkd07faq1ub36S3+2w3j2T/O2vsfypSQ79FZZbkuTTq8w7OsnD17DMx5Ls3KYf0uefZLckL32odWruM2glTatdyWc+sNaDtqoWVdWb1vZ61yTJUxkuivDcJJuNvHU0MGXQJtmgql5bVdf+ipvdjeG3plrPGLTSHJdkvyT/nOQLSW5McnySI9r9WJcm2aG1OzXJyUkWJbmhXS93xb1b/6G1vSLJ/m3+UUm+mOQbwPnA8QzBtCTJW9oI9+Ik32mP54zUc2GSzya5Lslp7S4tJHlmkkvbfWIXJtmitf9ye3+vJJe1Oi5N8pQp+pskJ7Z7l34deNTIe3u0z2Jxkq8m2XY1H9vhwD8BX6PdZSbJm4DHABckuaDNuzPJXyW5Enh269eeI9v76wz3uz0/yTZt3i/bJNk6wz1VN2K4eMOC9vktSLJVks8nuSrJt5I8vS3z/NZmSfsctnjIfyi0bpntK2b48OHjV3sAd7bn/YCfMdxndmOG68S+u733ZtqlFoFTgXMZ/oO9I8NVrzYB/hj4eGuzE/CjNv+o1marke18eWT7Dwc2adM7AotG2t3GcM3aecBlDFej2ojh8nrPbO0ewXDpvl+ud8W8Nv0i4HNT9PsQ4DyGEeljWt8PZbgV3qXANq3dghX9mmId1wOPB14MfGlk/jJG7n/KcAWtV468vhDYc+S9I9r0ccCJU7TZGljWpo9a0aa9/jDwzjb9AmBJm/4SsE+b3nzF5+Fj7j4ehqRJcHlV3QyQ5PsMIzWApcD+I+0+U1XLge8muZEhWPdl+EefqrouyQ+BJ7f251XV6u7NuyFwYpLdgPtHlgFYWFU/bvUsYdjtfBtwc1Vd3rZ1e3t/dJ1bAp9IsiNDkG04xXafB5xeVfcDP2kjboCnALsA57V1bsBwKc2VtNHmrVX1oyQ3AR9PstVq+nk/w80XprIcOKNNfxJ4qDdn2Bd4BUBVfSPJI5M8ArgE+GCS04CzVnyOmrvcdSxNhrtHppePvF4OK/2HetVrrk53Ddafr+G9twD/BjwD2JNhxDpVPfevUsOa/DlwQVXtAryMYWQ9rgDXVNVu7bFrVb14inaHAztluPPN9xlG0a9YzTp/0QJ9HCs+y/t44N/Wh1L/sJKq44HXMtwM4ZIkOz3UdWjdYtBK65fDksxrx22fyLAL9WLgCIAkT2bYpXr9FMveAYweL9ySYYS6HPg9hhHkmlwPbJvkmW1bW7STrEZtyQO3VztqNeu5iOFY5wbtGOyKEfv1wDZJnt3Wv2GSp40umGQe8Epg16qaX1XzGY7RHr6aPq7JPIZd1jCcJPbNNr0M2KNNj54Nveq6Rz/3/RhG2bcn2aGqllbVCcDlDHsdNIcZtNL65UcMd075CvD6qvoF8BFgXpKlDLtCj6qqu6dY9irg/nYi01vacke2E4V2Ys2jX6rqHobjph9uy5zHg0d87wfel+QKVj8KPhv4LnAtw+3+LhtZ/6HACW39S4DnrLLsc4GbquonI/MuAnZuoX0KcO6Kk6Gm8XOGG8pfzXCM9T1t/v8G3tD6sPVI+wvadpYkWQC8C9gjyVUMJ5od2dodneTqNv9ehu9Kc5h375HWE0lOZTjp6LOzXYu0PnFEK0lSR45oJUnqyBGtJEkdGbSSJHVk0EqS1JFBK0lSRwatJEkd/X/tKoNInGkDSQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nuevamente el atributo más importante es: *impuestos*."
      ],
      "metadata": {
        "id": "0s45kCORHVBY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Apecto lavadero"
      ],
      "metadata": {
        "id": "PdcyCmiTHVBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aspecto_id = list()\n",
        "\n",
        "for aspecto in list(filter(lambda x: x.startswith('lavadero_'), df_dummies.columns.tolist())):\n",
        "  aspecto_id.append(df_dummies.columns.get_loc(aspecto))"
      ],
      "metadata": {
        "id": "t8F1W3IIHVBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(df_test_dummies.columns[aspecto_id], XGB_Regressor.feature_importances_[aspecto_id])\n",
        "plt.xlabel(\"Importancia de Atributos\")\n",
        "plt.ylabel(\"Aspecto lavadero\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "92653ca0-ae75-4ace-b01a-31939726ffee",
        "id": "pamqiViMHVBY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Aspecto lavadero')"
            ]
          },
          "metadata": {},
          "execution_count": 185
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nuevamente el atributo más importante es: *cocina*."
      ],
      "metadata": {
        "id": "aR1-Za95HVBY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Apecto balcon"
      ],
      "metadata": {
        "id": "HgbQ0mosHVBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aspecto_id = list()\n",
        "\n",
        "for aspecto in list(filter(lambda x: x.startswith('balcon_'), df_dummies.columns.tolist())):\n",
        "  aspecto_id.append(df_dummies.columns.get_loc(aspecto))"
      ],
      "metadata": {
        "id": "NdM5HsGHHVBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(df_test_dummies.columns[aspecto_id], XGB_Regressor.feature_importances_[aspecto_id])\n",
        "plt.xlabel(\"Importancia de Atributos\")\n",
        "plt.ylabel(\"Aspecto balcon\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "e32f6716-4923-4359-d37e-155c630ab842",
        "id": "myBE8hMaHVBZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Aspecto balcon')"
            ]
          },
          "metadata": {},
          "execution_count": 187
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nuevamente el atributo más importante es: *terraza*."
      ],
      "metadata": {
        "id": "6BJPZY7UHVBZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Apecto cochera"
      ],
      "metadata": {
        "id": "fXsYD0w4HVBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aspecto_id = list()\n",
        "\n",
        "for aspecto in list(filter(lambda x: x.startswith('cochera_'), df_dummies.columns.tolist())):\n",
        "  aspecto_id.append(df_dummies.columns.get_loc(aspecto))"
      ],
      "metadata": {
        "id": "i8m6lyDXHVBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(df_test_dummies.columns[aspecto_id], XGB_Regressor.feature_importances_[aspecto_id])\n",
        "plt.xlabel(\"Importancia de Atributos\")\n",
        "plt.ylabel(\"Aspecto cochera\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "8f5ab625-f54e-4562-b15d-08f74ef07195",
        "id": "4RUuJfzBHVBa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Aspecto cochera')"
            ]
          },
          "metadata": {},
          "execution_count": 189
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nuevamente el atributo más importante es: *fija*."
      ],
      "metadata": {
        "id": "hxvILx6NHVBa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Apecto aire"
      ],
      "metadata": {
        "id": "Pn_ohex5HVBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aspecto_id = list()\n",
        "\n",
        "for aspecto in list(filter(lambda x: x.startswith('aire_'), df_dummies.columns.tolist())):\n",
        "  aspecto_id.append(df_dummies.columns.get_loc(aspecto))"
      ],
      "metadata": {
        "id": "x6996KcuHVBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(df_test_dummies.columns[aspecto_id], XGB_Regressor.feature_importances_[aspecto_id])\n",
        "plt.xlabel(\"Importancia de Atributos\")\n",
        "plt.ylabel(\"Aspecto aire\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "80c29019-a356-4484-c79f-1be783730808",
        "id": "U0XKqtUvHVBb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Aspecto aire')"
            ]
          },
          "metadata": {},
          "execution_count": 191
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nuevamente el atributo más importante es: *split*."
      ],
      "metadata": {
        "id": "pGP13GR6HVBb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conclusiones"
      ],
      "metadata": {
        "id": "tYLmoHA_QhU_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos que, con o sin optimización de parámetros, los atributos más importantes que encontramos para cada aspecto seleccionado fueron:\n",
        "- cocina: integrada\n",
        "- pisos: madera \n",
        "- calefaccion: radiante\n",
        "- expensas: impuestos\n",
        "- lavadero: cocina\n",
        "- balcon: terraza\n",
        "- cochera: fija\n",
        "- aire: split"
      ],
      "metadata": {
        "id": "8AVmBxz5QkGW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exportación del modelo"
      ],
      "metadata": {
        "id": "8HZA6ZbfQzn_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente exportamos el modelo utilizado para predecir, resultante de la optimización de hiperparámetros:"
      ],
      "metadata": {
        "id": "A0W8xtxXQ4Hp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if IN_COLAB:\n",
        "  path = '/content/drive/MyDrive/📒 Organización de Datos (75.06)/TPS/TP2/MODELOS/XGB_Regressor.json'\n",
        "else:\n",
        "  path = './MODELOS/XGB_Regressor.json'\n",
        "\n",
        "randomCV.best_estimator_.save_model(path)"
      ],
      "metadata": {
        "id": "EOYLW4dRQ5Vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Redes Neuronales"
      ],
      "metadata": {
        "collapsed": false,
        "id": "HWpWT3GZ_TQT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.a Regresión"
      ],
      "metadata": {
        "id": "2HjJDe4W_iY-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.a.1 Preparación del dataset"
      ],
      "metadata": {
        "id": "5xI2H0xyYm_B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "x_train_regresion = df_train_x.drop([\"id\"], axis=1).copy()\n",
        "y_train_regresion = df_train_y_regresion.copy()\n",
        "x_test_regresion = df_test_x.drop([\"id\"], axis=1).copy()\n",
        "y_test_regresion = df_test_y_regresion.copy()"
      ],
      "metadata": {
        "id": "hLziZH6gNtwj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizamos las entradas con StandardScaler:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "PKPRQVFS_TQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "estandarizar(x_train_regresion, ['start_date', 'end_date', 'latitud', 'longitud', 'property_rooms', 'property_surface_total'])\n",
        "estandarizar(x_test_regresion, ['start_date', 'end_date', 'latitud', 'longitud', 'property_rooms', 'property_surface_total'])"
      ],
      "metadata": {
        "id": "s3xTEOkRlufG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.a.2 Búsqueda del mejor modelo"
      ],
      "metadata": {
        "id": "NjqmQr4pYrEE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creo una función que me permite generar un modelo a partir de sus hiperparámetros. Esta función tiene como parámetros la cantidad de nodos de la primera y anteúltima capa, la cantidad de capas ocultas, la función de activación y el optimizador. Todos los modelos que genera a excepción de los casos sin capas ocultas) tienen forma de 'pirámide'."
      ],
      "metadata": {
        "collapsed": false,
        "id": "UTuYFbr4Ntwk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "cantidad_de_columnas = x_train_regresion.shape[1]\n",
        "\n",
        "def crear_modelo(hidden_layers, first_layer_nodes, last_layer_nodes, activation_func, optimizer):\n",
        "\n",
        "    sequential = Sequential()\n",
        "    sequential.add(keras.layers.Dense(cantidad_de_columnas, input_shape=(cantidad_de_columnas,), activation=activation_func))\n",
        "\n",
        "    if hidden_layers is 0 or hidden_layers is 1:\n",
        "        decremento = 0\n",
        "    else:\n",
        "        decremento = math.ceil((first_layer_nodes - last_layer_nodes) / (hidden_layers - 1))\n",
        "\n",
        "    for i in range (0, hidden_layers):\n",
        "        nodos = first_layer_nodes - decremento * i\n",
        "        sequential.add(Dense(nodos, activation=activation_func))\n",
        "\n",
        "    sequential.add(Dense(1, activation=activation_func))\n",
        "\n",
        "    sequential.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='mse',\n",
        "        metrics=['mse', 'mean_absolute_percentage_error']\n",
        "    )\n",
        "\n",
        "    return sequential\n",
        "\n",
        "\n",
        "modelo =  KerasRegressor(build_fn=crear_modelo, verbose = False)"
      ],
      "metadata": {
        "id": "OB3WOKToNtwk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luego busco el mejor modelo a partir de una grilla de parámetros arbitrarios con el método de 'GridSearchCV'. El criterio de mejor modelo es el que tenga menor error cuadrado, o lo que es equivalente, mayor error cuadrado negado. Nos limitamos en la cantidad de folds en el CV por el consumo temporal."
      ],
      "metadata": {
        "collapsed": false,
        "id": "QqEVqcy4Ntwl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "param_grid = dict(\n",
        "    hidden_layers=[0, 1],\n",
        "    first_layer_nodes = [math.ceil(cantidad_de_columnas * 0.7), math.ceil(cantidad_de_columnas * 0.5)],\n",
        "    last_layer_nodes = [5, cantidad_de_columnas * 0.5],\n",
        "    activation_func = ['sigmoid', 'relu', 'tanh'],\n",
        "    batch_size = [100],\n",
        "    epochs = [30],\n",
        "    optimizer=['RMSprop', 'adam'],\n",
        ")\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator = modelo,\n",
        "    param_grid = param_grid,\n",
        "    cv=5,\n",
        "    error_score='raise',\n",
        "    scoring='neg_mean_squared_error',\n",
        "    verbose=3,\n",
        ")"
      ],
      "metadata": {
        "id": "JZ4TuMh-Ntwl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamos todos los modelos"
      ],
      "metadata": {
        "collapsed": false,
        "id": "QtlE5E28Ntwl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
            "[CV 1/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-29239235185.519 total time=  14.6s\n",
            "[CV 2/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-28710824056.653 total time=  14.8s\n",
            "[CV 3/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-35295350407.247 total time=  15.3s\n",
            "[CV 4/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-58568012531.976 total time=  15.0s\n",
            "[CV 5/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-404399305824.783 total time=  15.0s\n",
            "[CV 1/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-29239235185.535 total time=  14.9s\n",
            "[CV 2/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-28710824056.660 total time=  15.5s\n",
            "[CV 3/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-35295350407.260 total time=  15.8s\n",
            "[CV 4/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-58568012531.993 total time=  15.7s\n",
            "[CV 5/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-404399305824.805 total time=  15.5s\n",
            "[CV 1/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-29239235185.519 total time=  14.6s\n",
            "[CV 2/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-28710824056.653 total time=  15.3s\n",
            "[CV 3/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-35295350407.247 total time=  14.9s\n",
            "[CV 4/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-58568012531.976 total time=  15.3s\n",
            "[CV 5/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-404399305824.783 total time=  14.8s\n",
            "[CV 1/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-29239235185.527 total time=  15.3s\n",
            "[CV 2/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-28710824056.666 total time=  15.1s\n",
            "[CV 3/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-35295350407.259 total time=  16.0s\n",
            "[CV 4/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-58568012531.993 total time=  15.3s\n",
            "[CV 5/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-404399305824.810 total time=  16.0s\n",
            "[CV 1/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-29239235185.519 total time=  16.3s\n",
            "[CV 2/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-28710824056.653 total time=  16.8s\n",
            "[CV 3/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-35295350407.247 total time=  17.4s\n",
            "[CV 4/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-58568012531.976 total time=  17.4s\n",
            "[CV 5/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-404399305824.783 total time=  16.5s\n",
            "[CV 1/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-29239235185.522 total time=  20.1s\n",
            "[CV 2/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-28710824056.670 total time=  18.6s\n",
            "[CV 3/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-35295350407.247 total time=  17.6s\n",
            "[CV 4/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-58568012531.988 total time=  17.8s\n",
            "[CV 5/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-404399305824.808 total time=  18.4s\n",
            "[CV 1/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-29239235185.519 total time=  16.1s\n",
            "[CV 2/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-28710824056.653 total time=  17.5s\n",
            "[CV 3/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-35295350407.247 total time=  17.8s\n",
            "[CV 4/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-58568012531.976 total time=  16.9s\n",
            "[CV 5/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-404399305824.783 total time=  17.2s\n",
            "[CV 1/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-29239235185.527 total time=  18.1s\n",
            "[CV 2/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-28710824056.670 total time=  17.8s\n",
            "[CV 3/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-35295350407.266 total time=  18.1s\n",
            "[CV 4/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-58568012531.980 total time=  18.6s\n",
            "[CV 5/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-404399305824.834 total time=  18.5s\n",
            "[CV 1/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-29239235185.519 total time=  14.2s\n",
            "[CV 2/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-28710824056.653 total time=  16.4s\n",
            "[CV 3/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-35295350407.247 total time=  14.9s\n",
            "[CV 4/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-58568012531.976 total time=  16.2s\n",
            "[CV 5/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-404399305824.783 total time=  14.9s\n",
            "[CV 1/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-29239235185.534 total time=  16.1s\n",
            "[CV 2/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-28710824056.661 total time=  15.3s\n",
            "[CV 3/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-35295350407.259 total time=  15.8s\n",
            "[CV 4/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-58568012531.984 total time=  16.0s\n",
            "[CV 5/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-404399305824.798 total time=  16.4s\n",
            "[CV 1/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-29239235185.519 total time=  14.7s\n",
            "[CV 2/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-28710824056.653 total time=  16.0s\n",
            "[CV 3/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-35295350407.247 total time=  15.1s\n",
            "[CV 4/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-58568012531.976 total time=  16.5s\n",
            "[CV 5/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-404399305824.783 total time=  15.1s\n",
            "[CV 1/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-29239235185.526 total time=  14.9s\n",
            "[CV 2/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-28710824056.663 total time=  16.0s\n",
            "[CV 3/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-35295350407.255 total time=  15.7s\n",
            "[CV 4/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-58568012531.989 total time=  15.7s\n",
            "[CV 5/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-404399305824.811 total time=  16.0s\n",
            "[CV 1/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-29239235185.519 total time=  16.3s\n",
            "[CV 2/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-28710824056.653 total time=  17.9s\n",
            "[CV 3/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-35295350407.247 total time=  17.3s\n",
            "[CV 4/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-58568012531.976 total time=  16.8s\n",
            "[CV 5/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-404399305824.783 total time=  17.7s\n",
            "[CV 1/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-29239235185.536 total time=  17.4s\n",
            "[CV 2/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-28710824056.672 total time=  17.3s\n",
            "[CV 3/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-35295350407.266 total time=  18.3s\n",
            "[CV 4/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-58568012532.024 total time=  18.6s\n",
            "[CV 5/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-404399305824.834 total time=  18.1s\n",
            "[CV 1/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-29239235185.519 total time=  16.4s\n",
            "[CV 2/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-28710824056.653 total time=  18.0s\n",
            "[CV 3/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-35295350407.247 total time=  17.9s\n",
            "[CV 4/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-58568012531.976 total time=  16.9s\n",
            "[CV 5/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-404399305824.783 total time=  17.4s\n",
            "[CV 1/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-29239235185.520 total time=  17.6s\n",
            "[CV 2/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-28710824056.662 total time=  17.8s\n",
            "[CV 3/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-35295350407.265 total time=  17.5s\n",
            "[CV 4/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-58568012531.988 total time=  18.6s\n",
            "[CV 5/5] END activation_func=sigmoid, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-404399305824.834 total time=  18.5s\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-15679314925.414 total time=  14.4s\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-16812663363.232 total time=  16.6s\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-21249292560.497 total time=  15.0s\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-36296949404.213 total time=  16.2s\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-340886778910.201 total time=  15.2s\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-14820032124.802 total time=  15.8s\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-14844887070.416 total time=  15.6s\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-19033522306.532 total time=  16.2s\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-31054425683.201 total time=  16.0s\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-332906095570.451 total time=  15.9s\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-16896521375.491 total time=  15.2s\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-16358123839.907 total time=  15.8s\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-20387854440.434 total time=  16.1s\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-33741022732.121 total time=  15.5s\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-345451118825.687 total time=  16.4s\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-14121125386.017 total time=  14.8s\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-14425232745.671 total time=  16.7s\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-19252137426.511 total time=  15.6s\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-34557700253.531 total time=  16.6s\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-330207517397.701 total time=  15.9s\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-53488865927.309 total time=  16.7s\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-5377812881.556 total time=  18.2s\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-4735907911.780 total time=  17.5s\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-4842373393.641 total time=  17.3s\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-168278489393.936 total time=  17.8s\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-54312939264.088 total time=  17.5s\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-5779825436.829 total time=  17.8s\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-5101916926.523 total time=  18.3s\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-5139023107.399 total time=  18.7s\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-167417170909.932 total time=  18.2s\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-51603235268.964 total time=  16.4s\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-5539528160.948 total time=  17.7s\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-4612926118.199 total time=  18.4s\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-4763323370.511 total time=  17.4s\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-167248486876.798 total time=  17.5s\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-52376771770.837 total time=  18.1s\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-5619397753.215 total time=  18.7s\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-4716956519.439 total time=  17.9s\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-4990138352.362 total time=  18.0s\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-166691371586.080 total time=  18.5s\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-15850930893.827 total time=  14.9s\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-15416444817.166 total time=  15.8s\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-20162670449.509 total time=  15.9s\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-38983400917.478 total time=  15.5s\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-346111692409.613 total time=  15.9s\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-14628191667.511 total time=  15.2s\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-14025507629.702 total time=  16.6s\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-18401717537.103 total time=  15.6s\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-33851533424.068 total time=  16.8s\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-334907654516.651 total time=  15.6s\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-15679651457.245 total time=  15.4s\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-16429924636.528 total time=  15.2s\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-21537230917.608 total time=  16.3s\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-37110700980.257 total time=  14.9s\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-342249914471.902 total time=  15.9s\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-13342827087.398 total time=  14.7s\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-15347960207.806 total time=  16.6s\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-18287412051.614 total time=  15.3s\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-33614138263.297 total time=  16.4s\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-328750644849.648 total time=  15.5s\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-53829584752.896 total time=  17.0s\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-5573778372.723 total time=  18.1s\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-4786530360.003 total time=  17.7s\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-4663551405.550 total time=  17.0s\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-170511486572.322 total time=  17.8s\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-55316662539.213 total time=  17.2s\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-5632096035.247 total time=  17.5s\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-5034877093.132 total time=  18.1s\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-4917470090.236 total time=  18.4s\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-170222314680.924 total time=  17.8s\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-53058014978.831 total time=  16.2s\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-5426652352.020 total time=  17.7s\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-4713889442.696 total time=  17.3s\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-4477669253.746 total time=  16.9s\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-168045808696.959 total time=  18.0s\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-56392501363.052 total time=  17.8s\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-5482003145.718 total time=  18.1s\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-4925235235.196 total time=  18.1s\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-5033870324.547 total time=  18.3s\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-170093213024.680 total time=  18.6s\n",
            "[CV 1/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-29239235185.519 total time=  14.2s\n",
            "[CV 2/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-28710824056.653 total time=  16.1s\n",
            "[CV 3/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-35295350407.247 total time=  15.0s\n",
            "[CV 4/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-58568012531.976 total time=  15.9s\n",
            "[CV 5/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-404399305824.783 total time=  14.9s\n",
            "[CV 1/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-29239235185.528 total time=  15.7s\n",
            "[CV 2/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-28710824056.656 total time=  15.2s\n",
            "[CV 3/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-35295350407.249 total time=  16.2s\n",
            "[CV 4/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-58568012531.978 total time=  15.8s\n",
            "[CV 5/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-404399305824.785 total time=  16.3s\n",
            "[CV 1/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-29239235185.519 total time=  14.7s\n",
            "[CV 2/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-28710824056.653 total time=  16.0s\n",
            "[CV 3/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-35295350407.247 total time=  15.5s\n",
            "[CV 4/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-58568012531.976 total time=  15.4s\n",
            "[CV 5/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-404399305824.783 total time=  15.3s\n",
            "[CV 1/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-29239235185.531 total time=  15.3s\n",
            "[CV 2/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-28710824056.657 total time=  15.6s\n",
            "[CV 3/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-35295350407.249 total time=  15.8s\n",
            "[CV 4/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-58568012531.978 total time=  16.1s\n",
            "[CV 5/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-404399305824.786 total time=  15.5s\n",
            "[CV 1/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-29239235185.519 total time=  17.3s\n",
            "[CV 2/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-28710824056.653 total time=  17.2s\n",
            "[CV 3/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-35295350407.247 total time=  17.2s\n",
            "[CV 4/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-58568012531.976 total time=  18.2s\n",
            "[CV 5/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-404399305824.783 total time=  18.1s\n",
            "[CV 1/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-29239235185.522 total time=  16.8s\n",
            "[CV 2/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-28710824056.654 total time=  18.3s\n",
            "[CV 3/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-35295350407.247 total time=  18.6s\n",
            "[CV 4/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-58568012531.977 total time=  18.6s\n",
            "[CV 5/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-404399305824.784 total time=  17.9s\n",
            "[CV 1/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-29239235185.519 total time=  16.6s\n",
            "[CV 2/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-28710824056.653 total time=  18.0s\n",
            "[CV 3/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-35295350407.247 total time=  17.5s\n",
            "[CV 4/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-58568012531.976 total time=  17.2s\n",
            "[CV 5/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-404399305824.783 total time=  17.4s\n",
            "[CV 1/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-29239235185.520 total time=  17.9s\n",
            "[CV 2/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-28710824056.654 total time=  17.6s\n",
            "[CV 3/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-35295350407.247 total time=  17.8s\n",
            "[CV 4/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-58568012531.977 total time=  18.7s\n",
            "[CV 5/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=49, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-404399305824.784 total time=  18.7s\n",
            "[CV 1/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-29239235185.519 total time=  14.3s\n",
            "[CV 2/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-28710824056.653 total time=  15.9s\n",
            "[CV 3/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-35295350407.247 total time=  15.2s\n",
            "[CV 4/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-58568012531.976 total time=  15.8s\n",
            "[CV 5/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=RMSprop;, score=-404399305824.783 total time=  15.1s\n",
            "[CV 1/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-29239235185.527 total time=  15.3s\n",
            "[CV 2/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-28710824056.657 total time=  15.6s\n",
            "[CV 3/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-35295350407.249 total time=  16.0s\n",
            "[CV 4/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-58568012531.978 total time=  15.8s\n",
            "[CV 5/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=5, optimizer=adam;, score=-404399305824.785 total time=  15.7s\n",
            "[CV 1/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-29239235185.519 total time=  15.0s\n",
            "[CV 2/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-28710824056.653 total time=  15.3s\n",
            "[CV 3/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-35295350407.247 total time=  15.5s\n",
            "[CV 4/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-58568012531.976 total time=  15.2s\n",
            "[CV 5/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=RMSprop;, score=-404399305824.783 total time=  15.4s\n",
            "[CV 1/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-29239235185.529 total time=  15.0s\n",
            "[CV 2/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-28710824056.656 total time=  16.0s\n",
            "[CV 3/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-35295350407.249 total time=  15.7s\n",
            "[CV 4/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-58568012531.978 total time=  16.5s\n",
            "[CV 5/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=0, last_layer_nodes=34.5, optimizer=adam;, score=-404399305824.786 total time=  15.1s\n",
            "[CV 1/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-29239235185.519 total time=  17.4s\n",
            "[CV 2/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-28710824056.653 total time=  17.4s\n",
            "[CV 3/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-35295350407.247 total time=  16.8s\n",
            "[CV 4/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-58568012531.976 total time=  17.5s\n",
            "[CV 5/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=RMSprop;, score=-404399305824.783 total time=  17.6s\n",
            "[CV 1/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-29239235185.520 total time=  16.5s\n",
            "[CV 2/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-28710824056.654 total time=  18.3s\n",
            "[CV 3/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-35295350407.247 total time=  18.1s\n",
            "[CV 4/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-58568012531.977 total time=  17.4s\n",
            "[CV 5/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=5, optimizer=adam;, score=-404399305824.783 total time=  17.7s\n",
            "[CV 1/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-29239235185.519 total time=  17.3s\n",
            "[CV 2/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-28710824056.653 total time=  18.0s\n",
            "[CV 3/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-35295350407.247 total time=  17.5s\n",
            "[CV 4/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-58568012531.976 total time=  17.3s\n",
            "[CV 5/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=RMSprop;, score=-404399305824.783 total time=  17.6s\n",
            "[CV 1/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-29239235185.519 total time=  17.1s\n",
            "[CV 2/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-28710824056.654 total time=  17.6s\n",
            "[CV 3/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-35295350407.247 total time=  18.4s\n",
            "[CV 4/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-58568012531.977 total time=  18.5s\n",
            "[CV 5/5] END activation_func=tanh, batch_size=100, epochs=30, first_layer_nodes=35, hidden_layers=1, last_layer_nodes=34.5, optimizer=adam;, score=-404399305824.784 total time=  17.7s\n"
          ]
        }
      ],
      "source": [
        "grid_result = grid.fit(x_train_regresion, y_train_regresion)"
      ],
      "metadata": {
        "id": "xhvUmLFXNtwl",
        "outputId": "1602a047-d8b7-4ca8-da0e-cca4694c01b1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los parámetros y métricas del mejor modelo fueron:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "yQ8-pLq0Ntwl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El error absoluto porcentual promedio del mejor modelo fue de:  26.96661\n",
            "El error absoluto cuadrado promedio del mejor modelo fue de:  18100505000.0\n",
            "Los parámetros óptimizados fueron:  {'activation_func': 'relu', 'batch_size': 100, 'epochs': 30, 'first_layer_nodes': 49, 'hidden_layers': 1, 'last_layer_nodes': 34.5, 'optimizer': 'RMSprop'}\n"
          ]
        }
      ],
      "source": [
        "print(\"El error absoluto porcentual promedio del mejor modelo fue de: \", grid_result.best_estimator_.model.metrics[2].result().numpy())\n",
        "print(\"El error absoluto cuadrado promedio del mejor modelo fue de: \", grid_result.best_estimator_.model.metrics[1].result().numpy())\n",
        "print(\"Los parámetros óptimizados fueron: \", grid.best_params_)"
      ],
      "metadata": {
        "id": "gWBHCBPaNtwm",
        "outputId": "ea2e0870-e766-49ec-c367-1a5441a383f5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.a.3 Predicción"
      ],
      "metadata": {
        "collapsed": false,
        "id": "9eCe1wA7Ntwm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "582/582 [==============================] - 1s 1ms/step - loss: 163353624576.0000 - mse: 163353624576.0000 - mean_absolute_percentage_error: 57.0202\n"
          ]
        }
      ],
      "source": [
        "grid_predict = grid.best_estimator_.model.evaluate(x_test_regresion, y_test_regresion)"
      ],
      "metadata": {
        "id": "doYVnST1Ntwm",
        "outputId": "70c17ca4-5713-4726-c22d-a14222c1a22a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.a.4 Métricas"
      ],
      "metadata": {
        "collapsed": false,
        "id": "hhmbLV0aNtwm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El error absoluto porcentual promedio fue de:  57.02020263671875\n",
            "El error absoluto cuadrado promedio (mse) fue de:  163353624576.0\n"
          ]
        }
      ],
      "source": [
        "print(\"El error absoluto porcentual promedio fue de: \", grid_predict[2])\n",
        "print(\"El error absoluto cuadrado promedio (mse) fue de: \", grid_predict[1])"
      ],
      "metadata": {
        "id": "qW4OwtkMNtwm",
        "outputId": "752f9588-01de-4b14-de81-25632ee92ba2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos cómo se comporta la función de pérdida del mejor modelo según la cantidad de épocas utilizadas:"
      ],
      "metadata": {
        "id": "vmBg6ev_ZO-e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": "{'verbose': 1, 'epochs': 1, 'steps': 582}"
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# epochs = range(60)\n",
        "# historia = grid_result.best_estimator_.model.history.history\n",
        "# historia\n",
        "# plt.plot(epochs, historia['mean_absolute_percentage_error'], color='orange', label='MSE')\n",
        "# plt.xlabel(\"epochs\")\n",
        "# plt.ylabel(\"MSE\")\n",
        "# plt.title('Error cuadrático medio por cantidad de épocas')\n",
        "# plt.legend()\n",
        "# print(grid_result.best_estimator_.model.metrics[0].result().numpy(), grid_result.best_estimator_.model.metrics[0].name)\n",
        "max(grid_result.cv_results_[\"mean_test_score\"])\n",
        "grid_result.best_estimator_.model.history.params"
      ],
      "metadata": {
        "id": "BzNqiJex_TQU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "214e1825-e3d1-4d66-f0db-9b0cdf7a2550"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El error según la métrica 'Mean Square Error' de test es: 163353668259.12692\n",
            "El error según la métrica 'Root Mean Square Error' de test es: 404170.34559592186\n"
          ]
        }
      ],
      "source": [
        "y_pred = grid.predict(x_test_regresion)\n",
        "\n",
        "mse = metrics.mean_squared_error(\n",
        "    y_true  = y_test_regresion,\n",
        "    y_pred  = y_pred,\n",
        "    squared = True\n",
        ")\n",
        "\n",
        "print(f\"El error según la métrica 'Mean Square Error' de test es: {mse}\")\n",
        "\n",
        "rmse = metrics.mean_squared_error(\n",
        "    y_true  = y_test_regresion,\n",
        "    y_pred  = y_pred,\n",
        "    squared = False\n",
        ")\n",
        "\n",
        "print(f\"El error según la métrica 'Root Mean Square Error' de test es: {rmse}\")"
      ],
      "metadata": {
        "id": "nzJk_KU-Ntwn",
        "outputId": "69e6785e-dc61-45b3-af94-4cf4509fc1d6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.a.5 Exportación de Datos"
      ],
      "metadata": {
        "id": "BeRZVagKeKzO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, exportamos el modelo utilizado:"
      ],
      "metadata": {
        "id": "lO3v9OUzeKzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if IN_COLAB:\n",
        "  path = '/content/drive/MyDrive/📔 Organización de Datos (75.06)/TPS/TP2/MODELOS/Redes_Regressor.json'\n",
        "else:\n",
        "  path = './MODELOS/Redes_Regressor.json'\n",
        "\n",
        "joblib.dump(grid.best_estimator_.model, path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac67727c-79b0-4c22-bb79-7bd9362015f4",
        "id": "tSuqGenveKzP"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\Salvador\\AppData\\Local\\Temp\\tmpeekvumao\\assets\n"
          ]
        },
        {
          "data": {
            "text/plain": "['./MODELOS/Redes_Regressor.json']"
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.b Clasificación\n",
        "___"
      ],
      "metadata": {
        "collapsed": false,
        "id": "dXdWW-m9_TQV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.b.1 Preparación del dataset"
      ],
      "metadata": {
        "id": "b176QcPLZj9N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "x_train_clasificacion = df_train_x.drop([\"id\"], axis=1).copy()\n",
        "y_train_clasificacion = df_train_y_clasificacion.copy()\n",
        "x_test_clasificacion = df_test_x.drop([\"id\"], axis=1).copy()\n",
        "y_test_clasificacion = df_test_y_clasificacion.copy()"
      ],
      "metadata": {
        "id": "enOp7LBHNtwo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizamos mediante Z-Score:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "JPjRt6tTOWIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_clasificacion[['start_date', 'end_date', 'latitud', 'longitud', 'property_rooms', 'property_surface_total']] = zscore(x_train_clasificacion[['start_date', 'end_date', 'latitud', 'longitud', 'property_rooms', 'property_surface_total']], axis=1)\n",
        "\n",
        "x_test_clasificacion[['start_date', 'end_date', 'latitud', 'longitud', 'property_rooms', 'property_surface_total']] = zscore(x_test_clasificacion[['start_date', 'end_date', 'latitud', 'longitud', 'property_rooms', 'property_surface_total']], axis=1)"
      ],
      "metadata": {
        "id": "qDlv11yi8sR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplicamos One Hot encoding a la columna target de entrenamiento y test, para que tenga 3 columnas al igual que la salida del modelo:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "IZ2XeEKi_TQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_clasificacion = pd.get_dummies(y_train_clasificacion, columns=['tipo_precio_3'], drop_first=False)\n",
        "y_test_clasificacion = pd.get_dummies(y_test_clasificacion, columns=['tipo_precio_3'], drop_first=False)"
      ],
      "metadata": {
        "id": "2jzMgy7b5js1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.b.2 Búsqueda del mejor modelo"
      ],
      "metadata": {
        "collapsed": false,
        "id": "Pb4FJARtNtwp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Función auxiliar para que GridSearchCV realice el scoring de forma correcta."
      ],
      "metadata": {
        "collapsed": false,
        "id": "D2jrVbgkNtwp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def my_categorical_accuracy(y_true, y_pred) :\n",
        "    y_pred_df = pd.DataFrame(data=y_pred, columns=['alto', 'bajo', 'medio'])\n",
        "    res = round(accuracy_score(y_true, y_pred_df), 2)\n",
        "    return res"
      ],
      "metadata": {
        "id": "Y5XutZjkNtwq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos una función que permite generar un modelo a partir de sus hiperparámetros configurables.\n",
        "Esta función recibe como parámetros la cantidad de capas ocultas extra, la cantidad de nodos de la última capa oculta, la función de activación y metadata del clasificador."
      ],
      "metadata": {
        "collapsed": false,
        "id": "ScQ0ytoFNtwq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def crear_modelo(extra_hidden_layers, last_layer_nodes, activation_func, loss_func, meta):\n",
        "\n",
        "    n_features_in_ = meta[\"n_features_in_\"]\n",
        "    X_shape_ = meta[\"X_shape_\"]\n",
        "    n_classes_ = meta[\"n_classes_\"]\n",
        "\n",
        "    sequential = Sequential()\n",
        "    sequential.add(keras.layers.Dense(n_features_in_ * 0.7, input_shape=X_shape_[1:], activation=activation_func))\n",
        "\n",
        "    if last_layer_nodes > n_features_in_:\n",
        "        decremento = 0\n",
        "    elif extra_hidden_layers is 0 or extra_hidden_layers is 1:\n",
        "        decremento = 0\n",
        "    else:\n",
        "        decremento = math.ceil((n_features_in_ - last_layer_nodes) / (extra_hidden_layers - 1))\n",
        "\n",
        "    for i in range (0, extra_hidden_layers):\n",
        "        nodos = n_features_in_ - decremento * i\n",
        "        sequential.add(Dense(nodos, activation=activation_func))\n",
        "\n",
        "    sequential.add(Dense(n_classes_, activation='softmax'))\n",
        "\n",
        "    sequential.compile(\n",
        "        loss='categorical_crossentropy'\n",
        "    )\n",
        "    return sequential\n"
      ],
      "metadata": {
        "id": "ViTphE2QNtwq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos un modelo base, necesario según la documentación de SciKeras - KerasClassifier.\n",
        "Este modelo base será editado por GridSearchCV al buscar los hiperparámetros."
      ],
      "metadata": {
        "collapsed": false,
        "id": "gOQbP0qINtwq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "base_model = KerasClassifier(crear_modelo,\n",
        "                             loss_func=\"categorical_crossentropy\",\n",
        "                             extra_hidden_layers=1,\n",
        "                             last_layer_nodes=1,\n",
        "                             activation_func='sigmoid',\n",
        "                             )"
      ],
      "metadata": {
        "id": "-CTS8iVGNtwq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos los hiperparámetros posibles. Además de los necesarios por la función crear_modelo, agregamos diferentes optimizadores, learning rates y cantidad de épocas."
      ],
      "metadata": {
        "collapsed": false,
        "id": "TRItpl0PNtwr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "param_grid = dict(\n",
        "    extra_hidden_layers=[0, 1],\n",
        "    last_layer_nodes = [10, 20],\n",
        "    activation_func = ['relu', 'softmax'],\n",
        "    batch_size = [100],\n",
        "    epochs = [5, 20],\n",
        "    optimizer__learning_rate = [0.001, 0.0001],\n",
        "    optimizer = [\"adam\", \"sge\"],\n",
        "    loss_func = [\"categorical_crossentropy\"],\n",
        ")\n",
        "\n",
        "gs = GridSearchCV(base_model,\n",
        "                  param_grid = param_grid,\n",
        "                  cv=5,\n",
        "                  scoring=make_scorer(my_categorical_accuracy),\n",
        "                  verbose=3,\n",
        "                  error_score='raise'\n",
        ")"
      ],
      "metadata": {
        "id": "iYSJIxPYNtwr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamos los diferentes modelos y obtenemos los mejores parámetros."
      ],
      "metadata": {
        "collapsed": false,
        "id": "mh6uCeekNtwr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
            "Epoch 1/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8447\n",
            "Epoch 2/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7959\n",
            "Epoch 3/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7934\n",
            "Epoch 4/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7920\n",
            "Epoch 5/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7916\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.150 total time=   4.4s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 909us/step - loss: 0.8761\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 880us/step - loss: 0.8056\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8028\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 892us/step - loss: 0.8016\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 981us/step - loss: 0.8012\n",
            "149/149 [==============================] - 0s 662us/step\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.520 total time=   3.5s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 887us/step - loss: 0.9158\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 884us/step - loss: 0.8576\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 874us/step - loss: 0.8555\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 965us/step - loss: 0.8547\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8544\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.290 total time=   3.6s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 2s 1ms/step - loss: 0.9135\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 928us/step - loss: 0.8608\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 990us/step - loss: 0.8588\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8581\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8574\n",
            "149/149 [==============================] - 0s 905us/step\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.380 total time=   4.5s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7320\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 909us/step - loss: 0.6890\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 906us/step - loss: 0.6862\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 865us/step - loss: 0.6853\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 875us/step - loss: 0.6848\n",
            "149/149 [==============================] - 0s 662us/step\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.010 total time=   3.6s\n",
            "Epoch 1/5\n",
            "594/594 [==============================] - 1s 847us/step - loss: 0.8380\n",
            "Epoch 2/5\n",
            "594/594 [==============================] - 0s 838us/step - loss: 0.7958\n",
            "Epoch 3/5\n",
            "594/594 [==============================] - 1s 840us/step - loss: 0.7929\n",
            "Epoch 4/5\n",
            "594/594 [==============================] - 1s 847us/step - loss: 0.7918\n",
            "Epoch 5/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7913\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.130 total time=   3.2s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8656\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8049\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8026\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8022\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8015\n",
            "149/149 [==============================] - 0s 831us/step\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.420 total time=   4.4s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 880us/step - loss: 0.9121\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 857us/step - loss: 0.8582\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 877us/step - loss: 0.8561\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 869us/step - loss: 0.8556\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 869us/step - loss: 0.8548\n",
            "149/149 [==============================] - 0s 662us/step\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.300 total time=   3.2s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 875us/step - loss: 0.9195\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 870us/step - loss: 0.8607\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8587\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8578\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8574\n",
            "149/149 [==============================] - 0s 993us/step\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.420 total time=   4.3s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7281\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6891\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6860\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6852\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 889us/step - loss: 0.6847\n",
            "149/149 [==============================] - 0s 730us/step\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.010 total time=   4.0s\n",
            "Epoch 1/5\n",
            "594/594 [==============================] - 1s 838us/step - loss: 0.8453\n",
            "Epoch 2/5\n",
            "594/594 [==============================] - 1s 865us/step - loss: 0.7969\n",
            "Epoch 3/5\n",
            "594/594 [==============================] - 1s 843us/step - loss: 0.7939\n",
            "Epoch 4/5\n",
            "594/594 [==============================] - 1s 879us/step - loss: 0.7924\n",
            "Epoch 5/5\n",
            "594/594 [==============================] - 1s 862us/step - loss: 0.7915\n",
            "149/149 [==============================] - 0s 669us/step\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.130 total time=   3.0s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 869us/step - loss: 0.8653\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8051\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8029\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8018\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8012\n",
            "149/149 [==============================] - 0s 892us/step\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.450 total time=   3.8s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9238\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8575\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8558\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8551\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 892us/step - loss: 0.8546\n",
            "149/149 [==============================] - 0s 669us/step\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.360 total time=   3.9s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 860us/step - loss: 0.9179\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 880us/step - loss: 0.8611\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 875us/step - loss: 0.8589\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 874us/step - loss: 0.8580\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 877us/step - loss: 0.8575\n",
            "149/149 [==============================] - 0s 797us/step\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.420 total time=   3.1s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7298\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6892\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6865\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6853\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6849\n",
            "149/149 [==============================] - 0s 824us/step\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.010 total time=   4.0s\n",
            "Epoch 1/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8412\n",
            "Epoch 2/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7952\n",
            "Epoch 3/5\n",
            "594/594 [==============================] - 1s 904us/step - loss: 0.7924\n",
            "Epoch 4/5\n",
            "594/594 [==============================] - 1s 858us/step - loss: 0.7917\n",
            "Epoch 5/5\n",
            "594/594 [==============================] - 1s 843us/step - loss: 0.7911\n",
            "149/149 [==============================] - 0s 669us/step\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.120 total time=   3.5s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 862us/step - loss: 0.8842\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 882us/step - loss: 0.8057\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 877us/step - loss: 0.8028\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 880us/step - loss: 0.8021\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 865us/step - loss: 0.8011\n",
            "149/149 [==============================] - 0s 669us/step\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.520 total time=   3.1s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9108\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8565\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8555\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8550\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8543\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.300 total time=   4.2s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9268\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 963us/step - loss: 0.8610\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 887us/step - loss: 0.8587\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 874us/step - loss: 0.8578\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 875us/step - loss: 0.8571\n",
            "149/149 [==============================] - 0s 716us/step\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.410 total time=   3.4s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 896us/step - loss: 0.7410\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 875us/step - loss: 0.6892\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 860us/step - loss: 0.6860\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 897us/step - loss: 0.6851\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 978us/step - loss: 0.6848\n",
            "149/149 [==============================] - 0s 953us/step\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.010 total time=   3.2s\n",
            "Epoch 1/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8443\n",
            "Epoch 2/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7956\n",
            "Epoch 3/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7928\n",
            "Epoch 4/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7917\n",
            "Epoch 5/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7913\n",
            "149/149 [==============================] - 0s 946us/step\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.130 total time=   4.1s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8784\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 889us/step - loss: 0.8053\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 882us/step - loss: 0.8031\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 882us/step - loss: 0.8019\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 882us/step - loss: 0.8011\n",
            "149/149 [==============================] - 0s 696us/step\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.500 total time=   3.3s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 875us/step - loss: 0.9188\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 882us/step - loss: 0.8576\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 865us/step - loss: 0.8556\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 988us/step - loss: 0.8551\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8549\n",
            "149/149 [==============================] - 0s 959us/step\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.300 total time=   3.4s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9176\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8610\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8591\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8579\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8576\n",
            "149/149 [==============================] - 0s 831us/step\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.390 total time=   3.9s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 911us/step - loss: 0.7373\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 889us/step - loss: 0.6891\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 894us/step - loss: 0.6861\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 892us/step - loss: 0.6853\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 889us/step - loss: 0.6849\n",
            "149/149 [==============================] - 0s 669us/step\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.010 total time=   3.2s\n",
            "Epoch 1/5\n",
            "594/594 [==============================] - 1s 877us/step - loss: 0.8360\n",
            "Epoch 2/5\n",
            "594/594 [==============================] - 1s 897us/step - loss: 0.7948\n",
            "Epoch 3/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7924\n",
            "Epoch 4/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7916\n",
            "Epoch 5/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7908\n",
            "149/149 [==============================] - 0s 885us/step\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.130 total time=   3.6s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8630\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8058\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8030\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8019\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8013\n",
            "149/149 [==============================] - 0s 716us/step\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.510 total time=   4.0s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 896us/step - loss: 0.9188\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 916us/step - loss: 0.8570\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 897us/step - loss: 0.8554\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 912us/step - loss: 0.8549\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 907us/step - loss: 0.8543\n",
            "149/149 [==============================] - 0s 716us/step\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.560 total time=   3.2s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 896us/step - loss: 0.9203\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8609\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8590\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8584\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8576\n",
            "149/149 [==============================] - 0s 953us/step\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.540 total time=   3.8s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7276\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6889\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6859\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6852\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 887us/step - loss: 0.6849\n",
            "149/149 [==============================] - 0s 682us/step\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.010 total time=   3.8s\n",
            "Epoch 1/5\n",
            "594/594 [==============================] - 1s 860us/step - loss: 0.8356\n",
            "Epoch 2/5\n",
            "594/594 [==============================] - 1s 870us/step - loss: 0.7953\n",
            "Epoch 3/5\n",
            "594/594 [==============================] - 1s 867us/step - loss: 0.7926\n",
            "Epoch 4/5\n",
            "594/594 [==============================] - 1s 857us/step - loss: 0.7917\n",
            "Epoch 5/5\n",
            "594/594 [==============================] - 1s 907us/step - loss: 0.7910\n",
            "149/149 [==============================] - 0s 716us/step\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.140 total time=   3.1s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 907us/step - loss: 0.8748\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8052\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8029\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8016\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8011\n",
            "149/149 [==============================] - 0s 899us/step\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.510 total time=   3.9s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9107\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8578\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 880us/step - loss: 0.8551\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 906us/step - loss: 0.8545\n",
            "149/149 [==============================] - 0s 689us/step\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.300 total time=   3.7s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 874us/step - loss: 0.9148\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 875us/step - loss: 0.8610\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 901us/step - loss: 0.8594\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 880us/step - loss: 0.8583\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 880us/step - loss: 0.8578\n",
            "149/149 [==============================] - 0s 662us/step\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.460 total time=   3.1s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7293\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6898\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6862\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6856\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6848\n",
            "149/149 [==============================] - 0s 953us/step\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.010 total time=   4.0s\n",
            "Epoch 1/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8400\n",
            "Epoch 2/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7957\n",
            "Epoch 3/5\n",
            "594/594 [==============================] - 1s 906us/step - loss: 0.7929\n",
            "Epoch 4/5\n",
            "594/594 [==============================] - 1s 902us/step - loss: 0.7916\n",
            "Epoch 5/5\n",
            "594/594 [==============================] - 1s 914us/step - loss: 0.7910\n",
            "149/149 [==============================] - 0s 723us/step\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.140 total time=   3.7s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8697\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 921us/step - loss: 0.8060\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 936us/step - loss: 0.8031\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 901us/step - loss: 0.8019\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8013\n",
            "149/149 [==============================] - 0s 926us/step\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.520 total time=   3.5s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9169\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8576\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8559\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8551\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8545\n",
            "149/149 [==============================] - 0s 905us/step\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.470 total time=   4.4s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 933us/step - loss: 0.9216\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 924us/step - loss: 0.8608\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 912us/step - loss: 0.8589\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 951us/step - loss: 0.8581\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 907us/step - loss: 0.8577\n",
            "149/149 [==============================] - 0s 730us/step\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.420 total time=   3.3s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 875us/step - loss: 0.7385\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 864us/step - loss: 0.6890\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6863\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6855\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6849\n",
            "149/149 [==============================] - 0s 845us/step\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.010 total time=   3.9s\n",
            "Epoch 1/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8228\n",
            "Epoch 2/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7954\n",
            "Epoch 3/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7933\n",
            "Epoch 4/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7924\n",
            "Epoch 5/5\n",
            "594/594 [==============================] - 1s 993us/step - loss: 0.7917\n",
            "149/149 [==============================] - 0s 757us/step\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.090 total time=   4.3s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8412\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8048\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 992us/step - loss: 0.8037\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 998us/step - loss: 0.8023\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 993us/step - loss: 0.8012\n",
            "149/149 [==============================] - 0s 716us/step\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.430 total time=   3.6s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8894\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8588\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8568\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8552\n",
            "149/149 [==============================] - 0s 926us/step\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.410 total time=   4.5s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8977\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8613\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8596\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 990us/step - loss: 0.8581\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 988us/step - loss: 0.8578\n",
            "149/149 [==============================] - 0s 716us/step\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.370 total time=   3.8s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7216\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6887\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6867\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6864\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6859\n",
            "149/149 [==============================] - 0s 865us/step\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.010 total time=   4.0s\n",
            "Epoch 1/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8270\n",
            "Epoch 2/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7953\n",
            "Epoch 3/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7932\n",
            "Epoch 4/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7920\n",
            "Epoch 5/5\n",
            "594/594 [==============================] - 1s 983us/step - loss: 0.7916\n",
            "149/149 [==============================] - 0s 723us/step\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.130 total time=   4.4s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 998us/step - loss: 0.8430\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 995us/step - loss: 0.8057\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8034\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8018\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 992us/step - loss: 0.8015\n",
            "149/149 [==============================] - 0s 730us/step\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.530 total time=   3.6s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8966\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8580\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8571\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8549\n",
            "149/149 [==============================] - 0s 973us/step\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.290 total time=   4.8s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8926\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8615\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8595\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 993us/step - loss: 0.8585\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1000us/step - loss: 0.8576\n",
            "149/149 [==============================] - 0s 716us/step\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.450 total time=   3.7s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7186\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6880\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6865\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6855\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6853\n",
            "149/149 [==============================] - 0s 885us/step\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.010 total time=   4.2s\n",
            "Epoch 1/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8229\n",
            "Epoch 2/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7939\n",
            "Epoch 3/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7927\n",
            "Epoch 4/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7921\n",
            "Epoch 5/5\n",
            "594/594 [==============================] - 1s 985us/step - loss: 0.7913\n",
            "149/149 [==============================] - 0s 764us/step\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.120 total time=   4.3s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8448\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8062\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8043\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8029\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8017\n",
            "149/149 [==============================] - 0s 743us/step\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.420 total time=   3.7s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8910\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8582\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8569\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8549\n",
            "149/149 [==============================] - 0s 959us/step\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.380 total time=   4.8s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9015\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 988us/step - loss: 0.8618\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8596\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8589\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8578\n",
            "149/149 [==============================] - 0s 716us/step\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.370 total time=   3.6s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7143\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6886\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6870\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6866\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6858\n",
            "149/149 [==============================] - 0s 966us/step\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.010 total time=   4.3s\n",
            "Epoch 1/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8195\n",
            "Epoch 2/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7950\n",
            "Epoch 3/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7932\n",
            "Epoch 4/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7926\n",
            "Epoch 5/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7917\n",
            "149/149 [==============================] - 0s 811us/step\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.130 total time=   4.3s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8474\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8054\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8031\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 993us/step - loss: 0.8020\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8014\n",
            "149/149 [==============================] - 0s 851us/step\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.530 total time=   3.6s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8930\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8581\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8569\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8559\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8550\n",
            "149/149 [==============================] - 0s 946us/step\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.390 total time=   4.7s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8958\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8612\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8594\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8586\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8583\n",
            "149/149 [==============================] - 0s 791us/step\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.450 total time=   3.6s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7159\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 990us/step - loss: 0.6883\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6865\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6861\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6856\n",
            "149/149 [==============================] - 0s 899us/step\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.010 total time=   4.2s\n",
            "Epoch 1/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8304\n",
            "Epoch 2/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7948\n",
            "Epoch 3/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7930\n",
            "Epoch 4/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7921\n",
            "Epoch 5/5\n",
            "594/594 [==============================] - 1s 988us/step - loss: 0.7912\n",
            "149/149 [==============================] - 0s 757us/step\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.090 total time=   4.2s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 998us/step - loss: 0.8404\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8047\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8029\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 997us/step - loss: 0.8015\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8012\n",
            "149/149 [==============================] - 0s 966us/step\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.480 total time=   3.6s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8916\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8596\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8569\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
            "149/149 [==============================] - 0s 986us/step\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.290 total time=   4.6s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8921\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 987us/step - loss: 0.8608\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 997us/step - loss: 0.8592\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 993us/step - loss: 0.8585\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8575\n",
            "149/149 [==============================] - 0s 716us/step\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.420 total time=   3.6s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7171\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6878\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6864\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6859\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6854\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.010 total time=   4.6s\n",
            "Epoch 1/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8191\n",
            "Epoch 2/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7949\n",
            "Epoch 3/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7925\n",
            "Epoch 4/5\n",
            "594/594 [==============================] - 1s 970us/step - loss: 0.7917\n",
            "Epoch 5/5\n",
            "594/594 [==============================] - 1s 993us/step - loss: 0.7915\n",
            "149/149 [==============================] - 0s 696us/step\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.120 total time=   4.0s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8448\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 998us/step - loss: 0.8061\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 995us/step - loss: 0.8036\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8023\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8015\n",
            "149/149 [==============================] - 0s 932us/step\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.450 total time=   3.8s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8913\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8581\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8571\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8555\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8552\n",
            "149/149 [==============================] - 0s 865us/step\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.420 total time=   4.6s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 993us/step - loss: 0.8921\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 971us/step - loss: 0.8612\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 993us/step - loss: 0.8590\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8582\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 988us/step - loss: 0.8578\n",
            "149/149 [==============================] - 0s 689us/step\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.420 total time=   3.6s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7241\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6882\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6867\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6865\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6857\n",
            "149/149 [==============================] - 0s 959us/step\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.010 total time=   4.3s\n",
            "Epoch 1/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8194\n",
            "Epoch 2/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7944\n",
            "Epoch 3/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7931\n",
            "Epoch 4/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7923\n",
            "Epoch 5/5\n",
            "594/594 [==============================] - 1s 997us/step - loss: 0.7915\n",
            "149/149 [==============================] - 0s 777us/step\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.060 total time=   4.3s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 992us/step - loss: 0.8434\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 995us/step - loss: 0.8054\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1000us/step - loss: 0.8034\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8026\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8014\n",
            "149/149 [==============================] - 0s 851us/step\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.470 total time=   3.8s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8897\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8588\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8571\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 977us/step - loss: 0.8558\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
            "149/149 [==============================] - 0s 959us/step\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.310 total time=   4.5s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8984\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8616\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8600\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8585\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8579\n",
            "149/149 [==============================] - 0s 743us/step\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.380 total time=   4.0s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7097\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6882\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6865\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6859\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6855\n",
            "149/149 [==============================] - 0s 851us/step\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.010 total time=   4.2s\n",
            "Epoch 1/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8249\n",
            "Epoch 2/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7943\n",
            "Epoch 3/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7927\n",
            "Epoch 4/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7918\n",
            "Epoch 5/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7914\n",
            "149/149 [==============================] - 0s 784us/step\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.090 total time=   4.4s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8418\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 981us/step - loss: 0.8056\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 987us/step - loss: 0.8032\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 988us/step - loss: 0.8020\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8015\n",
            "149/149 [==============================] - 0s 696us/step\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.460 total time=   3.6s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9017\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8583\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8575\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8565\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8551\n",
            "149/149 [==============================] - 0s 831us/step\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.300 total time=   4.6s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8958\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8611\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 985us/step - loss: 0.8593\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8583\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 992us/step - loss: 0.8578\n",
            "149/149 [==============================] - 0s 730us/step\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.410 total time=   3.8s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7168\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6891\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6867\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6861\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6856\n",
            "149/149 [==============================] - 0s 858us/step\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.010 total time=   4.1s\n",
            "Epoch 1/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8433\n",
            "Epoch 2/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7950\n",
            "Epoch 3/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7925\n",
            "Epoch 4/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7920\n",
            "Epoch 5/20\n",
            "594/594 [==============================] - 1s 943us/step - loss: 0.7912\n",
            "Epoch 6/20\n",
            "594/594 [==============================] - 1s 862us/step - loss: 0.7906\n",
            "Epoch 7/20\n",
            "594/594 [==============================] - 1s 860us/step - loss: 0.7905\n",
            "Epoch 8/20\n",
            "594/594 [==============================] - 1s 847us/step - loss: 0.7900\n",
            "Epoch 9/20\n",
            "594/594 [==============================] - 1s 863us/step - loss: 0.7898\n",
            "Epoch 10/20\n",
            "594/594 [==============================] - 0s 831us/step - loss: 0.7895\n",
            "Epoch 11/20\n",
            "594/594 [==============================] - 1s 845us/step - loss: 0.7897\n",
            "Epoch 12/20\n",
            "594/594 [==============================] - 1s 858us/step - loss: 0.7894\n",
            "Epoch 13/20\n",
            "594/594 [==============================] - 1s 879us/step - loss: 0.7894\n",
            "Epoch 14/20\n",
            "594/594 [==============================] - 1s 840us/step - loss: 0.7892\n",
            "Epoch 15/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7894\n",
            "Epoch 16/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7892\n",
            "Epoch 17/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7892\n",
            "Epoch 18/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7890\n",
            "Epoch 19/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7892\n",
            "Epoch 20/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7890\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.150 total time=  12.6s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8705\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 896us/step - loss: 0.8060\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 886us/step - loss: 0.8031\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 880us/step - loss: 0.8018\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 889us/step - loss: 0.8012\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 894us/step - loss: 0.8006\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 887us/step - loss: 0.8005\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 916us/step - loss: 0.7999\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 887us/step - loss: 0.7998\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 887us/step - loss: 0.7997\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7994\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7991\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7989\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7989\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7988\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7984\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7985\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7984\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 992us/step - loss: 0.7985\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 901us/step - loss: 0.7983\n",
            "149/149 [==============================] - 0s 797us/step\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.470 total time=  12.8s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 902us/step - loss: 0.9180\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 886us/step - loss: 0.8576\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 902us/step - loss: 0.8558\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 880us/step - loss: 0.8548\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 887us/step - loss: 0.8545\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 879us/step - loss: 0.8542\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8538\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8538\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8534\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8534\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 990us/step - loss: 0.8527\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 887us/step - loss: 0.8526\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 884us/step - loss: 0.8527\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 877us/step - loss: 0.8524\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 892us/step - loss: 0.8523\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 933us/step - loss: 0.8524\n",
            "149/149 [==============================] - 0s 662us/step\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.300 total time=  12.2s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 865us/step - loss: 0.9140\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 867us/step - loss: 0.8610\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 872us/step - loss: 0.8589\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8587\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8580\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8577\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8574\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8568\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8564\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 892us/step - loss: 0.8557\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 869us/step - loss: 0.8556\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 902us/step - loss: 0.8552\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 869us/step - loss: 0.8554\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 877us/step - loss: 0.8553\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 865us/step - loss: 0.8553\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 884us/step - loss: 0.8552\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 859us/step - loss: 0.8552\n",
            "149/149 [==============================] - 0s 655us/step\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.420 total time=  12.4s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7241\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6888\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6858\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6852\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6845\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6846\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6840\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6841\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 904us/step - loss: 0.6840\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 860us/step - loss: 0.6838\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 889us/step - loss: 0.6837\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 859us/step - loss: 0.6836\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 872us/step - loss: 0.6837\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 864us/step - loss: 0.6835\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 857us/step - loss: 0.6835\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 865us/step - loss: 0.6834\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 864us/step - loss: 0.6834\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 970us/step - loss: 0.6833\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6835\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6832\n",
            "149/149 [==============================] - 0s 851us/step\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.010 total time=  12.7s\n",
            "Epoch 1/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8544\n",
            "Epoch 2/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7981\n",
            "Epoch 3/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7939\n",
            "Epoch 4/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7923\n",
            "Epoch 5/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7915\n",
            "Epoch 6/20\n",
            "594/594 [==============================] - 1s 857us/step - loss: 0.7910\n",
            "Epoch 7/20\n",
            "594/594 [==============================] - 1s 874us/step - loss: 0.7904\n",
            "Epoch 8/20\n",
            "594/594 [==============================] - 1s 841us/step - loss: 0.7902\n",
            "Epoch 9/20\n",
            "594/594 [==============================] - 0s 831us/step - loss: 0.7902\n",
            "Epoch 10/20\n",
            "594/594 [==============================] - 1s 841us/step - loss: 0.7900\n",
            "Epoch 11/20\n",
            "594/594 [==============================] - 0s 836us/step - loss: 0.7897\n",
            "Epoch 12/20\n",
            "594/594 [==============================] - 1s 850us/step - loss: 0.7897\n",
            "Epoch 13/20\n",
            "594/594 [==============================] - 1s 850us/step - loss: 0.7896\n",
            "Epoch 14/20\n",
            "594/594 [==============================] - 1s 850us/step - loss: 0.7895\n",
            "Epoch 15/20\n",
            "594/594 [==============================] - 1s 912us/step - loss: 0.7894\n",
            "Epoch 16/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7891\n",
            "Epoch 17/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7891\n",
            "Epoch 18/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7894\n",
            "Epoch 19/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7893\n",
            "Epoch 20/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7892\n",
            "149/149 [==============================] - 0s 932us/step\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.140 total time=  12.4s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8770\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8057\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 901us/step - loss: 0.8031\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 892us/step - loss: 0.8021\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 884us/step - loss: 0.8013\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 892us/step - loss: 0.8011\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 896us/step - loss: 0.8008\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 899us/step - loss: 0.8003\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 880us/step - loss: 0.8000\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 901us/step - loss: 0.7998\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 891us/step - loss: 0.7994\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7993\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7991\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7990\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7988\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7988\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7987\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7986\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7984\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 938us/step - loss: 0.7982\n",
            "149/149 [==============================] - 0s 662us/step\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.470 total time=  13.0s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 880us/step - loss: 0.9147\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 882us/step - loss: 0.8572\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 879us/step - loss: 0.8557\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 865us/step - loss: 0.8551\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 880us/step - loss: 0.8544\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 880us/step - loss: 0.8540\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 880us/step - loss: 0.8538\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8534\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8534\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8532\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8528\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 963us/step - loss: 0.8526\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 887us/step - loss: 0.8525\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 874us/step - loss: 0.8528\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 874us/step - loss: 0.8526\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 884us/step - loss: 0.8525\n",
            "149/149 [==============================] - 0s 662us/step\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.350 total time=  12.5s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 875us/step - loss: 0.9172\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 891us/step - loss: 0.8599\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 877us/step - loss: 0.8582\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 963us/step - loss: 0.8578\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8569\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8564\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8564\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8564\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 889us/step - loss: 0.8556\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 894us/step - loss: 0.8556\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 865us/step - loss: 0.8555\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 886us/step - loss: 0.8555\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 872us/step - loss: 0.8554\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 896us/step - loss: 0.8553\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 875us/step - loss: 0.8551\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 884us/step - loss: 0.8550\n",
            "149/149 [==============================] - 0s 676us/step\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.460 total time=  12.4s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7270\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6895\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6865\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6852\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6849\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6843\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6842\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6836\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 921us/step - loss: 0.6837\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 902us/step - loss: 0.6838\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 896us/step - loss: 0.6837\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 894us/step - loss: 0.6836\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 906us/step - loss: 0.6833\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 887us/step - loss: 0.6833\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 901us/step - loss: 0.6831\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 899us/step - loss: 0.6832\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 909us/step - loss: 0.6831\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 931us/step - loss: 0.6831\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6830\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6829\n",
            "149/149 [==============================] - 0s 919us/step\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.010 total time=  13.0s\n",
            "Epoch 1/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8395\n",
            "Epoch 2/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7964\n",
            "Epoch 3/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7934\n",
            "Epoch 4/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7919\n",
            "Epoch 5/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7914\n",
            "Epoch 6/20\n",
            "594/594 [==============================] - 1s 885us/step - loss: 0.7907\n",
            "Epoch 7/20\n",
            "594/594 [==============================] - 1s 867us/step - loss: 0.7904\n",
            "Epoch 8/20\n",
            "594/594 [==============================] - 1s 899us/step - loss: 0.7902\n",
            "Epoch 9/20\n",
            "594/594 [==============================] - 1s 867us/step - loss: 0.7901\n",
            "Epoch 10/20\n",
            "594/594 [==============================] - 1s 882us/step - loss: 0.7899\n",
            "Epoch 11/20\n",
            "594/594 [==============================] - 1s 870us/step - loss: 0.7896\n",
            "Epoch 12/20\n",
            "594/594 [==============================] - 1s 894us/step - loss: 0.7897\n",
            "Epoch 13/20\n",
            "594/594 [==============================] - 1s 875us/step - loss: 0.7895\n",
            "Epoch 14/20\n",
            "594/594 [==============================] - 1s 879us/step - loss: 0.7895\n",
            "Epoch 15/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7896\n",
            "Epoch 16/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7894\n",
            "Epoch 17/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7894\n",
            "Epoch 18/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7893\n",
            "Epoch 19/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7892\n",
            "Epoch 20/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7893\n",
            "149/149 [==============================] - 0s 899us/step\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.130 total time=  13.0s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 956us/step - loss: 0.8593\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 875us/step - loss: 0.8044\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 879us/step - loss: 0.8022\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 862us/step - loss: 0.8013\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 880us/step - loss: 0.8010\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 857us/step - loss: 0.8005\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 882us/step - loss: 0.8001\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 864us/step - loss: 0.7998\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 870us/step - loss: 0.7997\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 892us/step - loss: 0.7992\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7991\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7991\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7990\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7987\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7987\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7985\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7985\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7987\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 896us/step - loss: 0.7986\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 889us/step - loss: 0.7984\n",
            "149/149 [==============================] - 0s 649us/step\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.510 total time=  12.9s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 897us/step - loss: 0.9122\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 896us/step - loss: 0.8575\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 891us/step - loss: 0.8555\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 892us/step - loss: 0.8551\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 880us/step - loss: 0.8542\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 879us/step - loss: 0.8543\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8541\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8538\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8536\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8535\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8533\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8535\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8531\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8531\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 971us/step - loss: 0.8530\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 896us/step - loss: 0.8530\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 879us/step - loss: 0.8528\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 886us/step - loss: 0.8527\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 891us/step - loss: 0.8526\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 882us/step - loss: 0.8525\n",
            "149/149 [==============================] - 0s 649us/step\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.370 total time=  12.5s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 884us/step - loss: 0.9263\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 852us/step - loss: 0.8607\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 0s 838us/step - loss: 0.8585\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8578\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8576\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8573\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8568\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8566\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8558\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 941us/step - loss: 0.8555\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 864us/step - loss: 0.8556\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 872us/step - loss: 0.8555\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 0s 835us/step - loss: 0.8553\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 0s 771us/step - loss: 0.8554\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 0s 763us/step - loss: 0.8552\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 907us/step - loss: 0.8553\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 864us/step - loss: 0.8553\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 0s 790us/step - loss: 0.8551\n",
            "149/149 [==============================] - 0s 818us/step\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.410 total time=  12.1s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7250\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6881\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6858\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6849\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6845\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6842\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6839\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6839\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 892us/step - loss: 0.6837\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 864us/step - loss: 0.6836\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 879us/step - loss: 0.6832\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 882us/step - loss: 0.6833\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 879us/step - loss: 0.6835\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 867us/step - loss: 0.6832\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 877us/step - loss: 0.6830\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 901us/step - loss: 0.6834\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 872us/step - loss: 0.6831\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 874us/step - loss: 0.6832\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 870us/step - loss: 0.6832\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6829\n",
            "149/149 [==============================] - 0s 858us/step\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.010 total time=  12.7s\n",
            "Epoch 1/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8394\n",
            "Epoch 2/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7956\n",
            "Epoch 3/20\n",
            "594/594 [==============================] - 1s 966us/step - loss: 0.7927\n",
            "Epoch 4/20\n",
            "594/594 [==============================] - 1s 956us/step - loss: 0.7916\n",
            "Epoch 5/20\n",
            "594/594 [==============================] - 0s 745us/step - loss: 0.7910\n",
            "Epoch 6/20\n",
            "594/594 [==============================] - 0s 747us/step - loss: 0.7905\n",
            "Epoch 7/20\n",
            "594/594 [==============================] - 1s 912us/step - loss: 0.7903\n",
            "Epoch 8/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7901\n",
            "Epoch 9/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7899\n",
            "Epoch 10/20\n",
            "594/594 [==============================] - 1s 875us/step - loss: 0.7898\n",
            "Epoch 11/20\n",
            "594/594 [==============================] - 1s 857us/step - loss: 0.7894\n",
            "Epoch 12/20\n",
            "594/594 [==============================] - 1s 874us/step - loss: 0.7895\n",
            "Epoch 13/20\n",
            "594/594 [==============================] - 1s 858us/step - loss: 0.7894\n",
            "Epoch 14/20\n",
            "594/594 [==============================] - 0s 838us/step - loss: 0.7894\n",
            "Epoch 15/20\n",
            "594/594 [==============================] - 1s 847us/step - loss: 0.7893\n",
            "Epoch 16/20\n",
            "594/594 [==============================] - 0s 830us/step - loss: 0.7889\n",
            "Epoch 17/20\n",
            "594/594 [==============================] - 1s 848us/step - loss: 0.7890\n",
            "Epoch 18/20\n",
            "594/594 [==============================] - 1s 841us/step - loss: 0.7888\n",
            "Epoch 19/20\n",
            "594/594 [==============================] - 1s 848us/step - loss: 0.7892\n",
            "Epoch 20/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7889\n",
            "149/149 [==============================] - 0s 980us/step\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.140 total time=  11.9s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8718\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8062\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8036\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8019\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8012\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8007\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 879us/step - loss: 0.8001\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 896us/step - loss: 0.7999\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 875us/step - loss: 0.7994\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 879us/step - loss: 0.7994\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 869us/step - loss: 0.7992\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 902us/step - loss: 0.7990\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 869us/step - loss: 0.7987\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 865us/step - loss: 0.7987\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 859us/step - loss: 0.7986\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7982\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7984\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7982\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7980\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7982\n",
            "149/149 [==============================] - 0s 838us/step\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.520 total time=  12.9s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9139\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8574\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 995us/step - loss: 0.8560\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 896us/step - loss: 0.8553\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 899us/step - loss: 0.8547\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 889us/step - loss: 0.8541\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 877us/step - loss: 0.8540\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 896us/step - loss: 0.8538\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 886us/step - loss: 0.8536\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 880us/step - loss: 0.8533\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 891us/step - loss: 0.8528\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 966us/step - loss: 0.8530\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8529\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8528\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8525\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8523\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8521\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8522\n",
            "149/149 [==============================] - 0s 635us/step\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.350 total time=  13.0s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 870us/step - loss: 0.9246\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 859us/step - loss: 0.8616\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 862us/step - loss: 0.8592\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 867us/step - loss: 0.8582\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 872us/step - loss: 0.8579\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 865us/step - loss: 0.8576\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 877us/step - loss: 0.8574\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 865us/step - loss: 0.8568\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8567\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8568\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8564\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8558\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1000us/step - loss: 0.8558\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 867us/step - loss: 0.8558\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 889us/step - loss: 0.8558\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 850us/step - loss: 0.8556\n",
            "149/149 [==============================] - 0s 642us/step\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.420 total time=  12.4s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 887us/step - loss: 0.7383\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 896us/step - loss: 0.6892\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 882us/step - loss: 0.6861\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 884us/step - loss: 0.6849\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 921us/step - loss: 0.6846\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6841\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6838\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6834\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6836\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6835\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6832\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6834\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6831\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 896us/step - loss: 0.6829\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 879us/step - loss: 0.6831\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 884us/step - loss: 0.6829\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 870us/step - loss: 0.6827\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 918us/step - loss: 0.6828\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 865us/step - loss: 0.6828\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 889us/step - loss: 0.6827\n",
            "149/149 [==============================] - 0s 642us/step\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.010 total time=  12.5s\n",
            "Epoch 1/20\n",
            "594/594 [==============================] - 1s 884us/step - loss: 0.8438\n",
            "Epoch 2/20\n",
            "594/594 [==============================] - 1s 865us/step - loss: 0.7948\n",
            "Epoch 3/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7921\n",
            "Epoch 4/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7915\n",
            "Epoch 5/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7908\n",
            "Epoch 6/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7907\n",
            "Epoch 7/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7904\n",
            "Epoch 8/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7902\n",
            "Epoch 9/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7901\n",
            "Epoch 10/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7899\n",
            "Epoch 11/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7898\n",
            "Epoch 12/20\n",
            "594/594 [==============================] - 1s 885us/step - loss: 0.7896\n",
            "Epoch 13/20\n",
            "594/594 [==============================] - 1s 890us/step - loss: 0.7897\n",
            "Epoch 14/20\n",
            "594/594 [==============================] - 1s 863us/step - loss: 0.7894\n",
            "Epoch 15/20\n",
            "594/594 [==============================] - 1s 875us/step - loss: 0.7895\n",
            "Epoch 16/20\n",
            "594/594 [==============================] - 1s 872us/step - loss: 0.7895\n",
            "Epoch 17/20\n",
            "594/594 [==============================] - 1s 885us/step - loss: 0.7894\n",
            "Epoch 18/20\n",
            "594/594 [==============================] - 1s 865us/step - loss: 0.7893\n",
            "Epoch 19/20\n",
            "594/594 [==============================] - 1s 889us/step - loss: 0.7893\n",
            "Epoch 20/20\n",
            "594/594 [==============================] - 1s 872us/step - loss: 0.7895\n",
            "149/149 [==============================] - 0s 689us/step\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.120 total time=  12.4s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8696\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8055\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8033\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8024\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8017\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8013\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8008\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 929us/step - loss: 0.8001\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 901us/step - loss: 0.8000\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 897us/step - loss: 0.7998\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 896us/step - loss: 0.7994\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 886us/step - loss: 0.7994\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 887us/step - loss: 0.7992\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 891us/step - loss: 0.7992\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 892us/step - loss: 0.7991\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 914us/step - loss: 0.7989\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 981us/step - loss: 0.7989\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7987\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7988\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7987\n",
            "149/149 [==============================] - 0s 892us/step\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.470 total time=  13.4s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9207\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8579\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8558\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 933us/step - loss: 0.8551\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 880us/step - loss: 0.8546\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 865us/step - loss: 0.8543\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 894us/step - loss: 0.8538\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 867us/step - loss: 0.8537\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 879us/step - loss: 0.8534\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 879us/step - loss: 0.8534\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 877us/step - loss: 0.8534\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 864us/step - loss: 0.8531\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 960us/step - loss: 0.8530\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8529\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8528\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8528\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
            "149/149 [==============================] - 0s 791us/step\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.350 total time=  12.9s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 872us/step - loss: 0.9110\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 870us/step - loss: 0.8608\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 882us/step - loss: 0.8593\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 869us/step - loss: 0.8582\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 877us/step - loss: 0.8578\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 886us/step - loss: 0.8571\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 865us/step - loss: 0.8568\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 872us/step - loss: 0.8567\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 874us/step - loss: 0.8566\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8558\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8555\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 968us/step - loss: 0.8551\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 886us/step - loss: 0.8553\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 872us/step - loss: 0.8554\n",
            "149/149 [==============================] - 0s 676us/step\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.420 total time=  12.4s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 892us/step - loss: 0.7276\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 884us/step - loss: 0.6884\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 897us/step - loss: 0.6857\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 887us/step - loss: 0.6849\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 882us/step - loss: 0.6844\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1000us/step - loss: 0.6840\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6838\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6833\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6835\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6832\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6833\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6833\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6832\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6831\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 882us/step - loss: 0.6831\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 897us/step - loss: 0.6829\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 897us/step - loss: 0.6830\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 896us/step - loss: 0.6827\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 879us/step - loss: 0.6827\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 896us/step - loss: 0.6828\n",
            "149/149 [==============================] - 0s 682us/step\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.010 total time=  12.5s\n",
            "Epoch 1/20\n",
            "594/594 [==============================] - 1s 899us/step - loss: 0.8395\n",
            "Epoch 2/20\n",
            "594/594 [==============================] - 1s 880us/step - loss: 0.7962\n",
            "Epoch 3/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7933\n",
            "Epoch 4/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7922\n",
            "Epoch 5/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7912\n",
            "Epoch 6/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7911\n",
            "Epoch 7/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7904\n",
            "Epoch 8/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7904\n",
            "Epoch 9/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7902\n",
            "Epoch 10/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7899\n",
            "Epoch 11/20\n",
            "594/594 [==============================] - 1s 924us/step - loss: 0.7897\n",
            "Epoch 12/20\n",
            "594/594 [==============================] - 1s 877us/step - loss: 0.7896\n",
            "Epoch 13/20\n",
            "594/594 [==============================] - 1s 889us/step - loss: 0.7895\n",
            "Epoch 14/20\n",
            "594/594 [==============================] - 1s 868us/step - loss: 0.7896\n",
            "Epoch 15/20\n",
            "594/594 [==============================] - 1s 879us/step - loss: 0.7893\n",
            "Epoch 16/20\n",
            "594/594 [==============================] - 1s 884us/step - loss: 0.7893\n",
            "Epoch 17/20\n",
            "594/594 [==============================] - 1s 902us/step - loss: 0.7893\n",
            "Epoch 18/20\n",
            "594/594 [==============================] - 1s 879us/step - loss: 0.7893\n",
            "Epoch 19/20\n",
            "594/594 [==============================] - 1s 875us/step - loss: 0.7892\n",
            "Epoch 20/20\n",
            "594/594 [==============================] - 1s 981us/step - loss: 0.7892\n",
            "149/149 [==============================] - 0s 865us/step\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.150 total time=  12.5s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8650\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 968us/step - loss: 0.8050\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8034\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8023\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8016\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8007\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 949us/step - loss: 0.8003\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 848us/step - loss: 0.8000\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 0s 822us/step - loss: 0.7998\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 845us/step - loss: 0.7993\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 0s 837us/step - loss: 0.7995\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 842us/step - loss: 0.7991\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 0s 832us/step - loss: 0.7990\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 862us/step - loss: 0.7988\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 0s 805us/step - loss: 0.7989\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 840us/step - loss: 0.7988\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 843us/step - loss: 0.7988\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 997us/step - loss: 0.7985\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7986\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 993us/step - loss: 0.7982\n",
            "149/149 [==============================] - 0s 662us/step\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.480 total time=  11.6s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9084\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8571\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8551\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 929us/step - loss: 0.8547\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 880us/step - loss: 0.8545\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 865us/step - loss: 0.8543\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 877us/step - loss: 0.8538\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 850us/step - loss: 0.8536\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 906us/step - loss: 0.8533\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 869us/step - loss: 0.8533\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 880us/step - loss: 0.8528\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 860us/step - loss: 0.8528\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 955us/step - loss: 0.8528\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8527\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8525\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8525\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
            "149/149 [==============================] - 0s 851us/step\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.350 total time=  13.1s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 976us/step - loss: 0.9237\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 891us/step - loss: 0.8620\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 891us/step - loss: 0.8595\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 887us/step - loss: 0.8584\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 912us/step - loss: 0.8581\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 907us/step - loss: 0.8575\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 887us/step - loss: 0.8570\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 884us/step - loss: 0.8567\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 894us/step - loss: 0.8563\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 960us/step - loss: 0.8563\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8559\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8553\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8552\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 914us/step - loss: 0.8553\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 894us/step - loss: 0.8552\n",
            "149/149 [==============================] - 0s 635us/step\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.410 total time=  12.7s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 892us/step - loss: 0.7227\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 862us/step - loss: 0.6878\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 869us/step - loss: 0.6858\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 886us/step - loss: 0.6855\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 872us/step - loss: 0.6852\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 872us/step - loss: 0.6849\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 860us/step - loss: 0.6845\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 887us/step - loss: 0.6844\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 872us/step - loss: 0.6841\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6842\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6836\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6837\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6835\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6835\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6834\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6834\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6833\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 948us/step - loss: 0.6833\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 867us/step - loss: 0.6832\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 875us/step - loss: 0.6833\n",
            "149/149 [==============================] - 0s 628us/step\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.010 total time=  12.4s\n",
            "Epoch 1/20\n",
            "594/594 [==============================] - 1s 865us/step - loss: 0.8309\n",
            "Epoch 2/20\n",
            "594/594 [==============================] - 1s 895us/step - loss: 0.7953\n",
            "Epoch 3/20\n",
            "594/594 [==============================] - 1s 863us/step - loss: 0.7927\n",
            "Epoch 4/20\n",
            "594/594 [==============================] - 1s 882us/step - loss: 0.7920\n",
            "Epoch 5/20\n",
            "594/594 [==============================] - 1s 879us/step - loss: 0.7913\n",
            "Epoch 6/20\n",
            "594/594 [==============================] - 1s 978us/step - loss: 0.7906\n",
            "Epoch 7/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7906\n",
            "Epoch 8/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7903\n",
            "Epoch 9/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7899\n",
            "Epoch 10/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7899\n",
            "Epoch 11/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7897\n",
            "Epoch 12/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7895\n",
            "Epoch 13/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7896\n",
            "Epoch 14/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7896\n",
            "Epoch 15/20\n",
            "594/594 [==============================] - 1s 879us/step - loss: 0.7894\n",
            "Epoch 16/20\n",
            "594/594 [==============================] - 1s 841us/step - loss: 0.7893\n",
            "Epoch 17/20\n",
            "594/594 [==============================] - 1s 860us/step - loss: 0.7894\n",
            "Epoch 18/20\n",
            "594/594 [==============================] - 1s 860us/step - loss: 0.7893\n",
            "Epoch 19/20\n",
            "594/594 [==============================] - 1s 858us/step - loss: 0.7893\n",
            "Epoch 20/20\n",
            "594/594 [==============================] - 1s 858us/step - loss: 0.7889\n",
            "149/149 [==============================] - 0s 649us/step\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.130 total time=  12.2s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 886us/step - loss: 0.8712\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 899us/step - loss: 0.8057\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8032\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8024\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8017\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8012\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8007\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8003\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7998\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7997\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7995\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 906us/step - loss: 0.7996\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 889us/step - loss: 0.7992\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 891us/step - loss: 0.7989\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 891us/step - loss: 0.7990\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 894us/step - loss: 0.7987\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 891us/step - loss: 0.7987\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 892us/step - loss: 0.7986\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 892us/step - loss: 0.7986\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 891us/step - loss: 0.7983\n",
            "149/149 [==============================] - 0s 939us/step\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.450 total time=  12.7s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9144\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 993us/step - loss: 0.8570\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8559\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8547\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8545\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8541\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 904us/step - loss: 0.8539\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 887us/step - loss: 0.8536\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 907us/step - loss: 0.8534\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 901us/step - loss: 0.8530\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 877us/step - loss: 0.8534\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 906us/step - loss: 0.8530\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 880us/step - loss: 0.8527\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 894us/step - loss: 0.8528\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 892us/step - loss: 0.8526\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8525\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8528\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8524\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.350 total time=  13.2s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9166\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8607\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8591\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 894us/step - loss: 0.8583\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 914us/step - loss: 0.8575\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 899us/step - loss: 0.8571\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 892us/step - loss: 0.8570\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 901us/step - loss: 0.8566\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 901us/step - loss: 0.8563\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 892us/step - loss: 0.8563\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 875us/step - loss: 0.8559\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 894us/step - loss: 0.8557\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8555\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8551\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8549\n",
            "149/149 [==============================] - 0s 777us/step\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.390 total time=  13.2s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 887us/step - loss: 0.7316\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 882us/step - loss: 0.6882\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 906us/step - loss: 0.6859\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 884us/step - loss: 0.6854\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 891us/step - loss: 0.6850\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 897us/step - loss: 0.6843\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 886us/step - loss: 0.6841\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 892us/step - loss: 0.6840\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 897us/step - loss: 0.6837\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6838\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6838\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6838\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6837\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6833\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6835\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6833\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6835\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 877us/step - loss: 0.6833\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 894us/step - loss: 0.6830\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 882us/step - loss: 0.6830\n",
            "149/149 [==============================] - 0s 642us/step\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.010 total time=  12.6s\n",
            "Epoch 1/20\n",
            "594/594 [==============================] - 1s 847us/step - loss: 0.8424\n",
            "Epoch 2/20\n",
            "594/594 [==============================] - 1s 879us/step - loss: 0.7960\n",
            "Epoch 3/20\n",
            "594/594 [==============================] - 1s 865us/step - loss: 0.7932\n",
            "Epoch 4/20\n",
            "594/594 [==============================] - 1s 863us/step - loss: 0.7920\n",
            "Epoch 5/20\n",
            "594/594 [==============================] - 1s 843us/step - loss: 0.7915\n",
            "Epoch 6/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7909\n",
            "Epoch 7/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7907\n",
            "Epoch 8/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7904\n",
            "Epoch 9/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7901\n",
            "Epoch 10/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7900\n",
            "Epoch 11/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7897\n",
            "Epoch 12/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7898\n",
            "Epoch 13/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7893\n",
            "Epoch 14/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7897\n",
            "Epoch 15/20\n",
            "594/594 [==============================] - 1s 882us/step - loss: 0.7894\n",
            "Epoch 16/20\n",
            "594/594 [==============================] - 1s 890us/step - loss: 0.7892\n",
            "Epoch 17/20\n",
            "594/594 [==============================] - 1s 860us/step - loss: 0.7893\n",
            "Epoch 18/20\n",
            "594/594 [==============================] - 1s 867us/step - loss: 0.7892\n",
            "Epoch 19/20\n",
            "594/594 [==============================] - 1s 867us/step - loss: 0.7890\n",
            "Epoch 20/20\n",
            "594/594 [==============================] - 1s 858us/step - loss: 0.7892\n",
            "149/149 [==============================] - 0s 709us/step\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.110 total time=  12.3s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 907us/step - loss: 0.8657\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 924us/step - loss: 0.8048\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8027\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8021\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8012\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8007\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8007\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8001\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7999\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7998\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 983us/step - loss: 0.7994\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 882us/step - loss: 0.7994\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 897us/step - loss: 0.7991\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 886us/step - loss: 0.7992\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 896us/step - loss: 0.7990\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 884us/step - loss: 0.7989\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 889us/step - loss: 0.7989\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 877us/step - loss: 0.7987\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 926us/step - loss: 0.7986\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 990us/step - loss: 0.7985\n",
            "149/149 [==============================] - 0s 885us/step\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.500 total time=  12.7s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9154\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8578\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8558\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8553\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 0s 806us/step - loss: 0.8548\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 902us/step - loss: 0.8545\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8544\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8541\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 981us/step - loss: 0.8538\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 870us/step - loss: 0.8539\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 901us/step - loss: 0.8535\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 884us/step - loss: 0.8533\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 884us/step - loss: 0.8531\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 929us/step - loss: 0.8532\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 891us/step - loss: 0.8533\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 889us/step - loss: 0.8530\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 887us/step - loss: 0.8528\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8528\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
            "149/149 [==============================] - 0s 932us/step\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.420 total time=  12.9s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9121\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8606\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8589\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8582\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8578\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 891us/step - loss: 0.8574\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 892us/step - loss: 0.8568\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 904us/step - loss: 0.8566\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 929us/step - loss: 0.8563\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 884us/step - loss: 0.8561\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 897us/step - loss: 0.8558\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 897us/step - loss: 0.8557\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 894us/step - loss: 0.8556\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 882us/step - loss: 0.8557\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8553\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8555\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8553\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8551\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8549\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8550\n",
            "149/149 [==============================] - 0s 973us/step\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.410 total time=  13.1s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7325\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 904us/step - loss: 0.6886\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 884us/step - loss: 0.6862\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 918us/step - loss: 0.6853\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 896us/step - loss: 0.6846\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 944us/step - loss: 0.6844\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 924us/step - loss: 0.6841\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 906us/step - loss: 0.6839\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 914us/step - loss: 0.6839\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 901us/step - loss: 0.6837\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6835\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6834\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6833\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6834\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6832\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6833\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6831\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6831\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 919us/step - loss: 0.6832\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 923us/step - loss: 0.6832\n",
            "149/149 [==============================] - 0s 696us/step\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.010 total time=  12.9s\n",
            "Epoch 1/20\n",
            "594/594 [==============================] - 1s 995us/step - loss: 0.8230\n",
            "Epoch 2/20\n",
            "594/594 [==============================] - 1s 985us/step - loss: 0.7950\n",
            "Epoch 3/20\n",
            "594/594 [==============================] - 1s 998us/step - loss: 0.7930\n",
            "Epoch 4/20\n",
            "594/594 [==============================] - 1s 992us/step - loss: 0.7922\n",
            "Epoch 5/20\n",
            "594/594 [==============================] - 1s 995us/step - loss: 0.7913\n",
            "Epoch 6/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7908\n",
            "Epoch 7/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7907\n",
            "Epoch 8/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7910\n",
            "Epoch 9/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7905\n",
            "Epoch 10/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7904\n",
            "Epoch 11/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7901\n",
            "Epoch 12/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7901\n",
            "Epoch 13/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7901\n",
            "Epoch 14/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7902\n",
            "Epoch 15/20\n",
            "594/594 [==============================] - 1s 985us/step - loss: 0.7901\n",
            "Epoch 16/20\n",
            "594/594 [==============================] - 1s 971us/step - loss: 0.7901\n",
            "Epoch 17/20\n",
            "594/594 [==============================] - 1s 987us/step - loss: 0.7901\n",
            "Epoch 18/20\n",
            "594/594 [==============================] - 1s 997us/step - loss: 0.7898\n",
            "Epoch 19/20\n",
            "594/594 [==============================] - 1s 997us/step - loss: 0.7898\n",
            "Epoch 20/20\n",
            "594/594 [==============================] - 1s 986us/step - loss: 0.7898\n",
            "149/149 [==============================] - 0s 709us/step\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.080 total time=  13.9s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8471\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8062\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8039\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8023\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8014\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8009\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8004\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8000\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8001\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7995\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7997\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7994\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7995\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7990\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7991\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7991\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.470 total time=  15.3s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8886\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8586\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8569\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8550\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8547\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8542\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8540\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8536\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8537\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8533\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8532\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8532\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8529\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8525\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8524\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 956us/step - loss: 0.8524\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 998us/step - loss: 0.8525\n",
            "149/149 [==============================] - 0s 743us/step\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.350 total time=  14.6s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8997\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8609\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8595\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8583\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8578\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8570\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8567\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8567\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8559\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8559\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8558\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8555\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
            "149/149 [==============================] - 0s 953us/step\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.410 total time=  14.7s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 2s 1ms/step - loss: 0.7110\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6882\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6867\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6861\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6851\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6853\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6849\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6845\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6845\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6846\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6843\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6843\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6843\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6837\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6840\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6841\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6838\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6838\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6836\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6835\n",
            "149/149 [==============================] - 0s 784us/step\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.010 total time=  15.9s\n",
            "Epoch 1/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8237\n",
            "Epoch 2/20\n",
            "594/594 [==============================] - 1s 992us/step - loss: 0.7951\n",
            "Epoch 3/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7931\n",
            "Epoch 4/20\n",
            "594/594 [==============================] - 1s 998us/step - loss: 0.7923\n",
            "Epoch 5/20\n",
            "594/594 [==============================] - 1s 980us/step - loss: 0.7914\n",
            "Epoch 6/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7909\n",
            "Epoch 7/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7908\n",
            "Epoch 8/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7907\n",
            "Epoch 9/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7903\n",
            "Epoch 10/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7901\n",
            "Epoch 11/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7900\n",
            "Epoch 12/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7901\n",
            "Epoch 13/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7898\n",
            "Epoch 14/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7896\n",
            "Epoch 15/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7899\n",
            "Epoch 16/20\n",
            "594/594 [==============================] - 1s 988us/step - loss: 0.7894\n",
            "Epoch 17/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7898\n",
            "Epoch 18/20\n",
            "594/594 [==============================] - 1s 987us/step - loss: 0.7896\n",
            "Epoch 19/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7894\n",
            "Epoch 20/20\n",
            "594/594 [==============================] - 1s 983us/step - loss: 0.7894\n",
            "149/149 [==============================] - 0s 730us/step\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.100 total time=  14.0s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8394\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8049\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8031\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8023\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8014\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8010\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8009\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8001\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 993us/step - loss: 0.8003\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 998us/step - loss: 0.7999\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7996\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7993\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 998us/step - loss: 0.7992\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7994\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 997us/step - loss: 0.7994\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7993\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7989\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7989\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7990\n",
            "149/149 [==============================] - 0s 953us/step\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.500 total time=  15.1s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8890\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8583\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 980us/step - loss: 0.8569\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 963us/step - loss: 0.8558\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 975us/step - loss: 0.8550\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 966us/step - loss: 0.8548\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 973us/step - loss: 0.8543\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 980us/step - loss: 0.8542\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 981us/step - loss: 0.8539\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8539\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8535\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8534\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8535\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8533\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8533\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8529\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8531\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8531\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8529\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8529\n",
            "149/149 [==============================] - 0s 689us/step\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.340 total time=  13.8s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8931\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8612\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8597\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8585\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8576\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8572\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8571\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8566\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8566\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8559\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8558\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1000us/step - loss: 0.8558\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8558\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8558\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
            "149/149 [==============================] - 0s 980us/step\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.420 total time=  14.4s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7156\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6879\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6869\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6861\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6855\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6854\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6848\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6848\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6848\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6845\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6844\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6843\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 998us/step - loss: 0.6843\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6843\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6841\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6841\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6839\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6838\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6838\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6838\n",
            "149/149 [==============================] - 0s 905us/step\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.010 total time=  15.5s\n",
            "Epoch 1/20\n",
            "594/594 [==============================] - 1s 990us/step - loss: 0.8190\n",
            "Epoch 2/20\n",
            "594/594 [==============================] - 1s 993us/step - loss: 0.7942\n",
            "Epoch 3/20\n",
            "594/594 [==============================] - 1s 993us/step - loss: 0.7923\n",
            "Epoch 4/20\n",
            "594/594 [==============================] - 1s 995us/step - loss: 0.7918\n",
            "Epoch 5/20\n",
            "594/594 [==============================] - 1s 998us/step - loss: 0.7912\n",
            "Epoch 6/20\n",
            "594/594 [==============================] - 1s 980us/step - loss: 0.7910\n",
            "Epoch 7/20\n",
            "594/594 [==============================] - 1s 993us/step - loss: 0.7906\n",
            "Epoch 8/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7905\n",
            "Epoch 9/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7900\n",
            "Epoch 10/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7901\n",
            "Epoch 11/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7901\n",
            "Epoch 12/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7897\n",
            "Epoch 13/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7899\n",
            "Epoch 14/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7897\n",
            "Epoch 15/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7897\n",
            "Epoch 16/20\n",
            "594/594 [==============================] - 1s 992us/step - loss: 0.7898\n",
            "Epoch 17/20\n",
            "594/594 [==============================] - 1s 970us/step - loss: 0.7896\n",
            "Epoch 18/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7897\n",
            "Epoch 19/20\n",
            "594/594 [==============================] - 1s 978us/step - loss: 0.7895\n",
            "Epoch 20/20\n",
            "594/594 [==============================] - 1s 990us/step - loss: 0.7894\n",
            "149/149 [==============================] - 0s 723us/step\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.130 total time=  13.8s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 995us/step - loss: 0.8452\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8051\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8033\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8022\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8012\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8007\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8005\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8002\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7999\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7996\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7991\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 995us/step - loss: 0.7991\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 997us/step - loss: 0.7992\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7988\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7987\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7988\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7985\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7987\n",
            "149/149 [==============================] - 0s 986us/step\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.470 total time=  14.8s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8944\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8589\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8566\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8558\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 983us/step - loss: 0.8550\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 995us/step - loss: 0.8548\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 998us/step - loss: 0.8543\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8540\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 995us/step - loss: 0.8539\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 997us/step - loss: 0.8536\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 992us/step - loss: 0.8534\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8534\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8534\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8532\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8531\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8527\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8529\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 988us/step - loss: 0.8527\n",
            "149/149 [==============================] - 0s 757us/step\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.370 total time=  14.5s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9024\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8615\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8599\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8590\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8580\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8575\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 998us/step - loss: 0.8569\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8565\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8566\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8559\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8555\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1000us/step - loss: 0.8556\n",
            "149/149 [==============================] - 0s 709us/step\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.410 total time=  14.1s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7186\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6879\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6867\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6861\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6852\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6854\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6847\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6847\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6844\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6844\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6839\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6842\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6837\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 993us/step - loss: 0.6838\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6840\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6837\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6836\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6834\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6836\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6834\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.010 total time=  14.7s\n",
            "Epoch 1/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8249\n",
            "Epoch 2/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7949\n",
            "Epoch 3/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7930\n",
            "Epoch 4/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7922\n",
            "Epoch 5/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7915\n",
            "Epoch 6/20\n",
            "594/594 [==============================] - 1s 983us/step - loss: 0.7907\n",
            "Epoch 7/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7908\n",
            "Epoch 8/20\n",
            "594/594 [==============================] - 1s 981us/step - loss: 0.7904\n",
            "Epoch 9/20\n",
            "594/594 [==============================] - 1s 987us/step - loss: 0.7900\n",
            "Epoch 10/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7898\n",
            "Epoch 11/20\n",
            "594/594 [==============================] - 1s 975us/step - loss: 0.7899\n",
            "Epoch 12/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7896\n",
            "Epoch 13/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7895\n",
            "Epoch 14/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7897\n",
            "Epoch 15/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7896\n",
            "Epoch 16/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7894\n",
            "Epoch 17/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7894\n",
            "Epoch 18/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7896\n",
            "Epoch 19/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7894\n",
            "Epoch 20/20\n",
            "594/594 [==============================] - 1s 983us/step - loss: 0.7896\n",
            "149/149 [==============================] - 0s 696us/step\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.120 total time=  14.6s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8398\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8056\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8034\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 992us/step - loss: 0.8023\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8018\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8005\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8004\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7997\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7999\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7997\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7996\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7993\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7993\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 995us/step - loss: 0.7990\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7990\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 998us/step - loss: 0.7987\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7986\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7985\n",
            "149/149 [==============================] - 0s 743us/step\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.510 total time=  14.2s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8898\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8577\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8566\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8553\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8549\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8543\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8540\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8535\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8537\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8533\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 997us/step - loss: 0.8532\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8533\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8529\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8529\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8527\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8525\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8528\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8527\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8525\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.370 total time=  14.9s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8981\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8609\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8592\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1000us/step - loss: 0.8582\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8575\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8572\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8569\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8563\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8563\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 998us/step - loss: 0.8562\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 992us/step - loss: 0.8561\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8558\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8558\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8555\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8555\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8553\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1000us/step - loss: 0.8554\n",
            "149/149 [==============================] - 0s 682us/step\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.450 total time=  14.8s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7165\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6883\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6869\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 993us/step - loss: 0.6861\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6859\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6856\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6852\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6850\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6847\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6844\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6841\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6841\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6838\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6840\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 993us/step - loss: 0.6838\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6838\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6837\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6840\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6839\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6837\n",
            "149/149 [==============================] - 0s 736us/step\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.010 total time=  14.1s\n",
            "Epoch 1/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8279\n",
            "Epoch 2/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7946\n",
            "Epoch 3/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7925\n",
            "Epoch 4/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7918\n",
            "Epoch 5/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7915\n",
            "Epoch 6/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7910\n",
            "Epoch 7/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7907\n",
            "Epoch 8/20\n",
            "594/594 [==============================] - 1s 998us/step - loss: 0.7906\n",
            "Epoch 9/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7906\n",
            "Epoch 10/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7904\n",
            "Epoch 11/20\n",
            "594/594 [==============================] - 1s 987us/step - loss: 0.7901\n",
            "Epoch 12/20\n",
            "594/594 [==============================] - 1s 1000us/step - loss: 0.7903\n",
            "Epoch 13/20\n",
            "594/594 [==============================] - 1s 990us/step - loss: 0.7902\n",
            "Epoch 14/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7900\n",
            "Epoch 15/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7901\n",
            "Epoch 16/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7902\n",
            "Epoch 17/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7898\n",
            "Epoch 18/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7897\n",
            "Epoch 19/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7897\n",
            "Epoch 20/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7897\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.140 total time=  14.9s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8418\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8062\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8037\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 997us/step - loss: 0.8025\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8016\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8013\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8010\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 995us/step - loss: 0.8002\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8001\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7998\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7998\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7994\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7991\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7991\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7993\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7989\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7988\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 995us/step - loss: 0.7992\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7988\n",
            "149/149 [==============================] - 0s 757us/step\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.480 total time=  14.3s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8911\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8589\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 997us/step - loss: 0.8571\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8555\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8547\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8545\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8544\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8540\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8537\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8537\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8534\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1000us/step - loss: 0.8532\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8534\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 992us/step - loss: 0.8530\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8528\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8529\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8529\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8527\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8529\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.370 total time=  14.2s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8959\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8608\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8593\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8584\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8581\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8571\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8570\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8567\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 997us/step - loss: 0.8565\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1000us/step - loss: 0.8563\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8558\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8555\n",
            "149/149 [==============================] - 0s 736us/step\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.420 total time=  15.2s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7109\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6882\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6868\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6858\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6856\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6853\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6853\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6846\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6844\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6844\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6843\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6842\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6841\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6839\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6838\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6837\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6831\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6837\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6833\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6835\n",
            "149/149 [==============================] - 0s 709us/step\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.010 total time=  14.2s\n",
            "Epoch 1/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8228\n",
            "Epoch 2/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7951\n",
            "Epoch 3/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7932\n",
            "Epoch 4/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7925\n",
            "Epoch 5/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7912\n",
            "Epoch 6/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7912\n",
            "Epoch 7/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7909\n",
            "Epoch 8/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7906\n",
            "Epoch 9/20\n",
            "594/594 [==============================] - 1s 1000us/step - loss: 0.7905\n",
            "Epoch 10/20\n",
            "594/594 [==============================] - 1s 993us/step - loss: 0.7904\n",
            "Epoch 11/20\n",
            "594/594 [==============================] - 1s 988us/step - loss: 0.7903\n",
            "Epoch 12/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7900\n",
            "Epoch 13/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7901\n",
            "Epoch 14/20\n",
            "594/594 [==============================] - 1s 987us/step - loss: 0.7901\n",
            "Epoch 15/20\n",
            "594/594 [==============================] - 1s 997us/step - loss: 0.7899\n",
            "Epoch 16/20\n",
            "594/594 [==============================] - 1s 988us/step - loss: 0.7901\n",
            "Epoch 17/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7900\n",
            "Epoch 18/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7895\n",
            "Epoch 19/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7896\n",
            "Epoch 20/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7895\n",
            "149/149 [==============================] - 0s 973us/step\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.140 total time=  14.8s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8478\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8054\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8038\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8023\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8015\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8011\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8007\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8001\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8001\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7998\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7995\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7997\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7996\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7991\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7988\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7990\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7990\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7991\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7985\n",
            "149/149 [==============================] - 0s 730us/step\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.520 total time=  14.8s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8914\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8584\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8573\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8559\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8550\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8541\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8544\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8540\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8538\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8535\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8534\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 928us/step - loss: 0.8532\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 891us/step - loss: 0.8532\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 978us/step - loss: 0.8530\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8528\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8529\n",
            "149/149 [==============================] - 0s 730us/step\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.350 total time=  14.1s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8978\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8614\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8592\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8587\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8579\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8576\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8571\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8569\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8564\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8563\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8559\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8559\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8558\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8555\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
            "149/149 [==============================] - 0s 912us/step\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.420 total time=  15.1s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 2s 1ms/step - loss: 0.7189\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6880\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1000us/step - loss: 0.6869\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6860\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6859\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6856\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6849\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 995us/step - loss: 0.6848\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6845\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6844\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6845\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6840\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6841\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6841\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6839\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6841\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6840\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6838\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6838\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6840\n",
            "149/149 [==============================] - 0s 743us/step\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.010 total time=  15.0s\n",
            "Epoch 1/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8268\n",
            "Epoch 2/20\n",
            "594/594 [==============================] - 1s 1000us/step - loss: 0.7949\n",
            "Epoch 3/20\n",
            "594/594 [==============================] - 1s 987us/step - loss: 0.7926\n",
            "Epoch 4/20\n",
            "594/594 [==============================] - 1s 981us/step - loss: 0.7918\n",
            "Epoch 5/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7914\n",
            "Epoch 6/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7909\n",
            "Epoch 7/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7907\n",
            "Epoch 8/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7903\n",
            "Epoch 9/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7903\n",
            "Epoch 10/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7898\n",
            "Epoch 11/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7901\n",
            "Epoch 12/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7899\n",
            "Epoch 13/20\n",
            "594/594 [==============================] - 1s 993us/step - loss: 0.7897\n",
            "Epoch 14/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7898\n",
            "Epoch 15/20\n",
            "594/594 [==============================] - 1s 987us/step - loss: 0.7898\n",
            "Epoch 16/20\n",
            "594/594 [==============================] - 1s 997us/step - loss: 0.7897\n",
            "Epoch 17/20\n",
            "594/594 [==============================] - 1s 985us/step - loss: 0.7895\n",
            "Epoch 18/20\n",
            "594/594 [==============================] - 1s 998us/step - loss: 0.7897\n",
            "Epoch 19/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7898\n",
            "Epoch 20/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7898\n",
            "149/149 [==============================] - 0s 919us/step\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.110 total time=  14.0s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8399\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8061\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8036\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8022\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8015\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8011\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8005\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8003\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7999\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1000us/step - loss: 0.7996\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7995\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7993\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7990\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7994\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7991\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7991\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7990\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7991\n",
            "149/149 [==============================] - 0s 777us/step\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.460 total time=  15.1s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8967\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 993us/step - loss: 0.8581\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 997us/step - loss: 0.8557\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8551\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8542\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8540\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8539\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8535\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8535\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8534\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8533\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8531\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8532\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8529\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8525\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8528\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8526\n",
            "149/149 [==============================] - 0s 696us/step\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.300 total time=  14.0s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8900\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 997us/step - loss: 0.8615\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8595\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8586\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8580\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8571\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8569\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8567\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8564\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1000us/step - loss: 0.8562\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 990us/step - loss: 0.8556\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1000us/step - loss: 0.8558\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8555\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8551\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8552\n",
            "149/149 [==============================] - 0s 939us/step\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.410 total time=  14.6s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7129\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6885\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6871\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6862\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6859\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6855\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1000us/step - loss: 0.6849\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6851\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6845\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 998us/step - loss: 0.6846\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6845\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6842\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6841\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6842\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6843\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6840\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6840\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6841\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6840\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6841\n",
            "149/149 [==============================] - 0s 709us/step\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.010 total time=  14.9s\n",
            "Epoch 1/20\n",
            "594/594 [==============================] - 1s 993us/step - loss: 0.8233\n",
            "Epoch 2/20\n",
            "594/594 [==============================] - 1s 985us/step - loss: 0.7953\n",
            "Epoch 3/20\n",
            "594/594 [==============================] - 1s 993us/step - loss: 0.7938\n",
            "Epoch 4/20\n",
            "594/594 [==============================] - 1s 976us/step - loss: 0.7923\n",
            "Epoch 5/20\n",
            "594/594 [==============================] - 1s 985us/step - loss: 0.7919\n",
            "Epoch 6/20\n",
            "594/594 [==============================] - 1s 998us/step - loss: 0.7914\n",
            "Epoch 7/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7906\n",
            "Epoch 8/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7904\n",
            "Epoch 9/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7903\n",
            "Epoch 10/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7903\n",
            "Epoch 11/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7902\n",
            "Epoch 12/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7904\n",
            "Epoch 13/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7902\n",
            "Epoch 14/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7900\n",
            "Epoch 15/20\n",
            "594/594 [==============================] - 1s 988us/step - loss: 0.7897\n",
            "Epoch 16/20\n",
            "594/594 [==============================] - 1s 988us/step - loss: 0.7901\n",
            "Epoch 17/20\n",
            "594/594 [==============================] - 1s 997us/step - loss: 0.7900\n",
            "Epoch 18/20\n",
            "594/594 [==============================] - 1s 990us/step - loss: 0.7900\n",
            "Epoch 19/20\n",
            "594/594 [==============================] - 1s 993us/step - loss: 0.7900\n",
            "Epoch 20/20\n",
            "594/594 [==============================] - 1s 981us/step - loss: 0.7900\n",
            "149/149 [==============================] - 0s 709us/step\n",
            "[CV 1/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.090 total time=  13.8s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8380\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8053\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8033\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8019\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8016\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8009\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8003\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8006\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7999\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7996\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7993\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7991\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7988\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7988\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7988\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7987\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7988\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7986\n",
            "149/149 [==============================] - 0s 757us/step\n",
            "[CV 2/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.470 total time=  14.9s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8950\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8590\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8571\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 998us/step - loss: 0.8561\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 998us/step - loss: 0.8556\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8549\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 997us/step - loss: 0.8545\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8543\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8537\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1000us/step - loss: 0.8539\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8536\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8532\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8532\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8532\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8531\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8528\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8529\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8528\n",
            "149/149 [==============================] - 0s 709us/step\n",
            "[CV 3/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.300 total time=  14.5s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9017\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8615\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8599\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8586\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8581\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8578\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8570\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8569\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8567\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8565\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8566\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8565\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 918us/step - loss: 0.8557\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 914us/step - loss: 0.8560\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 923us/step - loss: 0.8559\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 911us/step - loss: 0.8558\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 968us/step - loss: 0.8558\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
            "149/149 [==============================] - 0s 716us/step\n",
            "[CV 4/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.420 total time=  14.3s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7152\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6880\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6866\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6863\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6858\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6854\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6850\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6846\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 997us/step - loss: 0.6846\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6844\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6844\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 997us/step - loss: 0.6843\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6842\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6840\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6840\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6839\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6841\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6840\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6840\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6842\n",
            "149/149 [==============================] - 0s 993us/step\n",
            "[CV 5/5] END activation_func=relu, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.010 total time=  15.1s\n",
            "Epoch 1/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9546\n",
            "Epoch 2/5\n",
            "594/594 [==============================] - 1s 936us/step - loss: 0.8764\n",
            "Epoch 3/5\n",
            "594/594 [==============================] - 1s 911us/step - loss: 0.8367\n",
            "Epoch 4/5\n",
            "594/594 [==============================] - 1s 899us/step - loss: 0.8180\n",
            "Epoch 5/5\n",
            "594/594 [==============================] - 1s 906us/step - loss: 0.8086\n",
            "149/149 [==============================] - 0s 689us/step\n",
            "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.080 total time=   3.5s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 907us/step - loss: 1.0125\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 955us/step - loss: 0.9215\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 914us/step - loss: 0.8585\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 919us/step - loss: 0.8281\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8136\n",
            "149/149 [==============================] - 0s 993us/step\n",
            "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.480 total time=   3.6s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0619\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9560\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8937\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8729\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8650\n",
            "149/149 [==============================] - 0s 750us/step\n",
            "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.300 total time=   4.2s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 914us/step - loss: 1.0590\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 911us/step - loss: 0.9621\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 901us/step - loss: 0.9025\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 918us/step - loss: 0.8797\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 916us/step - loss: 0.8702\n",
            "149/149 [==============================] - 0s 709us/step\n",
            "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.410 total time=   3.2s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 921us/step - loss: 0.8807\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 918us/step - loss: 0.7666\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7195\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6999\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6929\n",
            "149/149 [==============================] - 0s 851us/step\n",
            "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.000 total time=   3.8s\n",
            "Epoch 1/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9491\n",
            "Epoch 2/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8729\n",
            "Epoch 3/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8334\n",
            "Epoch 4/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8168\n",
            "Epoch 5/5\n",
            "594/594 [==============================] - 1s 852us/step - loss: 0.8080\n",
            "149/149 [==============================] - 0s 615us/step\n",
            "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.080 total time=   4.0s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 911us/step - loss: 1.0071\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 933us/step - loss: 0.9183\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 960us/step - loss: 0.8581\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 931us/step - loss: 0.8289\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 918us/step - loss: 0.8140\n",
            "149/149 [==============================] - 0s 676us/step\n",
            "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.460 total time=   3.3s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 916us/step - loss: 1.0627\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 912us/step - loss: 0.9593\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8948\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8743\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8663\n",
            "149/149 [==============================] - 0s 946us/step\n",
            "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.300 total time=   3.8s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0633\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9691\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9045\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 993us/step - loss: 0.8799\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 943us/step - loss: 0.8698\n",
            "149/149 [==============================] - 0s 709us/step\n",
            "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.420 total time=   4.0s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 951us/step - loss: 0.8789\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 902us/step - loss: 0.7713\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 909us/step - loss: 0.7220\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 912us/step - loss: 0.7022\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 911us/step - loss: 0.6947\n",
            "149/149 [==============================] - 0s 655us/step\n",
            "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.000 total time=   3.3s\n",
            "Epoch 1/5\n",
            "594/594 [==============================] - 1s 916us/step - loss: 0.9541\n",
            "Epoch 2/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8773\n",
            "Epoch 3/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8351\n",
            "Epoch 4/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8170\n",
            "Epoch 5/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8081\n",
            "149/149 [==============================] - 0s 919us/step\n",
            "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.080 total time=   4.0s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0102\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9229\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8606\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 944us/step - loss: 0.8311\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 921us/step - loss: 0.8163\n",
            "149/149 [==============================] - 0s 676us/step\n",
            "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.460 total time=   3.9s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 923us/step - loss: 1.0666\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 928us/step - loss: 0.9684\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 916us/step - loss: 0.8995\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 928us/step - loss: 0.8751\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 921us/step - loss: 0.8657\n",
            "149/149 [==============================] - 0s 682us/step\n",
            "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.300 total time=   3.3s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0624\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9669\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9027\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8783\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8692\n",
            "149/149 [==============================] - 0s 973us/step\n",
            "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.380 total time=   4.3s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8802\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7706\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 957us/step - loss: 0.7234\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 966us/step - loss: 0.7022\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 963us/step - loss: 0.6944\n",
            "149/149 [==============================] - 0s 716us/step\n",
            "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.000 total time=   3.8s\n",
            "Epoch 1/5\n",
            "594/594 [==============================] - 1s 971us/step - loss: 0.9578\n",
            "Epoch 2/5\n",
            "594/594 [==============================] - 1s 956us/step - loss: 0.8785\n",
            "Epoch 3/5\n",
            "594/594 [==============================] - 1s 978us/step - loss: 0.8361\n",
            "Epoch 4/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8171\n",
            "Epoch 5/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8070\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.080 total time=   3.8s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0096\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9200\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8594\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8300\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8154\n",
            "149/149 [==============================] - 0s 763us/step\n",
            "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.460 total time=   4.5s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 949us/step - loss: 1.0629\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9600\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 956us/step - loss: 0.8964\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 968us/step - loss: 0.8744\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 939us/step - loss: 0.8660\n",
            "149/149 [==============================] - 0s 676us/step\n",
            "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.300 total time=   3.5s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0576\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9599\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9010\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8790\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8702\n",
            "149/149 [==============================] - 0s 872us/step\n",
            "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.380 total time=   4.5s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8739\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7667\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7215\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 919us/step - loss: 0.7013\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 909us/step - loss: 0.6942\n",
            "149/149 [==============================] - 0s 709us/step\n",
            "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.000 total time=   3.8s\n",
            "Epoch 1/5\n",
            "594/594 [==============================] - 1s 885us/step - loss: 0.9499\n",
            "Epoch 2/5\n",
            "594/594 [==============================] - 1s 902us/step - loss: 0.8730\n",
            "Epoch 3/5\n",
            "594/594 [==============================] - 1s 887us/step - loss: 0.8346\n",
            "Epoch 4/5\n",
            "594/594 [==============================] - 1s 892us/step - loss: 0.8175\n",
            "Epoch 5/5\n",
            "594/594 [==============================] - 1s 879us/step - loss: 0.8088\n",
            "149/149 [==============================] - 0s 723us/step\n",
            "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.090 total time=   3.2s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0094\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9184\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8589\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8304\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8157\n",
            "149/149 [==============================] - 0s 926us/step\n",
            "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.460 total time=   4.5s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0609\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 926us/step - loss: 0.9574\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 906us/step - loss: 0.8947\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 916us/step - loss: 0.8741\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 924us/step - loss: 0.8660\n",
            "149/149 [==============================] - 0s 676us/step\n",
            "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.300 total time=   3.4s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 931us/step - loss: 1.0577\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 919us/step - loss: 0.9584\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 951us/step - loss: 0.9023\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8799\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8699\n",
            "149/149 [==============================] - 0s 993us/step\n",
            "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.380 total time=   3.8s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8711\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7644\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7199\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7016\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6948\n",
            "149/149 [==============================] - 0s 696us/step\n",
            "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.000 total time=   4.3s\n",
            "Epoch 1/5\n",
            "594/594 [==============================] - 1s 892us/step - loss: 0.9558\n",
            "Epoch 2/5\n",
            "594/594 [==============================] - 1s 911us/step - loss: 0.8795\n",
            "Epoch 3/5\n",
            "594/594 [==============================] - 1s 882us/step - loss: 0.8356\n",
            "Epoch 4/5\n",
            "594/594 [==============================] - 1s 895us/step - loss: 0.8163\n",
            "Epoch 5/5\n",
            "594/594 [==============================] - 1s 895us/step - loss: 0.8073\n",
            "149/149 [==============================] - 0s 676us/step\n",
            "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.080 total time=   3.2s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 909us/step - loss: 1.0087\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 981us/step - loss: 0.9182\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8582\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8297\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8149\n",
            "149/149 [==============================] - 0s 959us/step\n",
            "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.490 total time=   3.9s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0623\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9613\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8977\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8756\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 902us/step - loss: 0.8658\n",
            "149/149 [==============================] - 0s 655us/step\n",
            "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.350 total time=   4.0s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 921us/step - loss: 1.0631\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 941us/step - loss: 0.9691\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 933us/step - loss: 0.9036\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 931us/step - loss: 0.8784\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 931us/step - loss: 0.8689\n",
            "149/149 [==============================] - 0s 662us/step\n",
            "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.410 total time=   3.3s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8802\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7680\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7176\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7001\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6933\n",
            "149/149 [==============================] - 0s 946us/step\n",
            "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.000 total time=   4.2s\n",
            "Epoch 1/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9514\n",
            "Epoch 2/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8764\n",
            "Epoch 3/5\n",
            "594/594 [==============================] - 1s 939us/step - loss: 0.8348\n",
            "Epoch 4/5\n",
            "594/594 [==============================] - 1s 894us/step - loss: 0.8165\n",
            "Epoch 5/5\n",
            "594/594 [==============================] - 1s 911us/step - loss: 0.8069\n",
            "149/149 [==============================] - 0s 682us/step\n",
            "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.080 total time=   3.6s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 918us/step - loss: 1.0094\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 924us/step - loss: 0.9196\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 919us/step - loss: 0.8550\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 904us/step - loss: 0.8273\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 921us/step - loss: 0.8152\n",
            "149/149 [==============================] - 0s 973us/step\n",
            "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.460 total time=   3.3s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0630\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9647\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8990\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8736\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8642\n",
            "149/149 [==============================] - 0s 986us/step\n",
            "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.300 total time=   4.5s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0618\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 906us/step - loss: 0.9631\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 921us/step - loss: 0.9017\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 919us/step - loss: 0.8796\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 906us/step - loss: 0.8705\n",
            "149/149 [==============================] - 0s 669us/step\n",
            "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.380 total time=   3.3s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 894us/step - loss: 0.8733\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 921us/step - loss: 0.7677\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 909us/step - loss: 0.7222\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7019\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6947\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.000 total time=   3.8s\n",
            "Epoch 1/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9534\n",
            "Epoch 2/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8687\n",
            "Epoch 3/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8323\n",
            "Epoch 4/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8157\n",
            "Epoch 5/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8079\n",
            "149/149 [==============================] - 0s 682us/step\n",
            "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.080 total time=   4.1s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 911us/step - loss: 1.0067\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 916us/step - loss: 0.9190\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 911us/step - loss: 0.8570\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 918us/step - loss: 0.8282\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 929us/step - loss: 0.8154\n",
            "149/149 [==============================] - 0s 696us/step\n",
            "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.450 total time=   3.3s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 914us/step - loss: 1.0588\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 990us/step - loss: 0.9563\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8938\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8728\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8646\n",
            "149/149 [==============================] - 0s 926us/step\n",
            "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.300 total time=   3.9s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0608\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9660\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9043\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8793\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 909us/step - loss: 0.8691\n",
            "149/149 [==============================] - 0s 669us/step\n",
            "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.380 total time=   3.9s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 926us/step - loss: 0.8748\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 919us/step - loss: 0.7656\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 916us/step - loss: 0.7175\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 911us/step - loss: 0.7005\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 912us/step - loss: 0.6941\n",
            "149/149 [==============================] - 0s 696us/step\n",
            "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.000 total time=   3.3s\n",
            "Epoch 1/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9678\n",
            "Epoch 2/5\n",
            "594/594 [==============================] - 1s 2ms/step - loss: 0.9206\n",
            "Epoch 3/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8620\n",
            "Epoch 4/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8302\n",
            "Epoch 5/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8186\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.060 total time=   5.1s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0302\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9813\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8921\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8491\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8358\n",
            "149/149 [==============================] - 0s 797us/step\n",
            "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.470 total time=   4.0s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0881\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0300\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9303\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8948\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8851\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.320 total time=   4.6s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 1.0839\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0334\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9376\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8989\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8873\n",
            "149/149 [==============================] - 0s 791us/step\n",
            "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.350 total time=   4.5s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8958\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8153\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7627\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7353\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7280\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.000 total time=   4.3s\n",
            "Epoch 1/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9679\n",
            "Epoch 2/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9211\n",
            "Epoch 3/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8630\n",
            "Epoch 4/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8309\n",
            "Epoch 5/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8190\n",
            "149/149 [==============================] - 0s 818us/step\n",
            "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.080 total time=   4.8s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0302\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9884\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9000\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8523\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8373\n",
            "149/149 [==============================] - 0s 797us/step\n",
            "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.480 total time=   3.9s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 2s 2ms/step - loss: 1.0886\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0373\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9345\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8959\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8858\n",
            "149/149 [==============================] - 0s 993us/step\n",
            "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.320 total time=   5.6s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0844\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0331\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9358\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8984\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8878\n",
            "149/149 [==============================] - 0s 818us/step\n",
            "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.390 total time=   3.9s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9052\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8164\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.7657\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7365\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7265\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.000 total time=   4.9s\n",
            "Epoch 1/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9689\n",
            "Epoch 2/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9180\n",
            "Epoch 3/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8613\n",
            "Epoch 4/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8305\n",
            "Epoch 5/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8183\n",
            "149/149 [==============================] - 0s 899us/step\n",
            "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.070 total time=   4.2s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0300\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9843\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8960\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8515\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8368\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.480 total time=   4.6s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0881\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 1.0359\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9349\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8965\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8864\n",
            "149/149 [==============================] - 0s 784us/step\n",
            "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.320 total time=   4.6s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0832\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0266\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9321\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8975\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8877\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.390 total time=   4.1s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9058\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8150\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7641\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7368\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7288\n",
            "149/149 [==============================] - 0s 777us/step\n",
            "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.000 total time=   4.8s\n",
            "Epoch 1/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9700\n",
            "Epoch 2/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9205\n",
            "Epoch 3/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8620\n",
            "Epoch 4/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8308\n",
            "Epoch 5/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8195\n",
            "149/149 [==============================] - 0s 838us/step\n",
            "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.080 total time=   3.8s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0328\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9853\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8949\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8496\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8365\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.480 total time=   5.1s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0876\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0267\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9318\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8967\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8863\n",
            "149/149 [==============================] - 0s 784us/step\n",
            "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.320 total time=   4.1s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0840\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0343\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9365\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8984\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8875\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.360 total time=   4.6s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.9019\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8158\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7659\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7386\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7303\n",
            "149/149 [==============================] - 0s 804us/step\n",
            "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.000 total time=   4.5s\n",
            "Epoch 1/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9706\n",
            "Epoch 2/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9203\n",
            "Epoch 3/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8627\n",
            "Epoch 4/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8312\n",
            "Epoch 5/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8193\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.070 total time=   4.1s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0324\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9861\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8968\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8499\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8361\n",
            "149/149 [==============================] - 0s 912us/step\n",
            "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.480 total time=   5.0s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0879\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0322\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9329\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8957\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8862\n",
            "149/149 [==============================] - 0s 777us/step\n",
            "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.310 total time=   3.9s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0839\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0363\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9380\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8981\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8868\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.350 total time=   5.1s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8979\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8194\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7708\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7362\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7276\n",
            "149/149 [==============================] - 0s 838us/step\n",
            "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.000 total time=   4.0s\n",
            "Epoch 1/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9697\n",
            "Epoch 2/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9240\n",
            "Epoch 3/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8664\n",
            "Epoch 4/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8319\n",
            "Epoch 5/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8187\n",
            "149/149 [==============================] - 0s 946us/step\n",
            "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.060 total time=   4.7s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 1.0314\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9872\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8999\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8518\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8368\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.470 total time=   4.5s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0882\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0343\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9338\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8973\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8875\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.320 total time=   4.4s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0837\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 1.0318\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.9339\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8976\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8871\n",
            "149/149 [==============================] - 0s 797us/step\n",
            "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.390 total time=   4.8s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8994\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8126\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7587\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7340\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7273\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.000 total time=   4.1s\n",
            "Epoch 1/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9693\n",
            "Epoch 2/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9214\n",
            "Epoch 3/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8641\n",
            "Epoch 4/5\n",
            "594/594 [==============================] - 1s 2ms/step - loss: 0.8314\n",
            "Epoch 5/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8191\n",
            "149/149 [==============================] - 0s 851us/step\n",
            "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.060 total time=   5.0s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0319\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9861\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8987\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8511\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8361\n",
            "149/149 [==============================] - 0s 811us/step\n",
            "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.470 total time=   4.0s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 2s 1ms/step - loss: 1.0883\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 1.0368\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9337\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8953\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8857\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.320 total time=   5.7s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0830\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0289\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9365\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9003\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8889\n",
            "149/149 [==============================] - 0s 770us/step\n",
            "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.390 total time=   3.9s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8981\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8159\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7650\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7356\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7283\n",
            "149/149 [==============================] - 0s 953us/step\n",
            "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.000 total time=   4.8s\n",
            "Epoch 1/5\n",
            "594/594 [==============================] - 1s 2ms/step - loss: 0.9700\n",
            "Epoch 2/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9212\n",
            "Epoch 3/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8653\n",
            "Epoch 4/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8318\n",
            "Epoch 5/5\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8188\n",
            "149/149 [==============================] - 0s 777us/step\n",
            "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.060 total time=   4.4s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0320\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9868\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8964\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8504\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8364\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.480 total time=   4.4s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 1.0873\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0287\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9332\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8979\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8877\n",
            "149/149 [==============================] - 0s 777us/step\n",
            "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.320 total time=   4.7s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0833\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0312\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9362\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9000\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8883\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.390 total time=   4.0s\n",
            "Epoch 1/5\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.9027\n",
            "Epoch 2/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8155\n",
            "Epoch 3/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7650\n",
            "Epoch 4/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7377\n",
            "Epoch 5/5\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7297\n",
            "149/149 [==============================] - 0s 993us/step\n",
            "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=5, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.000 total time=   5.1s\n",
            "Epoch 1/20\n",
            "594/594 [==============================] - 1s 895us/step - loss: 0.9492\n",
            "Epoch 2/20\n",
            "594/594 [==============================] - 1s 892us/step - loss: 0.8737\n",
            "Epoch 3/20\n",
            "594/594 [==============================] - 1s 907us/step - loss: 0.8328\n",
            "Epoch 4/20\n",
            "594/594 [==============================] - 1s 901us/step - loss: 0.8160\n",
            "Epoch 5/20\n",
            "594/594 [==============================] - 1s 902us/step - loss: 0.8074\n",
            "Epoch 6/20\n",
            "594/594 [==============================] - 1s 906us/step - loss: 0.8013\n",
            "Epoch 7/20\n",
            "594/594 [==============================] - 1s 894us/step - loss: 0.7976\n",
            "Epoch 8/20\n",
            "594/594 [==============================] - 1s 894us/step - loss: 0.7957\n",
            "Epoch 9/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7945\n",
            "Epoch 10/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7937\n",
            "Epoch 11/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7930\n",
            "Epoch 12/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7925\n",
            "Epoch 13/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7921\n",
            "Epoch 14/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7917\n",
            "Epoch 15/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7914\n",
            "Epoch 16/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7911\n",
            "Epoch 17/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7909\n",
            "Epoch 18/20\n",
            "594/594 [==============================] - 1s 897us/step - loss: 0.7907\n",
            "Epoch 19/20\n",
            "594/594 [==============================] - 1s 895us/step - loss: 0.7905\n",
            "Epoch 20/20\n",
            "594/594 [==============================] - 1s 885us/step - loss: 0.7903\n",
            "149/149 [==============================] - 0s 723us/step\n",
            "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.070 total time=  12.7s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 912us/step - loss: 1.0129\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 923us/step - loss: 0.9230\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 923us/step - loss: 0.8579\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 928us/step - loss: 0.8269\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8135\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8080\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8056\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8042\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 993us/step - loss: 0.8032\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 929us/step - loss: 0.8025\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 960us/step - loss: 0.8020\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 923us/step - loss: 0.8015\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 924us/step - loss: 0.8010\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 923us/step - loss: 0.8004\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 951us/step - loss: 0.8000\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7996\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7989\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7987\n",
            "149/149 [==============================] - 0s 682us/step\n",
            "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.460 total time=  13.1s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0630\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 916us/step - loss: 0.9635\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 934us/step - loss: 0.8974\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 923us/step - loss: 0.8753\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 923us/step - loss: 0.8674\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 926us/step - loss: 0.8624\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 924us/step - loss: 0.8589\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8567\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8547\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8543\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8540\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8537\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8536\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8535\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 928us/step - loss: 0.8533\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 976us/step - loss: 0.8532\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 928us/step - loss: 0.8531\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 918us/step - loss: 0.8531\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 921us/step - loss: 0.8530\n",
            "149/149 [==============================] - 0s 669us/step\n",
            "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.350 total time=  13.2s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 943us/step - loss: 1.0596\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 919us/step - loss: 0.9620\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9026\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8793\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8697\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8649\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8621\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8604\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8592\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8584\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 998us/step - loss: 0.8579\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 914us/step - loss: 0.8574\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 924us/step - loss: 0.8571\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 928us/step - loss: 0.8568\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 921us/step - loss: 0.8566\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 953us/step - loss: 0.8564\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8563\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 961us/step - loss: 0.8560\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
            "149/149 [==============================] - 0s 966us/step\n",
            "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.420 total time=  13.6s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8701\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7671\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7213\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7021\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6950\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6910\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 936us/step - loss: 0.6888\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 904us/step - loss: 0.6872\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 923us/step - loss: 0.6863\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 926us/step - loss: 0.6856\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 916us/step - loss: 0.6851\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 921us/step - loss: 0.6847\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 921us/step - loss: 0.6843\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 919us/step - loss: 0.6839\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6838\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6836\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6834\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6832\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6831\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6829\n",
            "149/149 [==============================] - 0s 926us/step\n",
            "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.010 total time=  13.8s\n",
            "Epoch 1/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9488\n",
            "Epoch 2/20\n",
            "594/594 [==============================] - 1s 914us/step - loss: 0.8759\n",
            "Epoch 3/20\n",
            "594/594 [==============================] - 1s 911us/step - loss: 0.8363\n",
            "Epoch 4/20\n",
            "594/594 [==============================] - 1s 904us/step - loss: 0.8174\n",
            "Epoch 5/20\n",
            "594/594 [==============================] - 1s 926us/step - loss: 0.8074\n",
            "Epoch 6/20\n",
            "594/594 [==============================] - 1s 899us/step - loss: 0.8019\n",
            "Epoch 7/20\n",
            "594/594 [==============================] - 1s 921us/step - loss: 0.7986\n",
            "Epoch 8/20\n",
            "594/594 [==============================] - 1s 897us/step - loss: 0.7962\n",
            "Epoch 9/20\n",
            "594/594 [==============================] - 1s 914us/step - loss: 0.7945\n",
            "Epoch 10/20\n",
            "594/594 [==============================] - 1s 953us/step - loss: 0.7934\n",
            "Epoch 11/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7925\n",
            "Epoch 12/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7919\n",
            "Epoch 13/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7915\n",
            "Epoch 14/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7911\n",
            "Epoch 15/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7908\n",
            "Epoch 16/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7906\n",
            "Epoch 17/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7903\n",
            "Epoch 18/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7902\n",
            "Epoch 19/20\n",
            "594/594 [==============================] - 0s 831us/step - loss: 0.7900\n",
            "Epoch 20/20\n",
            "594/594 [==============================] - 1s 890us/step - loss: 0.7899\n",
            "149/149 [==============================] - 0s 757us/step\n",
            "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.100 total time=  12.9s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0106\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 892us/step - loss: 0.9224\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 906us/step - loss: 0.8583\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 907us/step - loss: 0.8273\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 896us/step - loss: 0.8146\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 902us/step - loss: 0.8085\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 973us/step - loss: 0.8056\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8039\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8029\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8020\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8015\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8012\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8007\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8004\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8001\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7998\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 973us/step - loss: 0.7995\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7994\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 891us/step - loss: 0.7990\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 887us/step - loss: 0.7990\n",
            "149/149 [==============================] - 0s 703us/step\n",
            "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.460 total time=  13.2s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 907us/step - loss: 1.0650\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 911us/step - loss: 0.9649\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8982\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8760\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8677\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8625\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8593\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8573\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8553\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8547\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 901us/step - loss: 0.8544\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 906us/step - loss: 0.8541\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 904us/step - loss: 0.8538\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 906us/step - loss: 0.8537\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 923us/step - loss: 0.8536\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 918us/step - loss: 0.8535\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 902us/step - loss: 0.8533\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 902us/step - loss: 0.8532\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8532\n",
            "149/149 [==============================] - 0s 858us/step\n",
            "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.300 total time=  12.9s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0572\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9576\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9017\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8803\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8712\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8664\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 955us/step - loss: 0.8635\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 912us/step - loss: 0.8615\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 904us/step - loss: 0.8602\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 892us/step - loss: 0.8595\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 896us/step - loss: 0.8589\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 894us/step - loss: 0.8582\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 896us/step - loss: 0.8578\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 886us/step - loss: 0.8575\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 911us/step - loss: 0.8571\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8568\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8564\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8564\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
            "149/149 [==============================] - 0s 845us/step\n",
            "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.420 total time=  13.3s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8700\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7682\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 958us/step - loss: 0.7198\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 894us/step - loss: 0.7014\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 897us/step - loss: 0.6943\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 887us/step - loss: 0.6906\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 891us/step - loss: 0.6885\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 897us/step - loss: 0.6871\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 901us/step - loss: 0.6862\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 889us/step - loss: 0.6856\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 901us/step - loss: 0.6851\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6847\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6843\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6840\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6837\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6835\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6832\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6832\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6830\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 985us/step - loss: 0.6828\n",
            "149/149 [==============================] - 0s 669us/step\n",
            "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.010 total time=  13.1s\n",
            "Epoch 1/20\n",
            "594/594 [==============================] - 1s 880us/step - loss: 0.9535\n",
            "Epoch 2/20\n",
            "594/594 [==============================] - 1s 880us/step - loss: 0.8679\n",
            "Epoch 3/20\n",
            "594/594 [==============================] - 1s 867us/step - loss: 0.8318\n",
            "Epoch 4/20\n",
            "594/594 [==============================] - 1s 867us/step - loss: 0.8144\n",
            "Epoch 5/20\n",
            "594/594 [==============================] - 1s 870us/step - loss: 0.8053\n",
            "Epoch 6/20\n",
            "594/594 [==============================] - 1s 877us/step - loss: 0.8004\n",
            "Epoch 7/20\n",
            "594/594 [==============================] - 1s 882us/step - loss: 0.7976\n",
            "Epoch 8/20\n",
            "594/594 [==============================] - 1s 885us/step - loss: 0.7960\n",
            "Epoch 9/20\n",
            "594/594 [==============================] - 1s 877us/step - loss: 0.7946\n",
            "Epoch 10/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7934\n",
            "Epoch 11/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7927\n",
            "Epoch 12/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7920\n",
            "Epoch 13/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7914\n",
            "Epoch 14/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7910\n",
            "Epoch 15/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7906\n",
            "Epoch 16/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7904\n",
            "Epoch 17/20\n",
            "594/594 [==============================] - 1s 968us/step - loss: 0.7902\n",
            "Epoch 18/20\n",
            "594/594 [==============================] - 1s 909us/step - loss: 0.7900\n",
            "Epoch 19/20\n",
            "594/594 [==============================] - 1s 877us/step - loss: 0.7899\n",
            "Epoch 20/20\n",
            "594/594 [==============================] - 1s 877us/step - loss: 0.7897\n",
            "149/149 [==============================] - 0s 676us/step\n",
            "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.090 total time=  12.4s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 911us/step - loss: 1.0081\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 882us/step - loss: 0.9151\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 909us/step - loss: 0.8560\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 914us/step - loss: 0.8297\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 899us/step - loss: 0.8176\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8101\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8062\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8044\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8031\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8023\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8018\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8013\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 995us/step - loss: 0.8008\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 948us/step - loss: 0.8004\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 902us/step - loss: 0.8000\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 886us/step - loss: 0.7996\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 899us/step - loss: 0.7994\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 896us/step - loss: 0.7992\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 886us/step - loss: 0.7990\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 928us/step - loss: 0.7988\n",
            "149/149 [==============================] - 0s 689us/step\n",
            "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.480 total time=  12.5s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 914us/step - loss: 1.0598\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9559\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8941\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8727\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8646\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8604\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8581\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8569\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 909us/step - loss: 0.8552\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 912us/step - loss: 0.8549\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 907us/step - loss: 0.8546\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 919us/step - loss: 0.8543\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 921us/step - loss: 0.8541\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 933us/step - loss: 0.8539\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 911us/step - loss: 0.8537\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 912us/step - loss: 0.8536\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 909us/step - loss: 0.8535\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8533\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8532\n",
            "149/149 [==============================] - 0s 953us/step\n",
            "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.300 total time=  13.0s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0594\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9591\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9003\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8791\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8701\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 968us/step - loss: 0.8656\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 912us/step - loss: 0.8628\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 923us/step - loss: 0.8610\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 902us/step - loss: 0.8597\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 929us/step - loss: 0.8588\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 907us/step - loss: 0.8581\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 912us/step - loss: 0.8575\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 921us/step - loss: 0.8571\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 948us/step - loss: 0.8568\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 961us/step - loss: 0.8565\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 963us/step - loss: 0.8563\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8559\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8559\n",
            "149/149 [==============================] - 0s 939us/step\n",
            "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.420 total time=  13.0s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8745\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7660\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7203\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7017\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 934us/step - loss: 0.6946\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 899us/step - loss: 0.6908\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 901us/step - loss: 0.6885\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 897us/step - loss: 0.6870\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 902us/step - loss: 0.6862\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 901us/step - loss: 0.6856\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 897us/step - loss: 0.6850\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 904us/step - loss: 0.6846\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 960us/step - loss: 0.6843\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6841\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6839\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6838\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6836\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6835\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6834\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6832\n",
            "149/149 [==============================] - 0s 878us/step\n",
            "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.010 total time=  13.3s\n",
            "Epoch 1/20\n",
            "594/594 [==============================] - 1s 887us/step - loss: 0.9510\n",
            "Epoch 2/20\n",
            "594/594 [==============================] - 1s 879us/step - loss: 0.8705\n",
            "Epoch 3/20\n",
            "594/594 [==============================] - 1s 880us/step - loss: 0.8314\n",
            "Epoch 4/20\n",
            "594/594 [==============================] - 1s 885us/step - loss: 0.8159\n",
            "Epoch 5/20\n",
            "594/594 [==============================] - 1s 887us/step - loss: 0.8082\n",
            "Epoch 6/20\n",
            "594/594 [==============================] - 1s 884us/step - loss: 0.8029\n",
            "Epoch 7/20\n",
            "594/594 [==============================] - 1s 884us/step - loss: 0.7986\n",
            "Epoch 8/20\n",
            "594/594 [==============================] - 1s 885us/step - loss: 0.7959\n",
            "Epoch 9/20\n",
            "594/594 [==============================] - 1s 892us/step - loss: 0.7944\n",
            "Epoch 10/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7933\n",
            "Epoch 11/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7927\n",
            "Epoch 12/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7920\n",
            "Epoch 13/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7916\n",
            "Epoch 14/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7912\n",
            "Epoch 15/20\n",
            "594/594 [==============================] - 1s 998us/step - loss: 0.7909\n",
            "Epoch 16/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7907\n",
            "Epoch 17/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7905\n",
            "Epoch 18/20\n",
            "594/594 [==============================] - 1s 1000us/step - loss: 0.7903\n",
            "Epoch 19/20\n",
            "594/594 [==============================] - 1s 884us/step - loss: 0.7901\n",
            "Epoch 20/20\n",
            "594/594 [==============================] - 1s 899us/step - loss: 0.7899\n",
            "149/149 [==============================] - 0s 669us/step\n",
            "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.080 total time=  12.6s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 916us/step - loss: 1.0093\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 911us/step - loss: 0.9186\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 923us/step - loss: 0.8583\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 921us/step - loss: 0.8272\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 912us/step - loss: 0.8143\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8090\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8062\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8044\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8032\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8024\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8017\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8012\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8007\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 953us/step - loss: 0.8003\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 916us/step - loss: 0.7997\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 919us/step - loss: 0.7993\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 911us/step - loss: 0.7991\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 924us/step - loss: 0.7988\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 914us/step - loss: 0.7987\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 926us/step - loss: 0.7985\n",
            "149/149 [==============================] - 0s 703us/step\n",
            "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.500 total time=  13.0s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 938us/step - loss: 1.0608\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9573\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8963\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8737\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8647\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8600\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8576\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 923us/step - loss: 0.8547\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 924us/step - loss: 0.8543\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 923us/step - loss: 0.8541\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 921us/step - loss: 0.8539\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 924us/step - loss: 0.8536\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 919us/step - loss: 0.8536\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 928us/step - loss: 0.8533\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 923us/step - loss: 0.8532\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8531\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
            "149/149 [==============================] - 0s 919us/step\n",
            "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.350 total time=  13.5s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0608\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9643\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9019\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8792\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 963us/step - loss: 0.8698\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 916us/step - loss: 0.8649\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 919us/step - loss: 0.8620\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 912us/step - loss: 0.8600\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 938us/step - loss: 0.8588\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 933us/step - loss: 0.8580\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 921us/step - loss: 0.8575\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 914us/step - loss: 0.8571\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 912us/step - loss: 0.8568\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8566\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8563\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8558\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
            "149/149 [==============================] - 0s 872us/step\n",
            "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.420 total time=  13.7s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 939us/step - loss: 0.8815\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 931us/step - loss: 0.7687\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 918us/step - loss: 0.7205\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 918us/step - loss: 0.7019\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 928us/step - loss: 0.6947\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 916us/step - loss: 0.6907\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 931us/step - loss: 0.6886\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 919us/step - loss: 0.6870\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6860\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6853\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6847\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6843\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6840\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6837\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6835\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6833\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6832\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 928us/step - loss: 0.6830\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 919us/step - loss: 0.6829\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 907us/step - loss: 0.6828\n",
            "149/149 [==============================] - 0s 689us/step\n",
            "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.010 total time=  13.1s\n",
            "Epoch 1/20\n",
            "594/594 [==============================] - 1s 874us/step - loss: 0.9541\n",
            "Epoch 2/20\n",
            "594/594 [==============================] - 1s 879us/step - loss: 0.8729\n",
            "Epoch 3/20\n",
            "594/594 [==============================] - 1s 880us/step - loss: 0.8341\n",
            "Epoch 4/20\n",
            "594/594 [==============================] - 1s 965us/step - loss: 0.8168\n",
            "Epoch 5/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8067\n",
            "Epoch 6/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8008\n",
            "Epoch 7/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7979\n",
            "Epoch 8/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7961\n",
            "Epoch 9/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7949\n",
            "Epoch 10/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7939\n",
            "Epoch 11/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7931\n",
            "Epoch 12/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7926\n",
            "Epoch 13/20\n",
            "594/594 [==============================] - 1s 885us/step - loss: 0.7919\n",
            "Epoch 14/20\n",
            "594/594 [==============================] - 1s 880us/step - loss: 0.7915\n",
            "Epoch 15/20\n",
            "594/594 [==============================] - 1s 882us/step - loss: 0.7911\n",
            "Epoch 16/20\n",
            "594/594 [==============================] - 1s 880us/step - loss: 0.7908\n",
            "Epoch 17/20\n",
            "594/594 [==============================] - 1s 877us/step - loss: 0.7905\n",
            "Epoch 18/20\n",
            "594/594 [==============================] - 1s 872us/step - loss: 0.7903\n",
            "Epoch 19/20\n",
            "594/594 [==============================] - 1s 884us/step - loss: 0.7901\n",
            "Epoch 20/20\n",
            "594/594 [==============================] - 1s 880us/step - loss: 0.7900\n",
            "149/149 [==============================] - 0s 669us/step\n",
            "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.080 total time=  12.9s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0084\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9195\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8595\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8309\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8154\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8080\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8049\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8033\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 929us/step - loss: 0.8024\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 931us/step - loss: 0.8016\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 911us/step - loss: 0.8012\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 926us/step - loss: 0.8008\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 923us/step - loss: 0.8005\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 929us/step - loss: 0.8003\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 924us/step - loss: 0.8000\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 923us/step - loss: 0.7998\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 981us/step - loss: 0.7994\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7992\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7991\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7988\n",
            "149/149 [==============================] - 0s 953us/step\n",
            "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.480 total time=  13.7s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0620\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9620\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8981\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8746\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 936us/step - loss: 0.8654\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 914us/step - loss: 0.8608\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 921us/step - loss: 0.8583\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 923us/step - loss: 0.8568\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 892us/step - loss: 0.8558\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 899us/step - loss: 0.8552\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 911us/step - loss: 0.8548\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 919us/step - loss: 0.8543\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 970us/step - loss: 0.8541\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8539\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8536\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8534\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8533\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8531\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8531\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8528\n",
            "149/149 [==============================] - 0s 824us/step\n",
            "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.350 total time=  13.5s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 896us/step - loss: 1.0580\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 902us/step - loss: 0.9592\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 894us/step - loss: 0.8993\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 902us/step - loss: 0.8767\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 909us/step - loss: 0.8678\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 902us/step - loss: 0.8635\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 921us/step - loss: 0.8611\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 892us/step - loss: 0.8597\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 978us/step - loss: 0.8588\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8581\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8577\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8573\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8570\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8568\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8566\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8564\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 911us/step - loss: 0.8563\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 906us/step - loss: 0.8560\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 891us/step - loss: 0.8560\n",
            "149/149 [==============================] - 0s 669us/step\n",
            "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.420 total time=  12.7s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 909us/step - loss: 0.8794\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 960us/step - loss: 0.7665\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 916us/step - loss: 0.7189\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 916us/step - loss: 0.7008\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 923us/step - loss: 0.6941\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6903\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6883\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6869\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6860\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6853\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6848\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6844\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6841\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 938us/step - loss: 0.6838\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 919us/step - loss: 0.6835\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 924us/step - loss: 0.6833\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 919us/step - loss: 0.6832\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 938us/step - loss: 0.6830\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 934us/step - loss: 0.6829\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 906us/step - loss: 0.6828\n",
            "149/149 [==============================] - 0s 689us/step\n",
            "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.010 total time=  12.9s\n",
            "Epoch 1/20\n",
            "594/594 [==============================] - 1s 882us/step - loss: 0.9513\n",
            "Epoch 2/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8717\n",
            "Epoch 3/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8350\n",
            "Epoch 4/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8177\n",
            "Epoch 5/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8086\n",
            "Epoch 6/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8029\n",
            "Epoch 7/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7980\n",
            "Epoch 8/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7950\n",
            "Epoch 9/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7935\n",
            "Epoch 10/20\n",
            "594/594 [==============================] - 1s 906us/step - loss: 0.7926\n",
            "Epoch 11/20\n",
            "594/594 [==============================] - 1s 892us/step - loss: 0.7919\n",
            "Epoch 12/20\n",
            "594/594 [==============================] - 1s 872us/step - loss: 0.7915\n",
            "Epoch 13/20\n",
            "594/594 [==============================] - 1s 895us/step - loss: 0.7912\n",
            "Epoch 14/20\n",
            "594/594 [==============================] - 1s 926us/step - loss: 0.7908\n",
            "Epoch 15/20\n",
            "594/594 [==============================] - 1s 902us/step - loss: 0.7906\n",
            "Epoch 16/20\n",
            "594/594 [==============================] - 1s 874us/step - loss: 0.7904\n",
            "Epoch 17/20\n",
            "594/594 [==============================] - 1s 874us/step - loss: 0.7902\n",
            "Epoch 18/20\n",
            "594/594 [==============================] - 1s 879us/step - loss: 0.7900\n",
            "Epoch 19/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7898\n",
            "Epoch 20/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7897\n",
            "149/149 [==============================] - 0s 986us/step\n",
            "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.080 total time=  13.0s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0099\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9182\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8586\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8313\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8155\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 912us/step - loss: 0.8085\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 892us/step - loss: 0.8054\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 923us/step - loss: 0.8039\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 916us/step - loss: 0.8029\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 899us/step - loss: 0.8023\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 899us/step - loss: 0.8018\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 896us/step - loss: 0.8013\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 896us/step - loss: 0.8009\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 896us/step - loss: 0.8005\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8002\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7998\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7995\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7993\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7990\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7988\n",
            "149/149 [==============================] - 0s 939us/step\n",
            "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.490 total time=  13.0s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0640\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 985us/step - loss: 0.9651\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 939us/step - loss: 0.8985\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 916us/step - loss: 0.8750\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 894us/step - loss: 0.8661\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 897us/step - loss: 0.8615\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 887us/step - loss: 0.8585\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 904us/step - loss: 0.8567\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 894us/step - loss: 0.8557\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 904us/step - loss: 0.8550\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8544\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8542\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8539\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8537\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8535\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8533\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8531\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8530\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 992us/step - loss: 0.8529\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 899us/step - loss: 0.8528\n",
            "149/149 [==============================] - 0s 716us/step\n",
            "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.350 total time=  13.1s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 923us/step - loss: 1.0615\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 899us/step - loss: 0.9664\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 897us/step - loss: 0.9040\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 907us/step - loss: 0.8796\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 897us/step - loss: 0.8699\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 901us/step - loss: 0.8650\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8622\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8604\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8593\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8583\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8576\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8571\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8568\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8565\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8564\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 892us/step - loss: 0.8562\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 896us/step - loss: 0.8561\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 896us/step - loss: 0.8560\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 901us/step - loss: 0.8558\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 904us/step - loss: 0.8558\n",
            "149/149 [==============================] - 0s 709us/step\n",
            "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.420 total time=  12.7s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 924us/step - loss: 0.8814\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 909us/step - loss: 0.7697\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 993us/step - loss: 0.7220\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7022\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6947\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6908\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6886\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6872\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6864\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6857\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6851\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 914us/step - loss: 0.6847\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 907us/step - loss: 0.6844\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 928us/step - loss: 0.6841\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 924us/step - loss: 0.6839\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 912us/step - loss: 0.6837\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 897us/step - loss: 0.6835\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 916us/step - loss: 0.6833\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 919us/step - loss: 0.6832\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6831\n",
            "149/149 [==============================] - 0s 892us/step\n",
            "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.010 total time=  13.0s\n",
            "Epoch 1/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9506\n",
            "Epoch 2/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8755\n",
            "Epoch 3/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8342\n",
            "Epoch 4/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8166\n",
            "Epoch 5/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8072\n",
            "Epoch 6/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8010\n",
            "Epoch 7/20\n",
            "594/594 [==============================] - 1s 954us/step - loss: 0.7977\n",
            "Epoch 8/20\n",
            "594/594 [==============================] - 1s 894us/step - loss: 0.7959\n",
            "Epoch 9/20\n",
            "594/594 [==============================] - 1s 949us/step - loss: 0.7948\n",
            "Epoch 10/20\n",
            "594/594 [==============================] - 1s 895us/step - loss: 0.7940\n",
            "Epoch 11/20\n",
            "594/594 [==============================] - 1s 914us/step - loss: 0.7932\n",
            "Epoch 12/20\n",
            "594/594 [==============================] - 1s 906us/step - loss: 0.7926\n",
            "Epoch 13/20\n",
            "594/594 [==============================] - 1s 901us/step - loss: 0.7921\n",
            "Epoch 14/20\n",
            "594/594 [==============================] - 1s 890us/step - loss: 0.7917\n",
            "Epoch 15/20\n",
            "594/594 [==============================] - 1s 895us/step - loss: 0.7913\n",
            "Epoch 16/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7910\n",
            "Epoch 17/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7908\n",
            "Epoch 18/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7904\n",
            "Epoch 19/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7904\n",
            "Epoch 20/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7902\n",
            "149/149 [==============================] - 0s 926us/step\n",
            "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.070 total time=  13.7s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0092\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9199\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 884us/step - loss: 0.8599\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 894us/step - loss: 0.8317\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 897us/step - loss: 0.8156\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 894us/step - loss: 0.8085\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 892us/step - loss: 0.8054\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8038\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 958us/step - loss: 0.8029\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 936us/step - loss: 0.8023\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8018\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8014\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8010\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8006\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8004\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7999\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7995\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7993\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7991\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 926us/step - loss: 0.7988\n",
            "149/149 [==============================] - 0s 709us/step\n",
            "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.490 total time=  13.5s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 921us/step - loss: 1.0607\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 939us/step - loss: 0.9606\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 934us/step - loss: 0.8973\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 923us/step - loss: 0.8749\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 918us/step - loss: 0.8662\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 891us/step - loss: 0.8612\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8582\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8566\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8550\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8545\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8543\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8540\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 998us/step - loss: 0.8537\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 929us/step - loss: 0.8536\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 901us/step - loss: 0.8535\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 897us/step - loss: 0.8533\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 899us/step - loss: 0.8532\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 896us/step - loss: 0.8531\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 886us/step - loss: 0.8530\n",
            "149/149 [==============================] - 0s 689us/step\n",
            "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.300 total time=  12.7s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 891us/step - loss: 1.0588\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 906us/step - loss: 0.9599\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9011\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8786\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8690\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8644\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8617\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8600\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8589\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8579\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 968us/step - loss: 0.8574\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 897us/step - loss: 0.8571\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 897us/step - loss: 0.8568\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 889us/step - loss: 0.8565\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 892us/step - loss: 0.8565\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 904us/step - loss: 0.8563\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 894us/step - loss: 0.8562\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 892us/step - loss: 0.8562\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 912us/step - loss: 0.8561\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
            "149/149 [==============================] - 0s 865us/step\n",
            "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.420 total time=  12.8s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8768\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7683\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7210\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7018\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6945\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6907\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 939us/step - loss: 0.6885\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 916us/step - loss: 0.6870\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 919us/step - loss: 0.6860\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 924us/step - loss: 0.6853\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 916us/step - loss: 0.6848\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 914us/step - loss: 0.6844\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 916us/step - loss: 0.6841\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 924us/step - loss: 0.6838\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 926us/step - loss: 0.6835\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6833\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6831\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6831\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6829\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6828\n",
            "149/149 [==============================] - 0s 1000us/step\n",
            "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.000 total time=  13.8s\n",
            "Epoch 1/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9510\n",
            "Epoch 2/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8737\n",
            "Epoch 3/20\n",
            "594/594 [==============================] - 1s 879us/step - loss: 0.8331\n",
            "Epoch 4/20\n",
            "594/594 [==============================] - 1s 862us/step - loss: 0.8152\n",
            "Epoch 5/20\n",
            "594/594 [==============================] - 1s 868us/step - loss: 0.8060\n",
            "Epoch 6/20\n",
            "594/594 [==============================] - 1s 868us/step - loss: 0.8011\n",
            "Epoch 7/20\n",
            "594/594 [==============================] - 1s 877us/step - loss: 0.7981\n",
            "Epoch 8/20\n",
            "594/594 [==============================] - 1s 885us/step - loss: 0.7960\n",
            "Epoch 9/20\n",
            "594/594 [==============================] - 1s 870us/step - loss: 0.7944\n",
            "Epoch 10/20\n",
            "594/594 [==============================] - 1s 862us/step - loss: 0.7932\n",
            "Epoch 11/20\n",
            "594/594 [==============================] - 1s 897us/step - loss: 0.7921\n",
            "Epoch 12/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7915\n",
            "Epoch 13/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7910\n",
            "Epoch 14/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7905\n",
            "Epoch 15/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7903\n",
            "Epoch 16/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7902\n",
            "Epoch 17/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7900\n",
            "Epoch 18/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7898\n",
            "Epoch 19/20\n",
            "594/594 [==============================] - 1s 992us/step - loss: 0.7897\n",
            "Epoch 20/20\n",
            "594/594 [==============================] - 1s 887us/step - loss: 0.7896\n",
            "149/149 [==============================] - 0s 682us/step\n",
            "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.080 total time=  12.6s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 909us/step - loss: 1.0105\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 894us/step - loss: 0.9240\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 894us/step - loss: 0.8615\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 907us/step - loss: 0.8320\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 896us/step - loss: 0.8195\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 897us/step - loss: 0.8111\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 936us/step - loss: 0.8063\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8041\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8029\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8022\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8016\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8011\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8007\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8004\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7999\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 971us/step - loss: 0.7996\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 943us/step - loss: 0.7993\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 891us/step - loss: 0.7990\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 918us/step - loss: 0.7988\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 904us/step - loss: 0.7986\n",
            "149/149 [==============================] - 0s 655us/step\n",
            "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.480 total time=  12.7s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 909us/step - loss: 1.0627\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 924us/step - loss: 0.9614\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 923us/step - loss: 0.8982\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8747\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8658\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8613\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8587\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8572\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8548\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 912us/step - loss: 0.8544\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 904us/step - loss: 0.8540\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 916us/step - loss: 0.8537\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 904us/step - loss: 0.8535\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 923us/step - loss: 0.8534\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 929us/step - loss: 0.8532\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 918us/step - loss: 0.8531\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 911us/step - loss: 0.8531\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 918us/step - loss: 0.8530\n",
            "149/149 [==============================] - 0s 669us/step\n",
            "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.300 total time=  12.9s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0575\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9588\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9005\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8786\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8697\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8651\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8622\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8604\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 896us/step - loss: 0.8593\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 904us/step - loss: 0.8585\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 896us/step - loss: 0.8580\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 923us/step - loss: 0.8575\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 911us/step - loss: 0.8572\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 901us/step - loss: 0.8570\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 904us/step - loss: 0.8567\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 894us/step - loss: 0.8565\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 896us/step - loss: 0.8564\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8561\n",
            "149/149 [==============================] - 0s 872us/step\n",
            "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.420 total time=  13.2s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8826\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7745\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7231\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7025\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 921us/step - loss: 0.6950\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 929us/step - loss: 0.6909\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 933us/step - loss: 0.6886\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 911us/step - loss: 0.6871\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 906us/step - loss: 0.6860\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 906us/step - loss: 0.6854\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 914us/step - loss: 0.6848\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 914us/step - loss: 0.6843\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 904us/step - loss: 0.6840\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6837\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6835\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6833\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6831\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6830\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6829\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6828\n",
            "149/149 [==============================] - 0s 824us/step\n",
            "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=0, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.010 total time=  13.6s\n",
            "Epoch 1/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9721\n",
            "Epoch 2/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9173\n",
            "Epoch 3/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8588\n",
            "Epoch 4/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8292\n",
            "Epoch 5/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8181\n",
            "Epoch 6/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8116\n",
            "Epoch 7/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8072\n",
            "Epoch 8/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8043\n",
            "Epoch 9/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8022\n",
            "Epoch 10/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8005\n",
            "Epoch 11/20\n",
            "594/594 [==============================] - 1s 2ms/step - loss: 0.7990\n",
            "Epoch 12/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7977\n",
            "Epoch 13/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7964\n",
            "Epoch 14/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7954\n",
            "Epoch 15/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7946\n",
            "Epoch 16/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7942\n",
            "Epoch 17/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7938\n",
            "Epoch 18/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7935\n",
            "Epoch 19/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7931\n",
            "Epoch 20/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7928\n",
            "149/149 [==============================] - 0s 770us/step\n",
            "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.050 total time=  15.0s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0300\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9834\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8947\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8497\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8362\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8313\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8290\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8274\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8258\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8234\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8196\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8155\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8120\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8094\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8073\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8061\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8052\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8045\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8038\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8033\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.480 total time=  15.6s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 1.0886\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0377\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9361\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8960\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8861\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8795\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8744\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8706\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8670\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8634\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8605\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8584\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8572\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8563\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8558\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8552\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8549\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8547\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8544\n",
            "149/149 [==============================] - 0s 804us/step\n",
            "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.300 total time=  15.6s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0843\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0358\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9373\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8973\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8873\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8822\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8781\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8749\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8722\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8695\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8667\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8644\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8625\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8612\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8603\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8594\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8588\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8583\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8580\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8578\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.420 total time=  15.8s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9006\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8159\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7649\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7353\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7277\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7231\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7180\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7091\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6983\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6926\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6902\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.6890\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6880\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6872\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6867\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.6862\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6858\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6854\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6852\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6850\n",
            "149/149 [==============================] - 0s 811us/step\n",
            "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.000 total time=  15.8s\n",
            "Epoch 1/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9707\n",
            "Epoch 2/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9152\n",
            "Epoch 3/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8576\n",
            "Epoch 4/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8292\n",
            "Epoch 5/20\n",
            "594/594 [==============================] - 1s 2ms/step - loss: 0.8177\n",
            "Epoch 6/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8113\n",
            "Epoch 7/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8072\n",
            "Epoch 8/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8043\n",
            "Epoch 9/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8023\n",
            "Epoch 10/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8008\n",
            "Epoch 11/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7995\n",
            "Epoch 12/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7981\n",
            "Epoch 13/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7969\n",
            "Epoch 14/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7959\n",
            "Epoch 15/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7949\n",
            "Epoch 16/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7942\n",
            "Epoch 17/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7936\n",
            "Epoch 18/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7931\n",
            "Epoch 19/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7929\n",
            "Epoch 20/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7928\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.050 total time=  15.7s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0296\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9850\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8964\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8495\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8355\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8306\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8280\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8258\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8233\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8200\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8165\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8131\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8107\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8087\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8074\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8063\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8053\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8048\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8041\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8037\n",
            "149/149 [==============================] - 0s 797us/step\n",
            "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.480 total time=  15.9s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0882\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0382\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9403\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8994\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8879\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8818\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8760\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8714\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8671\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8634\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8604\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8583\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8572\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8563\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8555\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8552\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8550\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8547\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8545\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.340 total time=  16.0s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 2s 1ms/step - loss: 1.0830\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0275\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9326\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8981\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8875\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8828\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8789\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8751\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8722\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8693\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8669\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8647\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8631\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8618\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8608\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8599\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8592\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8588\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8584\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8580\n",
            "149/149 [==============================] - 0s 757us/step\n",
            "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.420 total time=  15.9s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9025\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8136\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7618\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7349\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7276\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7238\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7215\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7195\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7167\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7101\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6987\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6925\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6906\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6892\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6884\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6876\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6871\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6866\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6863\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6860\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.000 total time=  15.6s\n",
            "Epoch 1/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9714\n",
            "Epoch 2/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9221\n",
            "Epoch 3/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8644\n",
            "Epoch 4/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8316\n",
            "Epoch 5/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8194\n",
            "Epoch 6/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8128\n",
            "Epoch 7/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8082\n",
            "Epoch 8/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8052\n",
            "Epoch 9/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8030\n",
            "Epoch 10/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8013\n",
            "Epoch 11/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7998\n",
            "Epoch 12/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7985\n",
            "Epoch 13/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7973\n",
            "Epoch 14/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7960\n",
            "Epoch 15/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7950\n",
            "Epoch 16/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7942\n",
            "Epoch 17/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7938\n",
            "Epoch 18/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7934\n",
            "Epoch 19/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7932\n",
            "Epoch 20/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7928\n",
            "149/149 [==============================] - 0s 764us/step\n",
            "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.050 total time=  15.3s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0332\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9891\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8998\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8504\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8365\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8313\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8286\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8265\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8243\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8214\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8176\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8134\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8102\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8082\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8069\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8060\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8052\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8046\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8042\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8037\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.460 total time=  15.6s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0878\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0314\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9321\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8955\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8864\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8808\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8757\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8713\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8683\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8653\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8626\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8603\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8587\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8575\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8567\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8561\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8551\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8550\n",
            "149/149 [==============================] - 0s 777us/step\n",
            "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.350 total time=  15.7s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0835\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0317\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9374\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9000\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8887\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8832\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8786\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8742\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8702\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8672\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8649\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8633\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8620\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8612\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8606\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8601\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8595\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8592\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8588\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8584\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.420 total time=  15.6s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8995\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8185\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7716\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7403\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7305\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7230\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7106\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6989\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6934\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6907\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6894\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6882\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6875\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6869\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6863\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.6860\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6856\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6852\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6851\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6849\n",
            "149/149 [==============================] - 0s 750us/step\n",
            "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.000 total time=  15.8s\n",
            "Epoch 1/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9693\n",
            "Epoch 2/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9199\n",
            "Epoch 3/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8634\n",
            "Epoch 4/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8308\n",
            "Epoch 5/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8182\n",
            "Epoch 6/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8112\n",
            "Epoch 7/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8067\n",
            "Epoch 8/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8041\n",
            "Epoch 9/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8022\n",
            "Epoch 10/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8009\n",
            "Epoch 11/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7996\n",
            "Epoch 12/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7984\n",
            "Epoch 13/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7968\n",
            "Epoch 14/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7957\n",
            "Epoch 15/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7947\n",
            "Epoch 16/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7942\n",
            "Epoch 17/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7938\n",
            "Epoch 18/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7936\n",
            "Epoch 19/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7932\n",
            "Epoch 20/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7929\n",
            "149/149 [==============================] - 0s 797us/step\n",
            "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.040 total time=  14.6s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 1.0301\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9857\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9002\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8525\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8369\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8314\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8287\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8265\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8242\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8209\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8167\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8132\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8110\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8095\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8083\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8073\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8063\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8054\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8047\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8040\n",
            "149/149 [==============================] - 0s 791us/step\n",
            "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.490 total time=  16.1s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0882\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0340\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9347\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8972\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8855\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8785\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8740\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8706\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8679\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8647\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8618\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8595\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8578\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8569\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8563\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8557\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8552\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8549\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8547\n",
            "149/149 [==============================] - 0s 919us/step\n",
            "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.300 total time=  15.0s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0834\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0285\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9352\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8984\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8878\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8826\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8783\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8741\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8706\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8674\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8650\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8630\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8615\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8607\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8599\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8593\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8589\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8586\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8583\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8581\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.420 total time=  16.1s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9016\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8158\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7646\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7358\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7284\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7248\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7224\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7205\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7186\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7155\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7090\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6983\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6924\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6903\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6891\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6883\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6877\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6871\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6865\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6862\n",
            "149/149 [==============================] - 0s 770us/step\n",
            "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=10, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.000 total time=  14.9s\n",
            "Epoch 1/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9713\n",
            "Epoch 2/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9177\n",
            "Epoch 3/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8605\n",
            "Epoch 4/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8302\n",
            "Epoch 5/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8181\n",
            "Epoch 6/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8115\n",
            "Epoch 7/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8071\n",
            "Epoch 8/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8044\n",
            "Epoch 9/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8025\n",
            "Epoch 10/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8011\n",
            "Epoch 11/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7997\n",
            "Epoch 12/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7985\n",
            "Epoch 13/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7972\n",
            "Epoch 14/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7960\n",
            "Epoch 15/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7950\n",
            "Epoch 16/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7943\n",
            "Epoch 17/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7936\n",
            "Epoch 18/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7933\n",
            "Epoch 19/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7931\n",
            "Epoch 20/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7927\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.050 total time=  15.9s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0305\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9896\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9028\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8533\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8371\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8310\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8279\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8249\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8210\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8165\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8128\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8108\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8094\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8080\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8069\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8061\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8053\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8047\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8041\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8034\n",
            "149/149 [==============================] - 0s 764us/step\n",
            "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.510 total time=  15.1s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0875\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0251\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9274\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8946\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8861\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8814\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8771\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8735\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8703\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8675\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8646\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8619\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8597\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8581\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8571\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8564\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8559\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8555\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8553\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8550\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.340 total time=  16.0s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0835\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0313\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9366\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8992\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8877\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8820\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8776\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8737\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8699\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8667\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8641\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8621\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8610\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8600\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8593\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8589\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8585\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8583\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8580\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8578\n",
            "149/149 [==============================] - 0s 757us/step\n",
            "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.420 total time=  15.1s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8995\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8130\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7611\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7364\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7282\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7210\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7100\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6976\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6924\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6905\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6893\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6884\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6876\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6872\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6867\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6863\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6859\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6857\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6855\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6853\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.001;, score=0.000 total time=  16.1s\n",
            "Epoch 1/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9678\n",
            "Epoch 2/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9190\n",
            "Epoch 3/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8611\n",
            "Epoch 4/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8309\n",
            "Epoch 5/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8197\n",
            "Epoch 6/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8133\n",
            "Epoch 7/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8090\n",
            "Epoch 8/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8060\n",
            "Epoch 9/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8039\n",
            "Epoch 10/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8022\n",
            "Epoch 11/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8009\n",
            "Epoch 12/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7994\n",
            "Epoch 13/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7978\n",
            "Epoch 14/20\n",
            "594/594 [==============================] - 1s 2ms/step - loss: 0.7965\n",
            "Epoch 15/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7953\n",
            "Epoch 16/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7946\n",
            "Epoch 17/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7942\n",
            "Epoch 18/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7938\n",
            "Epoch 19/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7936\n",
            "Epoch 20/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7934\n",
            "149/149 [==============================] - 0s 743us/step\n",
            "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.050 total time=  15.0s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0323\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9889\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9024\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8522\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8365\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8309\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8277\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8247\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8212\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8170\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8137\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8115\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8099\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8086\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8074\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8063\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8054\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8047\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8042\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8037\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.480 total time=  15.9s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0877\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0318\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9320\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8955\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8856\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8791\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8746\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8714\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8684\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8650\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8612\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8585\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8570\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8562\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8552\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8550\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8548\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8546\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8544\n",
            "149/149 [==============================] - 0s 770us/step\n",
            "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.300 total time=  15.2s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0832\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0275\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9327\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8983\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8882\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8833\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8799\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8763\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8725\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8689\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8658\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8634\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8620\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8611\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8604\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8599\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8594\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8590\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8586\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8584\n",
            "149/149 [==============================] - 0s 973us/step\n",
            "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.420 total time=  16.1s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.9006\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8155\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7647\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7370\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7293\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7250\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7215\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7171\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7080\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6973\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.6924\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6905\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6892\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6883\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6876\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6871\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6866\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6862\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6859\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6857\n",
            "149/149 [==============================] - 0s 797us/step\n",
            "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=adam, optimizer__learning_rate=0.0001;, score=0.000 total time=  15.7s\n",
            "Epoch 1/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9718\n",
            "Epoch 2/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9197\n",
            "Epoch 3/20\n",
            "594/594 [==============================] - 1s 2ms/step - loss: 0.8628\n",
            "Epoch 4/20\n",
            "594/594 [==============================] - 1s 2ms/step - loss: 0.8310\n",
            "Epoch 5/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8186\n",
            "Epoch 6/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8115\n",
            "Epoch 7/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8069\n",
            "Epoch 8/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8037\n",
            "Epoch 9/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8015\n",
            "Epoch 10/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7996\n",
            "Epoch 11/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7979\n",
            "Epoch 12/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7964\n",
            "Epoch 13/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7955\n",
            "Epoch 14/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7949\n",
            "Epoch 15/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7943\n",
            "Epoch 16/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7941\n",
            "Epoch 17/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7937\n",
            "Epoch 18/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7934\n",
            "Epoch 19/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7932\n",
            "Epoch 20/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7929\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.050 total time=  16.2s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0316\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9837\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8930\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8491\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8360\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8311\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8287\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8266\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8242\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8202\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8156\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8117\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8091\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8073\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8062\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8054\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8043\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8036\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8028\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8021\n",
            "149/149 [==============================] - 0s 791us/step\n",
            "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.500 total time=  15.4s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0881\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0335\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9322\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8953\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8858\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8806\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8760\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8715\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8676\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8644\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8617\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8594\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8577\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8566\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8560\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8554\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8551\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8548\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8546\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8545\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.350 total time=  16.1s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 2s 1ms/step - loss: 1.0833\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0272\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9313\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8967\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8866\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8812\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8767\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8733\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8700\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8672\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8649\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8631\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8621\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8610\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8604\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8598\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8591\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8588\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8585\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8583\n",
            "149/149 [==============================] - 0s 791us/step\n",
            "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.420 total time=  15.5s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9010\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8152\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7634\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7355\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7252\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7127\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6993\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6930\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6904\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6892\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6882\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6875\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6870\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6865\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6862\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6860\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6856\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6854\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6853\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6851\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.001;, score=0.000 total time=  15.5s\n",
            "Epoch 1/20\n",
            "594/594 [==============================] - 1s 2ms/step - loss: 0.9709\n",
            "Epoch 2/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.9193\n",
            "Epoch 3/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8624\n",
            "Epoch 4/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8310\n",
            "Epoch 5/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8181\n",
            "Epoch 6/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8111\n",
            "Epoch 7/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8066\n",
            "Epoch 8/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8037\n",
            "Epoch 9/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8017\n",
            "Epoch 10/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.8004\n",
            "Epoch 11/20\n",
            "594/594 [==============================] - 1s 2ms/step - loss: 0.7993\n",
            "Epoch 12/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7980\n",
            "Epoch 13/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7970\n",
            "Epoch 14/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7958\n",
            "Epoch 15/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7950\n",
            "Epoch 16/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7941\n",
            "Epoch 17/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7938\n",
            "Epoch 18/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7933\n",
            "Epoch 19/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7931\n",
            "Epoch 20/20\n",
            "594/594 [==============================] - 1s 1ms/step - loss: 0.7929\n",
            "149/149 [==============================] - 0s 804us/step\n",
            "[CV 1/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.050 total time=  15.4s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0303\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9876\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8978\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8507\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8366\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8314\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8289\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8268\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8242\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8208\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8168\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8134\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8108\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8090\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8075\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8064\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8056\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8049\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8046\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8041\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "[CV 2/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.520 total time=  15.9s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 1.0881\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0324\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9324\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8954\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8854\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8797\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8747\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8710\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8677\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8643\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8609\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8587\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8574\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8565\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8560\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8556\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8555\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8552\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8550\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8548\n",
            "149/149 [==============================] - 0s 777us/step\n",
            "[CV 3/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.310 total time=  15.5s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0839\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 1.0337\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9369\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8991\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8882\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8828\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8784\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8741\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8701\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8669\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8644\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8626\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8614\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8606\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8599\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8594\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8590\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8588\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8585\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.8583\n",
            "149/149 [==============================] - 0s 784us/step\n",
            "[CV 4/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.420 total time=  15.8s\n",
            "Epoch 1/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.9036\n",
            "Epoch 2/20\n",
            "595/595 [==============================] - 1s 2ms/step - loss: 0.8167\n",
            "Epoch 3/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7656\n",
            "Epoch 4/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7374\n",
            "Epoch 5/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7296\n",
            "Epoch 6/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7255\n",
            "Epoch 7/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7228\n",
            "Epoch 8/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7208\n",
            "Epoch 9/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7186\n",
            "Epoch 10/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7150\n",
            "Epoch 11/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.7074\n",
            "Epoch 12/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6970\n",
            "Epoch 13/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6913\n",
            "Epoch 14/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6892\n",
            "Epoch 15/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6880\n",
            "Epoch 16/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6873\n",
            "Epoch 17/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6866\n",
            "Epoch 18/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6863\n",
            "Epoch 19/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6859\n",
            "Epoch 20/20\n",
            "595/595 [==============================] - 1s 1ms/step - loss: 0.6857\n",
            "149/149 [==============================] - 0s 770us/step\n",
            "[CV 5/5] END activation_func=softmax, batch_size=100, epochs=20, extra_hidden_layers=1, last_layer_nodes=20, loss_func=categorical_crossentropy, optimizer=sge, optimizer__learning_rate=0.0001;, score=0.000 total time=  15.5s\n",
            "Epoch 1/5\n",
            "743/743 [==============================] - 1s 850us/step - loss: 0.8958\n",
            "Epoch 2/5\n",
            "743/743 [==============================] - 1s 863us/step - loss: 0.8505\n",
            "Epoch 3/5\n",
            "743/743 [==============================] - 1s 861us/step - loss: 0.8490\n",
            "Epoch 4/5\n",
            "743/743 [==============================] - 1s 856us/step - loss: 0.8486\n",
            "Epoch 5/5\n",
            "743/743 [==============================] - 1s 1ms/step - loss: 0.8483\n",
            "Los parámetros óptimizados fueron:  {'activation_func': 'relu', 'batch_size': 100, 'epochs': 5, 'extra_hidden_layers': 0, 'last_layer_nodes': 20, 'loss_func': 'categorical_crossentropy', 'optimizer': 'adam', 'optimizer__learning_rate': 0.0001}\n"
          ]
        }
      ],
      "source": [
        "gs.fit(x_train_clasificacion, y_train_clasificacion)\n",
        "print(\"Los parámetros óptimizados fueron: \", gs.best_params_)"
      ],
      "metadata": {
        "id": "tyJ6__58Ntwr",
        "outputId": "69ae5d77-063b-46fe-ac1a-9466d4872b11"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predecimos con el dataset de test"
      ],
      "metadata": {
        "collapsed": false,
        "id": "j8q_nZhqNtws"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "187/187 [==============================] - 0s 978us/step\n"
          ]
        }
      ],
      "source": [
        "y_pr = gs.predict(x_test_clasificacion)"
      ],
      "metadata": {
        "id": "kUj9v6HVNtws",
        "outputId": "5a7b1da5-4890-48d5-e330-bb0ae816d44c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.b.4 Métricas\n",
        "Transformamos el array devuelto por el modelo a un dataframe de iguales columnas que y_test_clasificacion"
      ],
      "metadata": {
        "id": "W-KMjjHwaFjg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "y_pr_df = pd.DataFrame(data=y_pr, columns=['alto', 'bajo', 'medio'])"
      ],
      "metadata": {
        "id": "7AlemSySNtws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculamos las métricas"
      ],
      "metadata": {
        "collapsed": false,
        "id": "JNQyjOdnNtws"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.57\n",
            "Precision: 0.58\n",
            "Recall: 0.5\n",
            "F1 Score: 0.51\n"
          ]
        }
      ],
      "source": [
        "metricas_clasificacion(y_test_clasificacion, y_pr_df)"
      ],
      "metadata": {
        "id": "tFo_Q9r9Ntws",
        "outputId": "67302c8d-7a63-4189-fabf-76260635e6a6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.b.5 Exportación de Datos"
      ],
      "metadata": {
        "id": "5SsWSPw1fJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, exportamos el modelo utilizado:"
      ],
      "metadata": {
        "id": "IlgF2MmmfJYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "if IN_COLAB:\n",
        "  path = '/content/drive/MyDrive/📔 Organización de Datos (75.06)/TPS/TP2/MODELOS/Redes_Classifier.json'\n",
        "else:\n",
        "  path = './MODELOS/Redes_Classifier.json'\n",
        "\n",
        "joblib.dump(gs.best_estimator_, path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48479ec0-085c-4964-aa1d-b771dc5643e4",
        "id": "yjKFj8TjfJYn"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\Salvador\\AppData\\Local\\Temp\\tmpsufktigt\\assets\n"
          ]
        },
        {
          "data": {
            "text/plain": "['./MODELOS/Redes_Classifier.json']"
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDpREdwKxB6m"
      },
      "source": [
        "## 3. Ensamble de Modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvLq10beDadg"
      },
      "source": [
        "### 3. a) Voting - Clasificación\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAT6HU3buhLU"
      },
      "source": [
        "#### Preparación del dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZNjL2W-vZvC"
      },
      "source": [
        "Para la parte de ensambles, lo que haremos será utilizar nuevamente el dataset al cual se le aplicó una reducción de su dimensionalidad en el trabajo práctico n°1. \n",
        "\n",
        "Para esto lo que haremos será trabajar con una copia del dataset modificado al inicio del trabajo, el cual usa como base el reducido mencionado anteriormente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDp1eW_cHfxt"
      },
      "source": [
        "Para nuestra variable `target`, utilizaremos como convención la misma que fue planteada para el tp1. Ésta consiste en subdividir a la variable pxm2 (precio por metro cuadrado) en 3 intervalos, 25% a bajo, 50% a medio y el otro 25% restante a alto. A su vez, se hará la separación tambien por tipo de propiedad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7T0ZW9l-dcqI"
      },
      "outputs": [],
      "source": [
        "x_train_voting = x_train_clasificacion\n",
        "y_train_voting = y_train_clasificacion\n",
        "\n",
        "x_test_voting = x_test_clasificacion\n",
        "y_test_voting = y_test_clasificacion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSKtHVSSgBhv",
        "outputId": "7aa3496e-06d6-4554-9116-598df92b20e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se observaron:\n",
            "- 23227 registros de tipo 'bajo'.\n",
            "- 46459 registros de tipo 'medio'.\n",
            "- 23170 registros de tipo 'alto'.\n"
          ]
        }
      ],
      "source": [
        "bajo = y_train_voting['bajo'].sum() + y_test_voting.bajo.sum()\n",
        "medio = y_train_voting['medio'].sum() + y_test_voting.medio.sum()\n",
        "alto = y_train_voting['alto'].sum() + y_test_voting.alto.sum()\n",
        "\n",
        "print(f\"Se observaron:\")\n",
        "print(f\"- {round(bajo,3)} registros de tipo 'bajo'.\")\n",
        "print(f\"- {round(medio,3)} registros de tipo 'medio'.\")\n",
        "print(f\"- {round(alto,3)} registros de tipo 'alto'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kG7ZRlKuaxT"
      },
      "source": [
        "#### Definición del Ensamble"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGYLj6zEDcf7"
      },
      "source": [
        "Para el tipo de ensamble **voting**, lo que necesitaremos será contar con `n` cantidad de modelos previamente entrenados para luego someterlos a una votación. De la misma, saldrá la clasificación para la nueva instancia en base a lo que indique la mayoría de ellos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTMs6ZsBDd_Y"
      },
      "source": [
        "Elegimos tomar como modelos los mismos empleados en el TP1:\n",
        "\n",
        "\n",
        "*   Árbol de Decisión\n",
        "*   Random Forest\n",
        "*   KNN\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U437nPqDP87B"
      },
      "source": [
        "En esta línea, cargamos en memoria los modelos previamente guardados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_k9OCodePoJD"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "  path = '/content/drive/MyDrive/📒 Organización de Datos (75.06)/TPS/TP1/MODELOS/DecisionTree_Classfier.joblib'\n",
        "else:\n",
        "  path = './MODELOS/DecisionTree_Classfier.joblib'\n",
        "\n",
        "dcs_clf = load(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7IWWmUoPwGH"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "  path = '/content/drive/MyDrive/📒 Organización de Datos (75.06)/TPS/TP1/MODELOS/RandomForest_Classfier.joblib'\n",
        "else:\n",
        "  path = './MODELOS/RandomForest_Classfier.joblib'\n",
        "\n",
        "rnd_clf = load(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sx-_-Q9xPc29"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "  path = '/content/drive/MyDrive/📒 Organización de Datos (75.06)/TPS/TP1/MODELOS/KNN_Classfier.joblib'\n",
        "else:\n",
        "  path = './MODELOS/KNN_Classfier.joblib'\n",
        "\n",
        "knn_clf = load(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lz62MXjMR6eu"
      },
      "source": [
        "Recordemos que estos modelos fueron optimizados con los siguientes hiperparámetros y valores:\n",
        "\n",
        "- **Decision Tree**:\n",
        "    * ccp_alpha: 0.0001\n",
        "    * criterion: gini\n",
        "    * max_depth: 21\n",
        "- **Random Forest**: \n",
        "    * ccp_alpha: 0.0001\n",
        "    * criterion: entropy \n",
        "    * max_depth: 25\n",
        "    * n_estimators: 55\n",
        "- **K Nearest Neighbors**: \n",
        "    * algorithm: kd_tree\n",
        "    * leaf_size: 5\n",
        "    * n_jobs: -1\n",
        "    * n_neighbors: 3\n",
        "    * weights: distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEgb4Z2xDon_"
      },
      "source": [
        "Una vez que contamos con los modelos que vamos a utilizar en el ensamble, procedemos a su creación. En este caso particular decidimos utilizar el tipo de votación `hard` el cual utilizará la regla de la mayoría. Por otro lado, utilizamos el hiperparámetro `estimators` para definir como nos vamos a referir a dichos modelos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlSEwC0ODq26"
      },
      "outputs": [],
      "source": [
        "vot_clf = VotingClassifier(estimators = [('dcs', dcs_clf), ('rnd', rnd_clf), ('knn', knn_clf)], voting = 'hard')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8sgMCouvLx-"
      },
      "source": [
        "#### Entrenamiento y Predicción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "_aTA577USlsB"
      },
      "source": [
        "Reorganizamos los valores predichos para que queden en una sola columna. Luego, procedemos a comparar con el conjunto de prueba:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylyPOrZ9SlsC"
      },
      "outputs": [],
      "source": [
        "y_train_voting_arr = np.apply_along_axis(convert_b_m_a, axis=1, arr=y_train_voting)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMyijnL-SlsD"
      },
      "source": [
        "Seguimos reacomodando los valores para poder calcular las métricas correspondientes, notemos que no pueden guardarse valores equivalentes al string 'medio' en el array:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMGsKgJLSlsE",
        "outputId": "aa8c29f3-9a5c-4ef3-f56e-e992a4bc474e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['alto', 'bajo', 'medio'], dtype='<U5')"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "np.unique(y_train_voting_arr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmDJFqfxSlsE"
      },
      "source": [
        "Aplicamos estrategias de transformación de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vK5dgr3SSlsE"
      },
      "outputs": [],
      "source": [
        "y_train_voting_arr = np.where(y_train_voting_arr == 'medi', 'medio', y_train_voting_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0Wmo-6KSlsF",
        "outputId": "baae9009-5976-4512-85d4-ee5702c71214"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['alto', 'bajo', 'medio'], dtype='<U5')"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "np.unique(y_train_voting_arr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAJbjjZ1SlsF"
      },
      "source": [
        "Finalmente, `entrenamos` el ensamble:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yr85PLiD1vO",
        "outputId": "99637dc3-6d42-4237-870a-f307868d356d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('dcs',\n",
              "                              DecisionTreeClassifier(ccp_alpha=0.0001,\n",
              "                                                     max_depth=21)),\n",
              "                             ('rnd',\n",
              "                              RandomForestClassifier(ccp_alpha=0.0001,\n",
              "                                                     criterion='entropy',\n",
              "                                                     max_depth=25,\n",
              "                                                     n_estimators=55,\n",
              "                                                     random_state=5)),\n",
              "                             ('knn',\n",
              "                              KNeighborsClassifier(algorithm='kd_tree',\n",
              "                                                   leaf_size=5, n_jobs=-1,\n",
              "                                                   n_neighbors=3,\n",
              "                                                   weights='distance'))])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "vot_clf.fit(x_train_voting, y_train_voting_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mf1Le81Ujyc"
      },
      "outputs": [],
      "source": [
        "y_pred_voting = vot_clf.predict(x_test_voting)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZIFAhvgNv4p"
      },
      "source": [
        "Reaplicamos la reorganización de valores para el dataset de test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J44P4lPZNhzo"
      },
      "outputs": [],
      "source": [
        "y_test_voting_arr = np.apply_along_axis(convert_b_m_a, axis=1, arr=y_test_voting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2i17oA6N3v6",
        "outputId": "dcfeeae9-2dad-4ab3-a77e-5bd6c2309671"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['alto', 'bajo', 'medio'], dtype='<U5')"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "np.unique(y_test_voting_arr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTaTYoJYuv-M"
      },
      "source": [
        "#### Métricas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoJ-lAV7Qz6M"
      },
      "source": [
        "Para poder determinar que tan bueno resulto el modelo, lo que haremos será observar las `métricas` resultantes de una predicción con los datos de test. Recordemos que nuestras funciones de metricas fueron definidas al inicio de este trabajo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1klUyeDQ3zj",
        "outputId": "235008ad-118c-4a5a-f067-bf1611dc4d4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.63\n",
            "Precision: 0.65\n",
            "Recall: 0.57\n",
            "F1 Score: 0.59\n"
          ]
        }
      ],
      "source": [
        "metricas_clasificacion(y_test_voting_arr, y_pred_voting)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como se puede observar, el ensamble resultante predice bastante bien, aunque podriamos obtener mejores métricas. Si bien el Accuracy y la precision son buenas, al momento de calcular el recall tenemos un valor un poco menor, el cual repercute directamente en el F1 Score ya que como sabemos este tiene en cuenta las métricas tanto de Precision como Recall."
      ],
      "metadata": {
        "id": "IUBYcfzEmtxg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnFftUBRQ5zk"
      },
      "source": [
        "A su vez, también podemos visualizar los mismos a través de la siguiente matriz de confusión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "I6EWIuOUQ7W7",
        "outputId": "c2f0e330-edfc-4f1f-b404-d240c8fd1fa1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(33.0, 0.5, 'True')"
            ]
          },
          "metadata": {},
          "execution_count": 89
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "matrix = confusion_matrix(y_test_voting_arr, y_pred_voting)\n",
        "sns.heatmap(matrix,cmap='GnBu',annot=True,fmt='g')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nuevamente aqui se puede observar que la celda que presenta mayores valores por una amplia diferencia es la `[0][0]`. Notemos que las que le siguen en cantidad se ubican en `[1][0]` y `[2][0]`, las cuales hacen que las métricas decrementen su valor. Cercano a estos valores esta la celda de `[2][2]` en donde volvemos a tener saldo positivo, al igual que cuando tenemos en cuenta la `[1][1]` que por mas que sean algunos registros menos, sigue siendo una cantidad significante. Concluimos luego que los resultados se correlacionan con la matríz de confusión."
      ],
      "metadata": {
        "id": "V_OyAMISpdFz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tm_FRzR7fvEH"
      },
      "source": [
        "#### Exportación de Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b04Kqm-IfvEI"
      },
      "source": [
        "Finalmente, exportamos el ensamble utilizado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flZ1yIxzfvEJ",
        "outputId": "dfb2507e-2da9-4321-a770-4de40b6529a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/📒 Organización de Datos (75.06)/TPS/TP2/MODELOS/Voting_Classifier.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "if IN_COLAB:\n",
        "  path = '/content/drive/MyDrive/📒 Organización de Datos (75.06)/TPS/TP2/MODELOS/Voting_Classifier.joblib'\n",
        "else:\n",
        "  path = './MODELOS/Voting_Classifier.joblib'\n",
        "\n",
        "dump(vot_clf, path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gDV2ozmQ9mb"
      },
      "source": [
        "### 3. b) Stacking - Regresión\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRpAEJ7WrgeV"
      },
      "source": [
        "#### Preparación del dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQwjdBg4rgeW"
      },
      "source": [
        "Nuevamente, utilizamos los datasets de train y test previamente definidos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9obURdGWrgeW"
      },
      "outputs": [],
      "source": [
        "x_train_stacking = x_train_regresion\n",
        "y_train_stacking = y_train_regresion\n",
        "\n",
        "x_test_stacking = x_test_regresion\n",
        "y_test_stacking = y_test_regresion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FjGFid7Y7Fj"
      },
      "source": [
        "#### Definición del Ensamble\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3EG9oZ3Q_zL"
      },
      "source": [
        "Lo que haremos en esta nueva sección, será implementar un nuevo tipo de ensable híbrido con la salvedad de que esta vez utilizaremos el tipo `cascading`.\n",
        "El mismo se basa en el entrenamiento de distintos `modelos base`, y a su vez utilizará un `meta-modelo` el cual realizará su predicción en base a las predicciones de los diferentes modelos comentados anteriormente. \n",
        "\n",
        "Como es indicado por el enunciado del trabajo se utilizarán modelos de regresión. En particular, decidimos trabajar con:\n",
        "\n",
        "\n",
        "*   KNN\n",
        "*   XGBoost\n",
        "*   AdaBoost\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZ1GwmfuRe0C"
      },
      "source": [
        "En esta línea, cargamos en memoria los modelos previamente guardados del TP1 realizado con anterioridad:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Y0wFABHQOhS"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "  path = '/content/drive/MyDrive/📒 Organización de Datos (75.06)/TPS/TP1/MODELOS/KNN_Regressor_Train.joblib'\n",
        "else:\n",
        "  path = './MODELOS/KNN_Regressor_Train.joblib'\n",
        "\n",
        "knn_rgs = load(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zvVhilyQRDj",
        "outputId": "8a7d20be-3e5f-4b50-d94b-73b835c8d716"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:30:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        }
      ],
      "source": [
        "if IN_COLAB:\n",
        "  path = '/content/drive/MyDrive/📒 Organización de Datos (75.06)/TPS/TP1/MODELOS/XGB_Regressor_Train.joblib'\n",
        "else:\n",
        "  path = './MODELOS/XGB_Regressor_Train.joblib'\n",
        "\n",
        "xgb_rgs = load(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBui1YlcQQ7E"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "  path = '/content/drive/MyDrive/📒 Organización de Datos (75.06)/TPS/TP1/MODELOS/AdaB_Regressor_Train.joblib'\n",
        "else:\n",
        "  path = './MODELOS/AdaB_Regressor_Train.joblib'\n",
        "\n",
        "adb_rgs = load(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGi5lWsDTnpA"
      },
      "source": [
        "A modo de recordatorio, enunciamos los hiperparámetros con los que estos modelos fueron optimizados:\n",
        "\n",
        "- **K Nearest Neighbors**: \n",
        "    * weights: uniform\n",
        "    * n_neighbors: 51\n",
        "    * metric: chebyshev\n",
        "    * leaf_size: 22\n",
        "    * algorithm: ball_tree\n",
        "- **Extreme Gradient Boosting**: \n",
        "    * min_child_weight: 5\n",
        "    * max_depth: 6\n",
        "    * learning_rate: 0.3\n",
        "    * gamma: 0.1\n",
        "    * colsample_bytree: 0.3\n",
        "- **Adaptive Boosting**: \n",
        "    * n_estimators: 10\n",
        "    * learning_rate: 1.02"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoI5ilXVRD06"
      },
      "source": [
        "Luego utilizamos los mismos para definir nuestro modelo base, en el cual luego se basará el meta-modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qK74SKO-RF4U"
      },
      "outputs": [],
      "source": [
        "base_models = [('KNN', knn_rgs),\n",
        "               ('XGBoost', xgb_rgs),\n",
        "               ('AdaBoost', adb_rgs)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7j2qzBXRHd6"
      },
      "source": [
        "Como mencionamos, a continuación los utilizaremos para definir nuestro meta-modelo. Para este último, decidimos emplear el modelo de regresión logistica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mRJmKOSRJCy"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "meta_model = GradientBoostingRegressor()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnA6P4zORKsq"
      },
      "source": [
        "Creamos nuestro ensamble indicando como modelos estimadores Knn, XGBoost y AdaBoost, y como estimador final el modelo de Regresión Lineal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6j70-9G75VW2"
      },
      "outputs": [],
      "source": [
        "s = 5\n",
        "n = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWOHgLGcRMHr"
      },
      "outputs": [],
      "source": [
        "stacking_model = StackingRegressor(estimators=base_models, \n",
        "                                    final_estimator=meta_model, \n",
        "                                    passthrough=True, \n",
        "                                    cv=s,\n",
        "                                    verbose=n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYCuFlWQZhlo"
      },
      "source": [
        "#### Entrenamiento y Predicción"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez conformado el ensamble que decidimos utilizar, ahora si estamos en condiciones de pasar a realizar su entrenamiento."
      ],
      "metadata": {
        "id": "wIS8S06CrcwY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QomGOhfXEgg7",
        "outputId": "edc45690-84d9-4470-f51b-8fcfb63eb963"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating KNN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
            "[Parallel(n_jobs=3)]: Done  10 out of  10 | elapsed: 13.1min finished\n",
            "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating XGBoost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=3)]: Done  10 out of  10 | elapsed:  1.1min finished\n",
            "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating AdaBoost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=3)]: Done  10 out of  10 | elapsed:   27.1s finished\n"
          ]
        }
      ],
      "source": [
        "model_scores = defaultdict()\n",
        "\n",
        "for name, model in base_models:\n",
        "    print('Evaluating {}'.format(name))\n",
        "    scores = evaluate_model(model, x_train_stacking, y_train_stacking, s, n)\n",
        "    model_scores[name] = scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyJIbF3HsxK8"
      },
      "source": [
        "Una vez que realizamos una iteración por cada uno de los modelos base, evaluamos cómo resultaron los scores de los mismos a través del siguiente gráfico. En éste se puede apreciar la relación de cada uno de los modelos, y a su vez tener una noción concreta de sus principales métricas (mediana, q1, q3, mánimo y máximo)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "CPzQs8HBsuR4",
        "outputId": "6e627a64-00e4-4c82-fbfd-4ff3e1ac5835"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"4092681b-6c8b-4ba0-a3ae-4c26bc25e6d3\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4092681b-6c8b-4ba0-a3ae-4c26bc25e6d3\")) {                    Plotly.newPlot(                        \"4092681b-6c8b-4ba0-a3ae-4c26bc25e6d3\",                        [{\"boxpoints\":\"all\",\"jitter\":0.5,\"line\":{\"width\":1},\"marker\":{\"size\":2},\"name\":\"KNN\",\"whiskerwidth\":0.2,\"y\":[-21428775757.75755,-16201215328.812365,-17848391140.408684,-19763250501.8644,-17695749481.532146,-21657111489.639683,-16672426912.50796,-17847617677.27545,-19154713152.768898,-17543341189.858273],\"type\":\"box\"},{\"boxpoints\":\"all\",\"jitter\":0.5,\"line\":{\"width\":1},\"marker\":{\"size\":2},\"name\":\"XGBoost\",\"whiskerwidth\":0.2,\"y\":[-12982427106.775623,-8485467481.563318,-8157098015.72927,-11247594172.816221,-8759145370.370293,-12944688780.391924,-8497278206.171427,-8680600079.800514,-10389681057.153002,-8248096018.172669],\"type\":\"box\"},{\"boxpoints\":\"all\",\"jitter\":0.5,\"line\":{\"width\":1},\"marker\":{\"size\":2},\"name\":\"AdaBoost\",\"whiskerwidth\":0.2,\"y\":[-26717422906.89227,-28134704945.46074,-27041080039.86731,-23771692729.733738,-24517626402.191345,-27940002281.537373,-25324230344.669437,-29691821631.09539,-23991214276.47447,-22600643674.862305],\"type\":\"box\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Performance of Different Models Using 5-Fold Cross-Validation\"},\"paper_bgcolor\":\"rgb(243, 243, 243)\",\"plot_bgcolor\":\"rgb(243, 243, 243)\",\"xaxis\":{\"title\":{\"text\":\"Model\"}},\"yaxis\":{\"title\":{\"text\":\"Error Cuadr\\u00e1tico Medio\"}},\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('4092681b-6c8b-4ba0-a3ae-4c26bc25e6d3');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "plot_results(model_scores, name='stacking_model_cv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uduejW9os8-J"
      },
      "source": [
        "Entrenamos el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VT_HO24fk7kR",
        "outputId": "7f9d405b-8f69-4d6d-e534-5b4ce7bc7cff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:45:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.0min remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  9.0min finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:54:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.9s remaining:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:54:50] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[00:54:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[00:55:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[00:55:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   39.4s finished\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.7s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   18.5s finished\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StackingRegressor(cv=5,\n",
              "                  estimators=[('KNN',\n",
              "                               KNeighborsRegressor(algorithm='ball_tree',\n",
              "                                                   leaf_size=22,\n",
              "                                                   metric='chebyshev',\n",
              "                                                   n_neighbors=51)),\n",
              "                              ('XGBoost',\n",
              "                               XGBRegressor(colsample_bytree=0.3, gamma=0.1,\n",
              "                                            learning_rate=0.3, max_depth=6,\n",
              "                                            min_child_weight=5, missing=nan)),\n",
              "                              ('AdaBoost',\n",
              "                               AdaBoostRegressor(learning_rate=1.02,\n",
              "                                                 n_estimators=10))],\n",
              "                  final_estimator=GradientBoostingRegressor(), passthrough=True,\n",
              "                  verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "stacking_model.fit(x_train_stacking, y_train_stacking)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "567lujdizE8r"
      },
      "source": [
        "Finalmente haremos la predicción:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Cw7e8GzzEFC"
      },
      "outputs": [],
      "source": [
        "y_pred_stacking = stacking_model.predict(x_test_stacking)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUjE089xzI7j"
      },
      "source": [
        "#### Métricas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLNhGzU6zNVc"
      },
      "source": [
        "Para poder evaluar la performance que obtuvo nuestro modelo utilizaremos la métrica de evaluación del `error cuadrático medio` (MSE) como se pide por enunciado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgpouA6A0e1-",
        "outputId": "afbbb19f-82a1-4504-98fb-d6f89adab65a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El error según la métrica 'Mean Square Error' de test es: 109761158655.8607\n"
          ]
        }
      ],
      "source": [
        "mse = metrics.mean_squared_error(\n",
        "        y_true  = y_test_stacking,\n",
        "        y_pred  = y_pred_stacking,\n",
        "        squared = True\n",
        "       )\n",
        "\n",
        "print(f\"El error según la métrica 'Mean Square Error' de test es: {mse}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En la métrica MSE podemos ver que obtuvimos un error un tanto grosero. Luego de repasar las lógicas realizadas a lo largo de este punto como equipo decidimos atribuirlo a algún error involuntario cometido en el proceso."
      ],
      "metadata": {
        "id": "kOD_ohsJsinS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQk2khn_gLmD"
      },
      "source": [
        "#### Exportación de Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmlWq5XygLmE"
      },
      "source": [
        "Finalmente, exportamos el modelo utilizado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ruQqkIZgLmE",
        "outputId": "6dc06e2a-cd30-4cc9-a26a-7d6182b49873"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/📒 Organización de Datos (75.06)/TPS/TP2/MODELOS/Stacking_Regressor.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "source": [
        "if IN_COLAB:\n",
        "  path = '/content/drive/MyDrive/📒 Organización de Datos (75.06)/TPS/TP2/MODELOS/Stacking_Regressor.joblib'\n",
        "else:\n",
        "  path = './MODELOS/Stacking_Regressor.joblib'\n",
        "\n",
        "dump(stacking_model, path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFntMJUkIzEu"
      },
      "source": [
        "## Conclusiones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CE40zH4PI4xY"
      },
      "source": [
        "A modo de finalización de este trabajo, haremos un pequeño repaso sobre todos los puntos que analizamos y sus respectivos resultados y/o observaciones hechos por nosotros:\n",
        "\n",
        "Sobre el análisis realizado en el apartado de **procesamiento del lenguaje natural**, y en particular haciendo referencia a las métricas que obtuvimos luego del entrenamiento y predicción con el dataset producto de la ampliación, utilizando el modelo XGBoost, pudimos observar que si bien aún las métricas no nos resultan del todo satisfactorias cumplen con el objetivo de mejorar las resultantes del trabajo anterior. Más allá de que la cantidad de aciertos continúa sin incrementar, tanto el MSE como el RMSE decrecieron ofreciendo mejores resultados. Por otro lado, el coeficiente de determinación se incrementó notoriamente llegando casi a un 0.9%. En lo que respecta a *feature importance*, realizamos la misma enfocándonos en los atributos de cada uno de los aspectos elegidos como más importantes del dataset general. Cabe destacar que obtuvimos los mismos resultados con y sin optimizar los hiperparámetros del modelo de regresión.\n",
        "\n",
        "En cuanto a lo referido sobre **redes neuronales**, la comparación será directamente en base a los nuevos modelos ya que el dataset utilizado es compartido en ambos trabajos. Dicho esto, el error cometido en el modelo de regresión es significativamente pequeño. Teniendo en cuenta los resultantes del TP1, si utilizamos el menor luego de que éstos tuvieron su optimización de parámetros correspondiente, notamos que el que mejor performa es XGBoost con un MSE de 51 mil millones (al cual de todas formas le atribuímos arrastre de error en nuestro planteo). Utilizando redes neuronales cometemos tan solo un error cuadrático medio equivalente a 1.36. Por otro lado, en lo que respecta al modelo de clasificación, obtuvimos resultados bastante similares. Si bien tanto el accuracy, precisión y F1-Score dieron distintos, la diferencia es de tan solo uno/dos puntos. Con esto concluimos que para clasificación no se notan mejoras por sobre los modelos utilizados en el trabajo anterior.\n",
        "\n",
        "Como último requerimiento se pidió estudiar las métricas tanto para regresión como clasificación pero haciendo uso de **ensambles**, en particular de tipo híbridos. En lo que respecta al utilizado para clasificación (Voting) obtuvimos mejores resultados para las métricas de Accuracy, Recall y F1-Score. Sin embargo, aunque en Precisión disminuyó un poco, esta diferencia continúa siendo no significativa. Pasando al ensamble de regresión (Stacking) el MSE resultante que obtuvimos fue 106 mil millones que si bien continúa siendo alto, luego de aplicar la optimización de hiperparámetros como nos fue recomendado como corrección de esta reentrega este número se redujo a la mitad que obtenido en la entrega inicial. Mas allá de esto, al continuar siendo este bastante grosero, creemos que nuevamente estamos cometiendo involuntariamente algún arrastre de error en alguno de los incisos desarrollados, ya que este error es incluso mayor a los cometidos en los modelos individuales desarrollados en el TP1, y no estaría respetando la regla principal de ‘*La sabiduría de las multitudes*’."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "UIepC0DvF2Hl"
      ],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}